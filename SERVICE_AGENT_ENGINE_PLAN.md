# Agent Engine - åŠŸèƒ½æ¸…å•ä¸è¿­ä»£è®¡åˆ’

> **æœåŠ¡åç§°**: Agent Engine (algo/agent-engine)
> **å½“å‰ç‰ˆæœ¬**: v1.0.0
> **å®Œæˆåº¦**: 60%
> **ä¼˜å…ˆçº§**: P0 (æ ¸å¿ƒæœåŠ¡)

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

Agent Engine æ˜¯ VoiceAssistant å¹³å°çš„æ™ºèƒ½ä»£ç†æ‰§è¡Œå¼•æ“ï¼Œè´Ÿè´£å¤æ‚ä»»åŠ¡çš„åˆ†è§£ã€å·¥å…·è°ƒç”¨å’Œå¤šæ­¥æ¨ç†ã€‚å½“å‰å·²å®ç°åŸºç¡€ ReAct æ¡†æ¶ï¼Œä½†ä»æœ‰å¤šé¡¹å…³é”®åŠŸèƒ½å¾…å®Œå–„ã€‚

### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡       | å½“å‰çŠ¶æ€  | ç›®æ ‡çŠ¶æ€             | å·®è·  |
| ---------- | --------- | -------------------- | ----- |
| è®°å¿†ç³»ç»Ÿ   | Mock å®ç° | å‘é‡åŒ–æŒä¹…è®°å¿†       | âš ï¸ é«˜ |
| å·¥å…·æ•°é‡   | 3 ä¸ª Mock | 10+å®é™…å·¥å…·          | âš ï¸ é«˜ |
| æ¨ç†ç­–ç•¥   | ä»… ReAct  | ReAct + Plan&Execute | âš ï¸ ä¸­ |
| æµå¼è¾“å‡º   | ä¸æ”¯æŒ    | å®Œæ•´æ”¯æŒ             | âš ï¸ ä¸­ |
| ä»»åŠ¡æŒä¹…åŒ– | å†…å­˜      | Redis æŒä¹…åŒ–         | âš ï¸ é«˜ |

---

## ğŸ” æœªå®ŒæˆåŠŸèƒ½æ¸…å• (åŸºäº TODO æ‰«æ)

### P0 çº§åˆ« (é˜»å¡æ€§åŠŸèƒ½)

#### 1. è®°å¿†ç®¡ç† - å‘é‡æ£€ç´¢

**æ–‡ä»¶**: `app/memory/memory_manager.py:209,282,306`

**é—®é¢˜æè¿°**:

```python
# Line 209
# TODO: å®ç°åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ£€ç´¢

# Line 282
# TODO: å®ç°å‘é‡å­˜å‚¨

# Line 306
# TODO: å®ç°å‘é‡æ£€ç´¢
```

**å½±å“**: Agent æ— æ³•è¿›è¡Œä¸ªæ€§åŒ–å¯¹è¯å’ŒçŸ¥è¯†ç§¯ç´¯

**è¯¦ç»†è®¾è®¡æ–¹æ¡ˆ**:

```python
# app/memory/vector_memory.py

from typing import List, Dict, Optional
import numpy as np
from datetime import datetime
import httpx

class VectorMemoryManager:
    """åŸºäºå‘é‡æ•°æ®åº“çš„é•¿æœŸè®°å¿†ç®¡ç†"""

    def __init__(
        self,
        milvus_url: str = "http://milvus:19530",
        embedding_service_url: str = "http://model-adapter:8002"
    ):
        self.milvus_url = milvus_url
        self.embedding_service_url = embedding_service_url
        self.collection_name = "agent_memory"
        self._init_collection()

    def _init_collection(self):
        """åˆå§‹åŒ–Milvusé›†åˆ"""
        from pymilvus import Collection, CollectionSchema, FieldSchema, DataType

        fields = [
            FieldSchema(name="memory_id", dtype=DataType.VARCHAR, max_length=64, is_primary=True),
            FieldSchema(name="user_id", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=2048),
            FieldSchema(name="memory_type", dtype=DataType.VARCHAR, max_length=32),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1536),
            FieldSchema(name="created_at", dtype=DataType.INT64),
            FieldSchema(name="importance", dtype=DataType.FLOAT),
            FieldSchema(name="access_count", dtype=DataType.INT32),
            FieldSchema(name="last_accessed", dtype=DataType.INT64),
        ]

        schema = CollectionSchema(fields=fields, description="Agent Long-term Memory")
        collection = Collection(name=self.collection_name, schema=schema)

        # åˆ›å»ºç´¢å¼•
        index_params = {
            "metric_type": "L2",
            "index_type": "IVF_FLAT",
            "params": {"nlist": 1024}
        }
        collection.create_index(field_name="embedding", index_params=index_params)
        collection.load()

    async def store_memory(
        self,
        user_id: str,
        content: str,
        memory_type: str = "conversation",
        importance: float = 0.5
    ) -> str:
        """å­˜å‚¨æ–°è®°å¿†"""
        import uuid
        from pymilvus import Collection

        # ç”Ÿæˆembedding
        embedding = await self._get_embedding(content)

        memory_id = str(uuid.uuid4())
        memory_data = [{
            "memory_id": memory_id,
            "user_id": user_id,
            "content": content,
            "memory_type": memory_type,
            "embedding": embedding,
            "created_at": int(datetime.now().timestamp()),
            "importance": importance,
            "access_count": 0,
            "last_accessed": int(datetime.now().timestamp()),
        }]

        collection = Collection(self.collection_name)
        collection.insert(memory_data)

        return memory_id

    async def retrieve_memory(
        self,
        user_id: str,
        query: str,
        top_k: int = 5,
        time_decay: bool = True
    ) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³è®°å¿†"""
        from pymilvus import Collection

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = await self._get_embedding(query)

        # å‘é‡æ£€ç´¢
        collection = Collection(self.collection_name)
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}

        results = collection.search(
            data=[query_embedding],
            anns_field="embedding",
            param=search_params,
            limit=top_k * 2,  # è¿‡é‡‡æ ·
            expr=f'user_id == "{user_id}"'
        )

        # åå¤„ç†: æ—¶é—´è¡°å‡ + é‡è¦æ€§åŠ æƒ
        memories = []
        current_time = datetime.now().timestamp()

        for hits in results:
            for hit in hits:
                entity = hit.entity

                # Ebbinghausé—å¿˜æ›²çº¿è¡°å‡
                time_diff_days = (current_time - entity.get("created_at")) / 86400
                decay_factor = np.exp(-time_diff_days / 30)  # 30å¤©åŠè¡°æœŸ

                # è®¿é—®é¢‘ç‡å¢å¼º
                access_boost = min(entity.get("access_count", 0) * 0.1, 0.5)

                # ç»¼åˆå¾—åˆ†
                score = (
                    (1 - hit.distance) * 0.6 +  # å‘é‡ç›¸ä¼¼åº¦
                    entity.get("importance", 0.5) * 0.2 +  # é‡è¦æ€§
                    (decay_factor if time_decay else 1.0) * 0.1 +  # æ—¶é—´è¡°å‡
                    access_boost * 0.1  # è®¿é—®é¢‘ç‡
                )

                memories.append({
                    "memory_id": entity.get("memory_id"),
                    "content": entity.get("content"),
                    "memory_type": entity.get("memory_type"),
                    "score": score,
                    "created_at": entity.get("created_at"),
                })

        # æŒ‰ç»¼åˆå¾—åˆ†æ’åºå¹¶è¿”å›top_k
        memories.sort(key=lambda x: x["score"], reverse=True)
        return memories[:top_k]

    async def update_memory_access(self, memory_id: str):
        """æ›´æ–°è®°å¿†è®¿é—®ç»Ÿè®¡"""
        from pymilvus import Collection

        collection = Collection(self.collection_name)

        # å¢åŠ è®¿é—®è®¡æ•°å’Œæ›´æ–°è®¿é—®æ—¶é—´
        # æ³¨æ„: Milvusä¸æ”¯æŒåŸåœ°æ›´æ–°,éœ€è¦å…ˆæŸ¥è¯¢å†é‡æ–°æ’å…¥
        expr = f'memory_id == "{memory_id}"'
        results = collection.query(expr=expr, output_fields=["*"])

        if results:
            entity = results[0]
            entity["access_count"] += 1
            entity["last_accessed"] = int(datetime.now().timestamp())

            # åˆ é™¤æ—§è®°å½•
            collection.delete(expr=expr)

            # æ’å…¥æ›´æ–°åçš„è®°å½•
            collection.insert([entity])

    async def _get_embedding(self, text: str) -> List[float]:
        """è°ƒç”¨Model Adapterè·å–embedding"""
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{self.embedding_service_url}/api/v1/embeddings",
                json={
                    "input": text,
                    "model": "text-embedding-ada-002"
                }
            )
            response.raise_for_status()
            result = response.json()
            return result["data"][0]["embedding"]


# é›†æˆåˆ° MemoryManager

class MemoryManager:
    def __init__(self):
        self.short_term = {}  # å¯¹è¯çº§çŸ­æœŸè®°å¿†
        self.long_term = VectorMemoryManager()  # å‘é‡åŒ–é•¿æœŸè®°å¿†

    async def add_to_long_term(
        self,
        user_id: str,
        content: str,
        memory_type: str = "conversation"
    ):
        """æ·»åŠ åˆ°é•¿æœŸè®°å¿†"""
        # è¯„ä¼°é‡è¦æ€§
        importance = await self._evaluate_importance(content)

        await self.long_term.store_memory(
            user_id=user_id,
            content=content,
            memory_type=memory_type,
            importance=importance
        )

    async def recall(
        self,
        user_id: str,
        query: str,
        top_k: int = 3
    ) -> List[str]:
        """å›å¿†ç›¸å…³è®°å¿†"""
        memories = await self.long_term.retrieve_memory(
            user_id=user_id,
            query=query,
            top_k=top_k
        )

        # æ›´æ–°è®¿é—®ç»Ÿè®¡
        for memory in memories:
            await self.long_term.update_memory_access(memory["memory_id"])

        return [m["content"] for m in memories]

    async def _evaluate_importance(self, content: str) -> float:
        """ä½¿ç”¨LLMè¯„ä¼°è®°å¿†é‡è¦æ€§"""
        # ç®€åŒ–å®ç°: åŸºäºè§„åˆ™
        # ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨LLMè¯„ä¼°

        important_keywords = ["é‡è¦", "è®°ä½", "å…³é”®", "å¿…é¡»"]
        score = 0.5

        for keyword in important_keywords:
            if keyword in content:
                score += 0.1

        return min(score, 1.0)
```

**é…ç½®æ›´æ–°**:

```yaml
# config/agent-engine.yaml

memory:
  type: 'vector' # "memory" or "vector"
  vector:
    milvus_url: 'http://milvus:19530'
    embedding_service_url: 'http://model-adapter:8002'
    collection_name: 'agent_memory'
    time_decay_enabled: true
    time_decay_half_life_days: 30
```

**éªŒæ”¶æ ‡å‡†**:

- [ ] è®°å¿†æˆåŠŸå­˜å‚¨åˆ° Milvus
- [ ] å‘é‡æ£€ç´¢å¬å›ç‡ > 80%
- [ ] æ—¶é—´è¡°å‡æœºåˆ¶ç”Ÿæ•ˆ
- [ ] è®¿é—®é¢‘ç‡ç»Ÿè®¡æ­£ç¡®
- [ ] å•æ¬¡æ£€ç´¢å»¶è¿Ÿ < 300ms

**å·¥ä½œé‡**: 3-4 å¤©

---

#### 2. å·¥å…·æ³¨å†Œä¸å®ç°

**æ–‡ä»¶**:

- `app/tools/tool_registry.py:246,261,267`
- `app/core/tools/builtin_tools.py:34,65,79`
- `main.py:225`

**é—®é¢˜æè¿°**:

```python
# tool_registry.py:246
# TODO: å®ç°çœŸå®çš„æœç´¢åŠŸèƒ½

# tool_registry.py:261
# TODO: å®ç°çœŸå®çš„çŸ¥è¯†åº“æœç´¢

# tool_registry.py:267
# TODO: å®ç°çœŸå®çš„å¤©æ°”APIè°ƒç”¨

# builtin_tools.py:34
# TODO: å®é™…å®ç°æœç´¢åŠŸèƒ½(è°ƒç”¨æœç´¢å¼•æ“API)

# main.py:225
# TODO: å®ç°åŠ¨æ€å·¥å…·æ³¨å†Œ
```

**å½±å“**: Agent å·¥å…·è°ƒç”¨éƒ½æ˜¯ Mockï¼Œæ— å®é™…åŠŸèƒ½

**è¯¦ç»†è®¾è®¡æ–¹æ¡ˆ**:

```python
# app/tools/real_tools.py

from typing import Dict, Any, List
import httpx
import os
from datetime import datetime

class SearchTool:
    """ç½‘ç»œæœç´¢å·¥å…· (åŸºäºSerpAPI)"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("SERPAPI_KEY")
        self.base_url = "https://serpapi.com/search"

    async def execute(self, query: str, num_results: int = 5) -> str:
        """æ‰§è¡Œæœç´¢"""
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(
                self.base_url,
                params={
                    "q": query,
                    "api_key": self.api_key,
                    "num": num_results,
                    "engine": "google"
                }
            )

            if response.status_code != 200:
                return f"æœç´¢å¤±è´¥: {response.text}"

            data = response.json()
            organic_results = data.get("organic_results", [])

            # æ ¼å¼åŒ–ç»“æœ
            results = []
            for i, result in enumerate(organic_results[:num_results], 1):
                results.append(
                    f"{i}. {result.get('title')}\n"
                    f"   {result.get('snippet')}\n"
                    f"   URL: {result.get('link')}"
                )

            return "\n\n".join(results) if results else "æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"

    def get_definition(self) -> Dict:
        """å·¥å…·å®šä¹‰"""
        return {
            "name": "search",
            "description": "åœ¨äº’è”ç½‘ä¸Šæœç´¢ä¿¡æ¯ã€‚å½“éœ€è¦è·å–å®æ—¶ä¿¡æ¯ã€æœ€æ–°æ–°é—»æˆ–ä¸åœ¨çŸ¥è¯†åº“ä¸­çš„å†…å®¹æ—¶ä½¿ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢æŸ¥è¯¢è¯"
                    },
                    "num_results": {
                        "type": "integer",
                        "description": "è¿”å›ç»“æœæ•°é‡",
                        "default": 5
                    }
                },
                "required": ["query"]
            }
        }


class KnowledgeBaseTool:
    """çŸ¥è¯†åº“æŸ¥è¯¢å·¥å…·"""

    def __init__(self, rag_service_url: str = "http://rag-engine:8006"):
        self.rag_service_url = rag_service_url

    async def execute(
        self,
        query: str,
        knowledge_base_id: str,
        top_k: int = 3
    ) -> str:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{self.rag_service_url}/api/v1/rag/retrieve",
                json={
                    "query": query,
                    "knowledge_base_id": knowledge_base_id,
                    "top_k": top_k
                }
            )

            if response.status_code != 200:
                return f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {response.text}"

            data = response.json()
            documents = data.get("documents", [])

            if not documents:
                return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

            # æ ¼å¼åŒ–ç»“æœ
            results = []
            for i, doc in enumerate(documents, 1):
                results.append(
                    f"{i}. {doc.get('content')[:200]}...\n"
                    f"   (æ¥æº: {doc.get('metadata', {}).get('title', 'æœªçŸ¥')})"
                )

            return "\n\n".join(results)

    def get_definition(self) -> Dict:
        """å·¥å…·å®šä¹‰"""
        return {
            "name": "knowledge_base",
            "description": "ä»ä¼ä¸šçŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ã€‚å½“éœ€è¦æŸ¥è¯¢å…¬å¸æ–‡æ¡£ã€æ”¿ç­–ã€äº§å“ä¿¡æ¯æ—¶ä½¿ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æŸ¥è¯¢é—®é¢˜"
                    },
                    "knowledge_base_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    },
                    "top_k": {
                        "type": "integer",
                        "description": "è¿”å›æ–‡æ¡£æ•°é‡",
                        "default": 3
                    }
                },
                "required": ["query", "knowledge_base_id"]
            }
        }


class WeatherTool:
    """å¤©æ°”æŸ¥è¯¢å·¥å…·"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("OPENWEATHER_API_KEY")
        self.base_url = "https://api.openweathermap.org/data/2.5/weather"

    async def execute(self, city: str, country: str = "CN") -> str:
        """æŸ¥è¯¢å¤©æ°”"""
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(
                self.base_url,
                params={
                    "q": f"{city},{country}",
                    "appid": self.api_key,
                    "units": "metric",
                    "lang": "zh_cn"
                }
            )

            if response.status_code != 200:
                return f"å¤©æ°”æŸ¥è¯¢å¤±è´¥: {response.text}"

            data = response.json()

            weather_desc = data["weather"][0]["description"]
            temp = data["main"]["temp"]
            feels_like = data["main"]["feels_like"]
            humidity = data["main"]["humidity"]
            wind_speed = data["wind"]["speed"]

            return (
                f"{city}å½“å‰å¤©æ°”:\n"
                f"- å¤©æ°”: {weather_desc}\n"
                f"- æ¸©åº¦: {temp}Â°C (ä½“æ„Ÿ {feels_like}Â°C)\n"
                f"- æ¹¿åº¦: {humidity}%\n"
                f"- é£é€Ÿ: {wind_speed} m/s"
            )

    def get_definition(self) -> Dict:
        """å·¥å…·å®šä¹‰"""
        return {
            "name": "weather",
            "description": "æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°(ä¸­æ–‡æˆ–è‹±æ–‡)"
                    },
                    "country": {
                        "type": "string",
                        "description": "å›½å®¶ä»£ç (å¦‚CN, US)",
                        "default": "CN"
                    }
                },
                "required": ["city"]
            }
        }


class CalculatorTool:
    """è®¡ç®—å™¨å·¥å…·"""

    async def execute(self, expression: str) -> str:
        """æ‰§è¡Œè®¡ç®—"""
        try:
            # å®‰å…¨çš„æ•°å­¦è¡¨è¾¾å¼æ±‚å€¼
            import ast
            import operator as op

            # æ”¯æŒçš„è¿ç®—ç¬¦
            operators = {
                ast.Add: op.add,
                ast.Sub: op.sub,
                ast.Mult: op.mul,
                ast.Div: op.truediv,
                ast.Pow: op.pow,
                ast.USub: op.neg,
            }

            def eval_expr(node):
                if isinstance(node, ast.Num):
                    return node.n
                elif isinstance(node, ast.BinOp):
                    return operators[type(node.op)](
                        eval_expr(node.left),
                        eval_expr(node.right)
                    )
                elif isinstance(node, ast.UnaryOp):
                    return operators[type(node.op)](eval_expr(node.operand))
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„è¡¨è¾¾å¼: {node}")

            node = ast.parse(expression, mode='eval')
            result = eval_expr(node.body)

            return f"{expression} = {result}"

        except Exception as e:
            return f"è®¡ç®—é”™è¯¯: {str(e)}"

    def get_definition(self) -> Dict:
        """å·¥å…·å®šä¹‰"""
        return {
            "name": "calculator",
            "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—ã€‚æ”¯æŒåŠ å‡ä¹˜é™¤å’Œå¹‚è¿ç®—ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ '2 + 3 * 4'"
                    }
                },
                "required": ["expression"]
            }
        }


# åŠ¨æ€å·¥å…·æ³¨å†Œç³»ç»Ÿ

class DynamicToolRegistry:
    """åŠ¨æ€å·¥å…·æ³¨å†Œè¡¨"""

    def __init__(self):
        self.tools: Dict[str, Any] = {}
        self._init_builtin_tools()

    def _init_builtin_tools(self):
        """åˆå§‹åŒ–å†…ç½®å·¥å…·"""
        self.register(SearchTool())
        self.register(KnowledgeBaseTool())
        self.register(WeatherTool())
        self.register(CalculatorTool())

    def register(self, tool_instance: Any):
        """æ³¨å†Œå·¥å…·"""
        definition = tool_instance.get_definition()
        tool_name = definition["name"]

        self.tools[tool_name] = {
            "instance": tool_instance,
            "definition": definition
        }

        print(f"âœ… å·¥å…·å·²æ³¨å†Œ: {tool_name}")

    def unregister(self, tool_name: str):
        """æ³¨é”€å·¥å…·"""
        if tool_name in self.tools:
            del self.tools[tool_name]
            print(f"âŒ å·¥å…·å·²æ³¨é”€: {tool_name}")

    async def execute_tool(
        self,
        tool_name: str,
        parameters: Dict[str, Any]
    ) -> str:
        """æ‰§è¡Œå·¥å…·"""
        if tool_name not in self.tools:
            raise ValueError(f"å·¥å…·ä¸å­˜åœ¨: {tool_name}")

        tool_instance = self.tools[tool_name]["instance"]
        return await tool_instance.execute(**parameters)

    def list_tools(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å·¥å…·"""
        return [
            tool["definition"]
            for tool in self.tools.values()
        ]

    def get_tool_definitions_for_llm(self) -> List[Dict]:
        """è·å–OpenAI function callingæ ¼å¼çš„å·¥å…·å®šä¹‰"""
        return [
            {
                "type": "function",
                "function": tool["definition"]
            }
            for tool in self.tools.values()
        ]


# æ›´æ–° main.py å¯åŠ¨ä»£ç 

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨"""
    print("ğŸš€ Agent Engine starting...")

    # åˆå§‹åŒ–åŠ¨æ€å·¥å…·æ³¨å†Œè¡¨
    app.state.tool_registry = DynamicToolRegistry()

    # å¯é€‰: ä»é…ç½®æ–‡ä»¶åŠ è½½è‡ªå®šä¹‰å·¥å…·
    # await load_custom_tools(app.state.tool_registry)

    print(f"âœ… Loaded {len(app.state.tool_registry.tools)} tools")
    print("âœ… Agent Engine started successfully")


# å·¥å…·APIç«¯ç‚¹

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

router = APIRouter(prefix="/api/v1/tools", tags=["Tools"])

class ToolExecuteRequest(BaseModel):
    tool_name: str
    parameters: Dict[str, Any]

class ToolExecuteResponse(BaseModel):
    result: str
    execution_time: float

@router.post("/execute", response_model=ToolExecuteResponse)
async def execute_tool(request: ToolExecuteRequest):
    """æ‰§è¡Œå·¥å…·"""
    import time

    start_time = time.time()

    try:
        result = await app.state.tool_registry.execute_tool(
            tool_name=request.tool_name,
            parameters=request.parameters
        )

        execution_time = time.time() - start_time

        return ToolExecuteResponse(
            result=result,
            execution_time=execution_time
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/list")
async def list_tools():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·"""
    return {
        "tools": app.state.tool_registry.list_tools(),
        "count": len(app.state.tool_registry.tools)
    }


@router.post("/register")
async def register_custom_tool(tool_definition: Dict):
    """æ³¨å†Œè‡ªå®šä¹‰å·¥å…· (é«˜çº§åŠŸèƒ½)"""
    # ä»å·¥å…·å®šä¹‰åŠ¨æ€åˆ›å»ºå·¥å…·å®ä¾‹
    # ç”Ÿäº§ç¯å¢ƒéœ€è¦ä¸¥æ ¼çš„å®‰å…¨éªŒè¯
    raise HTTPException(status_code=501, detail="Custom tool registration not implemented")
```

**ç¯å¢ƒå˜é‡**:

```bash
# .env

# å·¥å…·APIå¯†é’¥
SERPAPI_KEY=your_serpapi_key
OPENWEATHER_API_KEY=your_openweather_key

# æœåŠ¡åœ°å€
RAG_SERVICE_URL=http://rag-engine:8006
```

**éªŒæ”¶æ ‡å‡†**:

- [ ] æœç´¢å·¥å…·è¿”å›çœŸå®æœç´¢ç»“æœ
- [ ] çŸ¥è¯†åº“å·¥å…·æˆåŠŸè°ƒç”¨ RAG æœåŠ¡
- [ ] å¤©æ°”å·¥å…·è¿”å›å®æ—¶å¤©æ°”æ•°æ®
- [ ] è®¡ç®—å™¨å·¥å…·æ­£ç¡®è®¡ç®—è¡¨è¾¾å¼
- [ ] åŠ¨æ€å·¥å…·æ³¨å†Œ/æ³¨é”€åŠŸèƒ½æ­£å¸¸
- [ ] å·¥å…·æ‰§è¡Œå»¶è¿Ÿ < 5s

**å·¥ä½œé‡**: 3-4 å¤©

---

#### 3. Plan-Execute æ‰§è¡Œå™¨

**æ–‡ä»¶**: `app/core/executor/plan_execute_executor.py:97`

**é—®é¢˜æè¿°**:

```python
# TODO: å®é™…åº”è¯¥è§£ææ­¥éª¤ï¼Œè°ƒç”¨å·¥å…·
```

**å½±å“**: æ— æ³•å¤„ç†å¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡

**è¯¦ç»†è®¾è®¡æ–¹æ¡ˆ**:

````python
# app/core/executor/plan_execute_executor.py (å®Œæ•´å®ç°)

from typing import List, Dict, Any, Optional
from pydantic import BaseModel
import json
import asyncio

class ExecutionStep(BaseModel):
    """æ‰§è¡Œæ­¥éª¤"""
    step_id: int
    description: str
    tool_name: Optional[str] = None
    parameters: Optional[Dict[str, Any]] = None
    status: str = "pending"  # pending, running, completed, failed
    result: Optional[str] = None
    error: Optional[str] = None


class ExecutionPlan(BaseModel):
    """æ‰§è¡Œè®¡åˆ’"""
    task: str
    steps: List[ExecutionStep]
    status: str = "created"
    current_step: int = 0


class PlanExecuteExecutor:
    """Plan-and-Execute æ‰§è¡Œå™¨"""

    def __init__(
        self,
        llm_service,
        tool_registry,
        max_retries: int = 2
    ):
        self.llm_service = llm_service
        self.tool_registry = tool_registry
        self.max_retries = max_retries

    async def execute(
        self,
        task: str,
        context: Dict = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„Plan-Executeæµç¨‹"""

        # Phase 1: Planning - ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        plan = await self._generate_plan(task, context)

        # Phase 2: Execution - é€æ­¥æ‰§è¡Œ
        execution_log = []

        for i, step in enumerate(plan.steps):
            print(f"\nğŸ“‹ æ‰§è¡Œæ­¥éª¤ {i+1}/{len(plan.steps)}: {step.description}")

            step.status = "running"
            plan.current_step = i

            try:
                # æ‰§è¡Œæ­¥éª¤
                result = await self._execute_step(step, execution_log)

                step.status = "completed"
                step.result = result

                execution_log.append({
                    "step_id": step.step_id,
                    "description": step.description,
                    "result": result,
                    "status": "completed"
                })

                print(f"âœ… æ­¥éª¤å®Œæˆ: {result[:100]}...")

            except Exception as e:
                step.status = "failed"
                step.error = str(e)

                execution_log.append({
                    "step_id": step.step_id,
                    "description": step.description,
                    "error": str(e),
                    "status": "failed"
                })

                print(f"âŒ æ­¥éª¤å¤±è´¥: {str(e)}")

                # å°è¯•ä¿®å¤æˆ–è·³è¿‡
                retry_success = await self._handle_failure(step, execution_log)

                if not retry_success:
                    # è‡´å‘½å¤±è´¥ï¼Œä¸­æ­¢æ‰§è¡Œ
                    break

        # Phase 3: Synthesis - ç»¼åˆæœ€ç»ˆç­”æ¡ˆ
        final_answer = await self._synthesize_answer(task, execution_log)

        return {
            "task": task,
            "plan": plan.dict(),
            "execution_log": execution_log,
            "final_answer": final_answer,
            "status": "completed" if all(s.status == "completed" for s in plan.steps) else "partial"
        }

    async def _generate_plan(
        self,
        task: str,
        context: Dict = None
    ) -> ExecutionPlan:
        """ä½¿ç”¨LLMç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""

        # è·å–å¯ç”¨å·¥å…·
        tools = self.tool_registry.list_tools()
        tools_desc = "\n".join([
            f"- {tool['name']}: {tool['description']}"
            for tool in tools
        ])

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è§„åˆ’åŠ©æ‰‹ã€‚ç»™å®šä¸€ä¸ªä»»åŠ¡ï¼Œä½ éœ€è¦å°†å…¶åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„æ­¥éª¤ã€‚

å¯ç”¨å·¥å…·:
{tools_desc}

è¯·ç”Ÿæˆä¸€ä¸ªJSONæ ¼å¼çš„æ‰§è¡Œè®¡åˆ’ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
{{
    "steps": [
        {{
            "step_id": 1,
            "description": "æ­¥éª¤æè¿°",
            "tool_name": "å·¥å…·åç§°(å¯é€‰)",
            "parameters": {{"param1": "value1"}}
        }}
    ]
}}

è§„åˆ™:
1. æ¯ä¸ªæ­¥éª¤åº”è¯¥æ¸…æ™°ã€å¯æ‰§è¡Œ
2. å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·ï¼ŒæŒ‡å®štool_nameå’Œparameters
3. æ­¥éª¤ä¹‹é—´åº”è¯¥æœ‰é€»è¾‘é¡ºåº
4. æœ€åä¸€æ­¥é€šå¸¸æ˜¯ç»¼åˆæ‰€æœ‰ä¿¡æ¯å›ç­”é—®é¢˜
"""

        user_prompt = f"""ä»»åŠ¡: {task}

{f"ä¸Šä¸‹æ–‡: {context}" if context else ""}

è¯·ç”Ÿæˆæ‰§è¡Œè®¡åˆ’:"""

        # è°ƒç”¨LLM
        response = await self.llm_service.chat(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            model="gpt-4",
            temperature=0.1
        )

        # è§£æè®¡åˆ’
        try:
            plan_json = self._extract_json(response["choices"][0]["message"]["content"])
            steps = [ExecutionStep(**step) for step in plan_json["steps"]]

            return ExecutionPlan(task=task, steps=steps)

        except Exception as e:
            # å›é€€: ä½¿ç”¨é»˜è®¤å•æ­¥è®¡åˆ’
            print(f"âš ï¸  è®¡åˆ’è§£æå¤±è´¥ï¼Œä½¿ç”¨å›é€€è®¡åˆ’: {e}")
            return ExecutionPlan(
                task=task,
                steps=[
                    ExecutionStep(
                        step_id=1,
                        description=f"ç›´æ¥å›ç­”: {task}",
                        tool_name=None
                    )
                ]
            )

    async def _execute_step(
        self,
        step: ExecutionStep,
        execution_log: List[Dict]
    ) -> str:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""

        if step.tool_name:
            # å·¥å…·è°ƒç”¨
            return await self.tool_registry.execute_tool(
                tool_name=step.tool_name,
                parameters=step.parameters or {}
            )
        else:
            # LLMæ¨ç†
            return await self._llm_reasoning(step, execution_log)

    async def _llm_reasoning(
        self,
        step: ExecutionStep,
        execution_log: List[Dict]
    ) -> str:
        """ä½¿ç”¨LLMè¿›è¡Œæ¨ç†"""

        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n".join([
            f"æ­¥éª¤ {log['step_id']}: {log['description']}\nç»“æœ: {log.get('result', 'å¤±è´¥')}"
            for log in execution_log
        ])

        prompt = f"""åŸºäºä»¥ä¸‹å·²æ‰§è¡Œæ­¥éª¤çš„ç»“æœ:

{context}

è¯·æ‰§è¡Œ: {step.description}"""

        response = await self.llm_service.chat(
            messages=[{"role": "user", "content": prompt}],
            model="gpt-4",
            temperature=0.7
        )

        return response["choices"][0]["message"]["content"]

    async def _handle_failure(
        self,
        step: ExecutionStep,
        execution_log: List[Dict]
    ) -> bool:
        """å¤„ç†æ­¥éª¤å¤±è´¥"""

        if step.tool_name:
            # å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå°è¯•ç”¨LLMæ›¿ä»£
            print(f"ğŸ”„ å°è¯•ç”¨LLMæ›¿ä»£å·¥å…·: {step.tool_name}")

            try:
                result = await self._llm_reasoning(step, execution_log)
                step.status = "completed"
                step.result = result

                execution_log[-1]["status"] = "recovered"
                execution_log[-1]["result"] = result

                return True
            except Exception as e:
                print(f"âŒ æ¢å¤å¤±è´¥: {e}")
                return False

        return False

    async def _synthesize_answer(
        self,
        task: str,
        execution_log: List[Dict]
    ) -> str:
        """ç»¼åˆæœ€ç»ˆç­”æ¡ˆ"""

        context = "\n\n".join([
            f"æ­¥éª¤ {log['step_id']}: {log['description']}\n"
            f"çŠ¶æ€: {log['status']}\n"
            f"ç»“æœ: {log.get('result', log.get('error', 'æœªæ‰§è¡Œ'))}"
            for log in execution_log
        ])

        prompt = f"""åŸå§‹ä»»åŠ¡: {task}

æ‰§è¡Œè¿‡ç¨‹:
{context}

åŸºäºä»¥ä¸Šæ‰§è¡Œè¿‡ç¨‹ï¼Œè¯·ç»¼åˆç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚è¦æ±‚:
1. ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
2. æ•´åˆæ‰€æœ‰æ­¥éª¤çš„æœ‰æ•ˆä¿¡æ¯
3. å¦‚æœæœ‰æ­¥éª¤å¤±è´¥ï¼Œè¯´æ˜åŸå› ä½†ä¸å½±å“æ•´ä½“å›ç­”
4. ä¿æŒç®€æ´æ¸…æ™°"""

        response = await self.llm_service.chat(
            messages=[{"role": "user", "content": prompt}],
            model="gpt-4",
            temperature=0.7
        )

        return response["choices"][0]["message"]["content"]

    def _extract_json(self, text: str) -> Dict:
        """ä»æ–‡æœ¬ä¸­æå–JSON"""
        # å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(text)
        except:
            pass

        # å°è¯•æå–```json```ä»£ç å—
        import re
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))

        # å°è¯•æå–ç¬¬ä¸€ä¸ªJSONå¯¹è±¡
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(0))

        raise ValueError("æ— æ³•ä»å“åº”ä¸­æå–JSON")


# ç¤ºä¾‹ä½¿ç”¨

async def example_usage():
    """ç¤ºä¾‹: ä½¿ç”¨Plan-Executeæ‰§è¡Œå¤æ‚ä»»åŠ¡"""

    executor = PlanExecuteExecutor(
        llm_service=llm_service,
        tool_registry=tool_registry
    )

    task = "å¸®æˆ‘æŸ¥ä¸€ä¸‹æ˜å¤©åŒ—äº¬çš„å¤©æ°”ï¼Œå¹¶ä¸”æœç´¢ä¸€ä¸‹åŒ—äº¬æœ€è¿‘æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹"

    result = await executor.execute(task)

    print("\n" + "="*80)
    print("ğŸ“‹ æ‰§è¡Œè®¡åˆ’:")
    for step in result["plan"]["steps"]:
        print(f"  {step['step_id']}. {step['description']}")

    print("\n" + "="*80)
    print("ğŸ“ æ‰§è¡Œæ—¥å¿—:")
    for log in result["execution_log"]:
        print(f"  [{log['status']}] {log['description']}")
        if log.get('result'):
            print(f"    â†’ {log['result'][:100]}...")

    print("\n" + "="*80)
    print("ğŸ¯ æœ€ç»ˆç­”æ¡ˆ:")
    print(result["final_answer"])
````

**API é›†æˆ**:

```python
# app/routers/agent.py

@router.post("/execute/plan")
async def execute_with_plan(request: AgentTaskRequest):
    """ä½¿ç”¨Plan-Executeæ¨¡å¼æ‰§è¡Œä»»åŠ¡"""

    executor = PlanExecuteExecutor(
        llm_service=app.state.llm_service,
        tool_registry=app.state.tool_registry
    )

    result = await executor.execute(
        task=request.task,
        context=request.context
    )

    return result
```

**éªŒæ”¶æ ‡å‡†**:

- [ ] èƒ½æ­£ç¡®åˆ†è§£å¤æ‚ä»»åŠ¡
- [ ] æ­¥éª¤æŒ‰é¡ºåºæ­£ç¡®æ‰§è¡Œ
- [ ] æ­¥éª¤å¤±è´¥æ—¶èƒ½æ¢å¤æˆ–è·³è¿‡
- [ ] æœ€ç»ˆç­”æ¡ˆç»¼åˆæ‰€æœ‰ä¿¡æ¯
- [ ] æ‰§è¡Œæ—¥å¿—å®Œæ•´å¯è¿½æº¯

**å·¥ä½œé‡**: 3-4 å¤©

---

#### 4. æµå¼è¾“å‡º

**æ–‡ä»¶**: `app/workflows/react_agent.py:385`

**é—®é¢˜æè¿°**:

```python
# TODO: å®ç°æµå¼è¾“å‡º
```

**å½±å“**: æ— æ³•å®æ—¶æŸ¥çœ‹ Agent æ¨ç†è¿‡ç¨‹

**è¯¦ç»†è®¾è®¡æ–¹æ¡ˆ**:

```python
# app/services/agent_service.py

from typing import AsyncIterator
import json

class AgentService:

    async def execute_stream(
        self,
        task: AgentTask
    ) -> AsyncIterator[str]:
        """æµå¼æ‰§è¡ŒAgentä»»åŠ¡"""

        # åˆå§‹åŒ–
        yield self._format_sse({
            "type": "start",
            "task_id": task.task_id,
            "task": task.task
        })

        # ReActå¾ªç¯
        iteration = 0
        max_iterations = task.max_iterations or 10

        while iteration < max_iterations:
            iteration += 1

            # 1. Thought - æ€è€ƒ
            yield self._format_sse({
                "type": "thought",
                "iteration": iteration,
                "stage": "thinking"
            })

            thought_response = await self._llm_think(task, iteration)
            thought = self._extract_thought(thought_response)

            yield self._format_sse({
                "type": "thought",
                "iteration": iteration,
                "content": thought
            })

            # 2. åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ç»ˆç­”æ¡ˆ
            if self._is_final_answer(thought_response):
                final_answer = self._extract_final_answer(thought_response)

                yield self._format_sse({
                    "type": "final_answer",
                    "content": final_answer,
                    "iterations": iteration
                })

                yield self._format_sse({
                    "type": "complete",
                    "status": "success"
                })

                return

            # 3. Action - è¡ŒåŠ¨
            action = self._extract_action(thought_response)

            yield self._format_sse({
                "type": "action",
                "iteration": iteration,
                "tool_name": action["tool"],
                "parameters": action["input"]
            })

            # 4. Observation - è§‚å¯Ÿ
            try:
                observation = await self._execute_action(action)

                yield self._format_sse({
                    "type": "observation",
                    "iteration": iteration,
                    "content": observation
                })

            except Exception as e:
                yield self._format_sse({
                    "type": "error",
                    "iteration": iteration,
                    "error": str(e)
                })

                yield self._format_sse({
                    "type": "complete",
                    "status": "error"
                })

                return

        # è¶…æ—¶
        yield self._format_sse({
            "type": "timeout",
            "iterations": max_iterations
        })

        yield self._format_sse({
            "type": "complete",
            "status": "timeout"
        })

    def _format_sse(self, data: dict) -> str:
        """æ ¼å¼åŒ–SSEæ¶ˆæ¯"""
        return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

    # ... å…¶ä»–è¾…åŠ©æ–¹æ³•


# app/routers/agent.py

from fastapi.responses import StreamingResponse

@router.post("/execute/stream")
async def execute_agent_stream(request: AgentTaskRequest):
    """æµå¼æ‰§è¡ŒAgent (SSE)"""

    task = AgentTask(
        task_id=str(uuid.uuid4()),
        task=request.task,
        context=request.context,
        max_iterations=request.max_iterations
    )

    return StreamingResponse(
        agent_service.execute_stream(task),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨nginxç¼“å†²
        }
    )
```

**å‰ç«¯é›†æˆç¤ºä¾‹**:

```javascript
// React å‰ç«¯ç¤ºä¾‹

const useAgentStream = (task) => {
  const [events, setEvents] = useState([]);
  const [status, setStatus] = useState('idle');

  const execute = async () => {
    setStatus('running');
    setEvents([]);

    const response = await fetch('/api/v1/agent/execute/stream', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ task }),
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\n\n');

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = JSON.parse(line.slice(6));

          setEvents((prev) => [...prev, data]);

          if (data.type === 'complete') {
            setStatus(data.status);
          }
        }
      }
    }
  };

  return { events, status, execute };
};

// ä½¿ç”¨
function AgentDebugPanel() {
  const { events, status, execute } = useAgentStream();

  return (
    <div>
      <button onClick={() => execute('æŸ¥è¯¢æ˜å¤©åŒ—äº¬å¤©æ°”')}>æ‰§è¡Œ</button>

      <div className="timeline">
        {events.map((event, i) => (
          <div key={i} className={`event event-${event.type}`}>
            {event.type === 'thought' && <div>ğŸ’­ æ€è€ƒ: {event.content}</div>}
            {event.type === 'action' && <div>âš¡ è¡ŒåŠ¨: {event.tool_name}</div>}
            {event.type === 'observation' && <div>ğŸ‘ï¸ è§‚å¯Ÿ: {event.content}</div>}
            {event.type === 'final_answer' && <div>âœ… ç­”æ¡ˆ: {event.content}</div>}
          </div>
        ))}
      </div>
    </div>
  );
}
```

**éªŒæ”¶æ ‡å‡†**:

- [ ] SSE è¿æ¥ç¨³å®šä¸æ–­å¼€
- [ ] äº‹ä»¶å®æ—¶æ¨é€å»¶è¿Ÿ < 100ms
- [ ] æ‰€æœ‰äº‹ä»¶ç±»å‹æ­£ç¡®æ¨é€
- [ ] å‰ç«¯èƒ½æ­£ç¡®è§£æå’Œæ˜¾ç¤º
- [ ] é”™è¯¯åœºæ™¯èƒ½ä¼˜é›…å¤„ç†

**å·¥ä½œé‡**: 2-3 å¤©

---

#### 5. Agent è·¯ç”±é€»è¾‘

**æ–‡ä»¶**: `routers/agent.py:34,53`

**é—®é¢˜æè¿°**:

```python
# TODO: å®é™…å®ç°æœç´¢åŠŸèƒ½ï¼ˆè°ƒç”¨æœç´¢å¼•æ“APIï¼‰
# TODO: Implement agent execution logic using LangGraph
# TODO: Implement status retrieval
```

**å½±å“**: Agent è·¯ç”±å’ŒçŠ¶æ€æŸ¥è¯¢æœªå®ç°

**è¯¦ç»†è®¾è®¡æ–¹æ¡ˆ**:

```python
# routers/agent.py (å®Œæ•´å®ç°)

from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import Optional
import uuid
from datetime import datetime

router = APIRouter(prefix="/api/v1/agent", tags=["Agent"])

# ä»»åŠ¡å­˜å‚¨ (ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨Redis)
task_store = {}

@router.post("/execute", response_model=AgentResponse)
async def execute_agent(
    request: AgentExecuteRequest,
    background_tasks: BackgroundTasks
):
    """åŒæ­¥æ‰§è¡ŒAgentä»»åŠ¡"""

    task_id = str(uuid.uuid4())

    # åˆ›å»ºä»»åŠ¡è®°å½•
    task_store[task_id] = {
        "task_id": task_id,
        "status": "running",
        "created_at": datetime.now().isoformat(),
        "request": request.dict()
    }

    try:
        # æ ¹æ®ç­–ç•¥é€‰æ‹©æ‰§è¡Œå™¨
        if request.strategy == "react":
            executor = ReactExecutor(...)
        elif request.strategy == "plan_execute":
            executor = PlanExecuteExecutor(...)
        else:
            raise HTTPException(400, f"ä¸æ”¯æŒçš„ç­–ç•¥: {request.strategy}")

        # æ‰§è¡Œ
        result = await executor.execute(
            task=request.task,
            context=request.context
        )

        # æ›´æ–°ä»»åŠ¡è®°å½•
        task_store[task_id].update({
            "status": "completed",
            "result": result,
            "completed_at": datetime.now().isoformat()
        })

        return AgentResponse(
            task_id=task_id,
            status="completed",
            result=result["final_answer"],
            steps=result.get("execution_log", []),
            metadata={
                "strategy": request.strategy,
                "iterations": result.get("iterations", 0),
                "execution_time": result.get("execution_time", 0)
            }
        )

    except Exception as e:
        task_store[task_id].update({
            "status": "failed",
            "error": str(e),
            "failed_at": datetime.now().isoformat()
        })

        raise HTTPException(500, str(e))


@router.post("/execute-async")
async def execute_agent_async(
    request: AgentExecuteRequest,
    background_tasks: BackgroundTasks
):
    """å¼‚æ­¥æ‰§è¡ŒAgentä»»åŠ¡"""

    task_id = str(uuid.uuid4())

    # åˆ›å»ºä»»åŠ¡è®°å½•
    task_store[task_id] = {
        "task_id": task_id,
        "status": "queued",
        "created_at": datetime.now().isoformat(),
        "request": request.dict()
    }

    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(
        _execute_agent_background,
        task_id=task_id,
        request=request
    )

    return {
        "task_id": task_id,
        "status": "queued",
        "message": "ä»»åŠ¡å·²æäº¤ï¼Œè¯·ä½¿ç”¨task_idæŸ¥è¯¢ç»“æœ"
    }


async def _execute_agent_background(task_id: str, request: AgentExecuteRequest):
    """åå°æ‰§è¡ŒAgent"""

    task_store[task_id]["status"] = "running"
    task_store[task_id]["started_at"] = datetime.now().isoformat()

    try:
        # é€‰æ‹©æ‰§è¡Œå™¨
        if request.strategy == "react":
            executor = ReactExecutor(...)
        elif request.strategy == "plan_execute":
            executor = PlanExecuteExecutor(...)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç­–ç•¥: {request.strategy}")

        # æ‰§è¡Œ
        result = await executor.execute(
            task=request.task,
            context=request.context
        )

        # æ›´æ–°ç»“æœ
        task_store[task_id].update({
            "status": "completed",
            "result": result,
            "completed_at": datetime.now().isoformat()
        })

    except Exception as e:
        task_store[task_id].update({
            "status": "failed",
            "error": str(e),
            "failed_at": datetime.now().isoformat()
        })


@router.get("/task/{task_id}")
async def get_task_status(task_id: str):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""

    if task_id not in task_store:
        raise HTTPException(404, "ä»»åŠ¡ä¸å­˜åœ¨")

    task = task_store[task_id]

    response = {
        "task_id": task_id,
        "status": task["status"],
        "created_at": task["created_at"]
    }

    if task["status"] == "completed":
        response["result"] = task["result"]
        response["completed_at"] = task.get("completed_at")

    elif task["status"] == "failed":
        response["error"] = task.get("error")
        response["failed_at"] = task.get("failed_at")

    elif task["status"] == "running":
        response["started_at"] = task.get("started_at")
        # å¯é€‰: è¿”å›ä¸­é—´è¿›åº¦
        response["progress"] = task.get("progress", {})

    return response


@router.delete("/task/{task_id}")
async def cancel_task(task_id: str):
    """å–æ¶ˆä»»åŠ¡"""

    if task_id not in task_store:
        raise HTTPException(404, "ä»»åŠ¡ä¸å­˜åœ¨")

    task = task_store[task_id]

    if task["status"] in ["completed", "failed"]:
        raise HTTPException(400, "ä»»åŠ¡å·²ç»“æŸï¼Œæ— æ³•å–æ¶ˆ")

    # æ ‡è®°ä¸ºå–æ¶ˆ
    task_store[task_id]["status"] = "cancelled"
    task_store[task_id]["cancelled_at"] = datetime.now().isoformat()

    return {"message": "ä»»åŠ¡å·²å–æ¶ˆ"}


@router.get("/tasks")
async def list_tasks(
    status: Optional[str] = None,
    limit: int = 20,
    offset: int = 0
):
    """åˆ—å‡ºä»»åŠ¡"""

    tasks = list(task_store.values())

    # è¿‡æ»¤çŠ¶æ€
    if status:
        tasks = [t for t in tasks if t["status"] == status]

    # æ’åº (æœ€æ–°çš„åœ¨å‰)
    tasks.sort(key=lambda x: x["created_at"], reverse=True)

    # åˆ†é¡µ
    total = len(tasks)
    tasks = tasks[offset:offset+limit]

    return {
        "tasks": tasks,
        "total": total,
        "limit": limit,
        "offset": offset
    }
```

**Redis æŒä¹…åŒ–ç‰ˆæœ¬**:

```python
# app/infrastructure/task_store.py

import redis
import json
from typing import Dict, Optional, List
from datetime import datetime, timedelta

class RedisTaskStore:
    """åŸºäºRedisçš„ä»»åŠ¡å­˜å‚¨"""

    def __init__(self, redis_url: str = "redis://localhost:6379/0"):
        self.redis = redis.from_url(redis_url, decode_responses=True)
        self.ttl_days = 7  # ä»»åŠ¡ä¿ç•™7å¤©

    def save_task(self, task_id: str, task_data: Dict):
        """ä¿å­˜ä»»åŠ¡"""
        key = f"agent:task:{task_id}"

        self.redis.setex(
            key,
            timedelta(days=self.ttl_days),
            json.dumps(task_data, ensure_ascii=False)
        )

    def get_task(self, task_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡"""
        key = f"agent:task:{task_id}"
        data = self.redis.get(key)

        return json.loads(data) if data else None

    def update_task(self, task_id: str, updates: Dict):
        """æ›´æ–°ä»»åŠ¡"""
        task = self.get_task(task_id)
        if task:
            task.update(updates)
            self.save_task(task_id, task)

    def list_tasks(
        self,
        status: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """åˆ—å‡ºä»»åŠ¡"""
        # æ‰«ææ‰€æœ‰ä»»åŠ¡key
        keys = self.redis.keys("agent:task:*")

        tasks = []
        for key in keys:
            data = self.redis.get(key)
            if data:
                task = json.loads(data)
                if not status or task.get("status") == status:
                    tasks.append(task)

        # æ’åºå¹¶é™åˆ¶æ•°é‡
        tasks.sort(key=lambda x: x.get("created_at", ""), reverse=True)
        return tasks[:limit]

    def delete_task(self, task_id: str):
        """åˆ é™¤ä»»åŠ¡"""
        key = f"agent:task:{task_id}"
        self.redis.delete(key)


# åœ¨ main.py ä¸­åˆå§‹åŒ–

@app.on_event("startup")
async def startup_event():
    app.state.task_store = RedisTaskStore(
        redis_url=settings.REDIS_URL
    )
```

**éªŒæ”¶æ ‡å‡†**:

- [ ] åŒæ­¥æ‰§è¡Œè¿”å›å®Œæ•´ç»“æœ
- [ ] å¼‚æ­¥æ‰§è¡Œæ­£ç¡®å…¥é˜Ÿ
- [ ] ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢å‡†ç¡®
- [ ] ä»»åŠ¡åˆ—è¡¨åˆ†é¡µæ­£å¸¸
- [ ] ä»»åŠ¡å–æ¶ˆåŠŸèƒ½ç”Ÿæ•ˆ
- [ ] Redis æŒä¹…åŒ–ä¸ä¸¢æ•°æ®

**å·¥ä½œé‡**: 2-3 å¤©

---

### P1 çº§åˆ« (é‡è¦åŠŸèƒ½)

#### 6. LangGraph é«˜çº§å·¥ä½œæµ

**å»ºè®®æ–°å¢åŠŸèƒ½** (å‚è€ƒä¸šç•Œæœ€ä½³å®è·µ)

**åŠŸèƒ½æè¿°**: ä½¿ç”¨ LangGraph æ„å»ºæ›´å¤æ‚çš„ Agent å·¥ä½œæµ

**æŠ€æœ¯æ–¹æ¡ˆ**:

```python
# app/workflows/langgraph_workflow.py

from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated, Sequence
import operator

class AgentState(TypedDict):
    """Agent çŠ¶æ€"""
    messages: Annotated[Sequence[str], operator.add]
    task: str
    plan: dict
    current_step: int
    observations: list
    final_answer: str

def plan_node(state: AgentState):
    """è§„åˆ’èŠ‚ç‚¹"""
    # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
    plan = generate_plan(state["task"])
    return {"plan": plan, "current_step": 0}

def execute_node(state: AgentState):
    """æ‰§è¡ŒèŠ‚ç‚¹"""
    step = state["plan"]["steps"][state["current_step"]]
    observation = execute_step(step)

    return {
        "observations": state["observations"] + [observation],
        "current_step": state["current_step"] + 1
    }

def should_continue(state: AgentState):
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­"""
    if state["current_step"] >= len(state["plan"]["steps"]):
        return "synthesize"
    else:
        return "execute"

def synthesize_node(state: AgentState):
    """ç»¼åˆç­”æ¡ˆèŠ‚ç‚¹"""
    final_answer = synthesize_answer(
        task=state["task"],
        observations=state["observations"]
    )
    return {"final_answer": final_answer}

# æ„å»ºå›¾
workflow = StateGraph(AgentState)

workflow.add_node("plan", plan_node)
workflow.add_node("execute", execute_node)
workflow.add_node("synthesize", synthesize_node)

workflow.set_entry_point("plan")
workflow.add_edge("plan", "execute")
workflow.add_conditional_edges(
    "execute",
    should_continue,
    {
        "execute": "execute",
        "synthesize": "synthesize"
    }
)
workflow.add_edge("synthesize", END)

app_workflow = workflow.compile()
```

**å·¥ä½œé‡**: 4-5 å¤©

---

## ğŸ“ˆ åç»­è¿­ä»£è®¡åˆ’

### Sprint 1: æ ¸å¿ƒåŠŸèƒ½è¡¥å…¨ (Week 1-2)

#### ç›®æ ‡

å®Œæˆ P0 é˜»å¡æ€§åŠŸèƒ½ï¼Œä½¿ Agent å…·å¤‡å®é™…å¯ç”¨æ€§

#### ä»»åŠ¡æ¸…å•

| ä»»åŠ¡                | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | è´Ÿè´£äºº        | çŠ¶æ€      |
| ------------------- | ------ | ------ | ------------- | --------- |
| è®°å¿†ç³»ç»Ÿ - å‘é‡æ£€ç´¢ | P0     | 3-4 å¤© | AI Engineer 1 | ğŸ“ å¾…å¼€å§‹ |
| å·¥å…·æ³¨å†Œä¸å®ç°      | P0     | 3-4 å¤© | AI Engineer 2 | ğŸ“ å¾…å¼€å§‹ |
| Plan-Execute æ‰§è¡Œå™¨ | P0     | 3-4 å¤© | AI Engineer 1 | ğŸ“ å¾…å¼€å§‹ |

#### éªŒæ”¶æ ‡å‡†

- [ ] è®°å¿†ç³»ç»Ÿå¬å›ç‡ > 80%
- [ ] è‡³å°‘ 5 ä¸ªå®é™…å·¥å…·å¯ç”¨
- [ ] Plan-Execute èƒ½æ­£ç¡®åˆ†è§£ä»»åŠ¡

---

### Sprint 2: ç”¨æˆ·ä½“éªŒæå‡ (Week 3-4)

#### ç›®æ ‡

ä¼˜åŒ–äº¤äº’ä½“éªŒï¼Œå¢å¼ºå¯è§‚æµ‹æ€§

#### ä»»åŠ¡æ¸…å•

| ä»»åŠ¡             | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | è´Ÿè´£äºº           | çŠ¶æ€      |
| ---------------- | ------ | ------ | ---------------- | --------- |
| æµå¼è¾“å‡º         | P0     | 2-3 å¤© | Backend Engineer | ğŸ“ å¾…å¼€å§‹ |
| Agent è·¯ç”±é€»è¾‘   | P0     | 2-3 å¤© | Backend Engineer | ğŸ“ å¾…å¼€å§‹ |
| Redis ä»»åŠ¡æŒä¹…åŒ– | P1     | 2 å¤©   | Backend Engineer | ğŸ“ å¾…å¼€å§‹ |

#### éªŒæ”¶æ ‡å‡†

- [ ] SSE æµå¼è¾“å‡ºç¨³å®š
- [ ] ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢å‡†ç¡®
- [ ] Redis æŒä¹…åŒ–ä¸ä¸¢æ•°æ®

---

### Sprint 3: é«˜çº§èƒ½åŠ›å»ºè®¾ (Week 5-6)

#### ç›®æ ‡

å¢åŠ é«˜çº§æ¨ç†èƒ½åŠ›å’Œå·¥å…·ç”Ÿæ€

#### ä»»åŠ¡æ¸…å•

| ä»»åŠ¡               | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | è´Ÿè´£äºº          | çŠ¶æ€      |
| ------------------ | ------ | ------ | --------------- | --------- |
| LangGraph å·¥ä½œæµ   | P1     | 4-5 å¤© | AI Engineer 1   | ğŸ“ å¾…å¼€å§‹ |
| è‡ªå®šä¹‰å·¥å…·æ’ä»¶ç³»ç»Ÿ | P2     | 3 å¤©   | AI Engineer 2   | ğŸ“ å¾…å¼€å§‹ |
| å¤š Agent åä½œ      | P2     | 5-7 å¤© | AI Engineer 1+2 | ğŸ“ å¾…å¼€å§‹ |

#### éªŒæ”¶æ ‡å‡†

- [ ] LangGraph å·¥ä½œæµå¯æ­£å¸¸è¿è¡Œ
- [ ] æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰å·¥å…·æ³¨å†Œ
- [ ] å¤š Agent èƒ½ååŒå®Œæˆä»»åŠ¡

---

## ğŸ¯ ä¸šç•Œå¯¹æ¯”ä¸æœ€ä½³å®è·µ

### ä¸ LangChain/AutoGPT/BabyAGI å¯¹æ¯”

| åŠŸèƒ½           | å½“å‰å®ç°     | LangChain | AutoGPT   | æœ¬é¡¹ç›®ç›®æ ‡         |
| -------------- | ------------ | --------- | --------- | ------------------ |
| ReAct Agent    | âœ… å·²å®ç°    | âœ…        | âœ…        | âœ…                 |
| Plan & Execute | âš ï¸ éƒ¨åˆ†å®Œæˆ  | âœ…        | âœ…        | âœ… å®Œå–„            |
| å·¥å…·ç”Ÿæ€       | âš ï¸ 3 ä¸ª Mock | âœ… 50+    | âœ… 20+    | âœ… 10+ å®é™…å·¥å…·    |
| è®°å¿†ç³»ç»Ÿ       | âŒ Mock      | âœ… å‘é‡åŒ– | âœ… å‘é‡åŒ– | âœ… å‘é‡åŒ–+æ—¶é—´è¡°å‡ |
| æµå¼è¾“å‡º       | âŒ           | âœ…        | âŒ        | âœ…                 |
| å¤š Agent åä½œ  | âŒ           | âœ…        | âœ…        | âœ… (Sprint 3)      |
| è‡ªå­¦ä¹          | âŒ           | âš ï¸ éƒ¨åˆ†   | âœ…        | ğŸ“‹ è§„åˆ’ä¸­          |

### å€Ÿé‰´çš„æœ€ä½³å®è·µ

1. **LangChain**

   - å·¥å…·å®šä¹‰æ ‡å‡†åŒ– (OpenAI Function Calling æ ¼å¼)
   - è®°å¿†ç³»ç»Ÿè®¾è®¡ (çŸ­æœŸ + é•¿æœŸ)
   - Agent æ‰§è¡Œå™¨æŠ½è±¡

2. **AutoGPT**

   - Plan-and-Execute æ¨¡å¼
   - è‡ªä¸»ç›®æ ‡åˆ†è§£
   - æŒç»­è®°å¿†ç®¡ç†

3. **ChatDev/MetaGPT**
   - å¤š Agent åä½œæ¨¡å¼
   - è§’è‰²æ‰®æ¼”æœºåˆ¶

---

## ğŸ“Š æˆåŠŸæŒ‡æ ‡ (KPI)

| æŒ‡æ ‡         | å½“å‰     | ç›®æ ‡ (Sprint 1) | ç›®æ ‡ (Sprint 3) |
| ------------ | -------- | --------------- | --------------- |
| å·¥å…·æ•°é‡     | 3 (Mock) | 5+ (å®é™…)       | 10+ (å®é™…)      |
| è®°å¿†å¬å›ç‡   | N/A      | > 80%           | > 90%           |
| ä»»åŠ¡æˆåŠŸç‡   | ~40%     | > 70%           | > 85%           |
| å¹³å‡æ‰§è¡Œæ—¶é—´ | ~10s     | < 8s            | < 5s            |
| ç”¨æˆ·æ»¡æ„åº¦   | N/A      | > 4.0/5.0       | > 4.5/5.0       |

---

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æœ¬åœ°å¼€å‘

```bash
# 1. å®‰è£…ä¾èµ–
cd algo/agent-engine
pip install -r requirements.txt

# 2. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env å¡«å…¥ API Keys

# 3. å¯åŠ¨æœåŠ¡
uvicorn main:app --reload --port 8003

# 4. è®¿é—®æ–‡æ¡£
open http://localhost:8003/docs
```

### æµ‹è¯•

```bash
# å•å…ƒæµ‹è¯•
pytest tests/unit/ -v

# é›†æˆæµ‹è¯•
pytest tests/integration/ -v

# è¦†ç›–ç‡
pytest --cov=app tests/
```

### Docker éƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t agent-engine:v2.0 .

# è¿è¡Œå®¹å™¨
docker run -p 8003:8003 \
  -e OPENAI_API_KEY=$OPENAI_API_KEY \
  -e REDIS_URL=redis://redis:6379/0 \
  agent-engine:v2.0
```

---

## ğŸ“ ç›¸å…³æ–‡æ¡£

- [Agent Engine README](algo/agent-engine/README.md)
- [Agent Engine å®ç°æ€»ç»“](algo/agent-engine/IMPLEMENTATION_SUMMARY.md)
- [API æ–‡æ¡£](http://localhost:8003/docs)
- [æ¶æ„è®¾è®¡](docs/arch/agent-engine.md)

---

## ğŸ“ è”ç³»æ–¹å¼

- **è´Ÿè´£äºº**: AI Team Lead
- **å¼€å‘å›¢é˜Ÿ**: AI Engineer 1, AI Engineer 2
- **Slack**: #agent-engine-dev
- **Wiki**: [Agent Engine Wiki](link)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-10-27
**ä¸‹æ¬¡æ›´æ–°**: Sprint 1 ç»“æŸå (Week 2)
