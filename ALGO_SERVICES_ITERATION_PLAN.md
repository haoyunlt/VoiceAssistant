# ç®—æ³•æœåŠ¡è¿­ä»£è®¡åˆ’ï¼ˆPython Servicesï¼‰

> **ç‰ˆæœ¬**: v2.0  
> **ç”Ÿæˆæ—¥æœŸ**: 2025-10-27  
> **é€‚ç”¨æœåŠ¡**: Agent Engine, Voice Engine, RAG Engine, Retrieval Service, Model Adapter, Indexing Service, Multimodal Engine, Vector Store Adapter, Knowledge Service (Python)

---

## ğŸ“‹ ç›®å½•

- [1. Agent Engineï¼ˆAgentæ‰§è¡Œå¼•æ“ï¼‰](#1-agent-engine)
- [2. Voice Engineï¼ˆè¯­éŸ³å¼•æ“ï¼‰](#2-voice-engine)
- [3. RAG Engineï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆå¼•æ“ï¼‰](#3-rag-engine)
- [4. Retrieval Serviceï¼ˆæ£€ç´¢æœåŠ¡ï¼‰](#4-retrieval-service)
- [5. Model Adapterï¼ˆæ¨¡å‹é€‚é…å™¨ï¼‰](#5-model-adapter)
- [6. Indexing Serviceï¼ˆç´¢å¼•æœåŠ¡ï¼‰](#6-indexing-service)
- [7. Multimodal Engineï¼ˆå¤šæ¨¡æ€å¼•æ“ï¼‰](#7-multimodal-engine)
- [8. Vector Store Adapterï¼ˆå‘é‡å­˜å‚¨é€‚é…å™¨ï¼‰](#8-vector-store-adapter)
- [9. Knowledge Serviceï¼ˆçŸ¥è¯†æœåŠ¡-Pythonéƒ¨åˆ†ï¼‰](#9-knowledge-service)

---

## æ¦‚è¿°

æœ¬æ–‡æ¡£æ±‡æ€»äº†æ‰€æœ‰ç®—æ³•æœåŠ¡ï¼ˆPythonï¼‰çš„å½“å‰å®ç°çŠ¶æ€ã€å¾…å®ç°åŠŸèƒ½å’Œè¯¦ç»†çš„è¿­ä»£è®¡åˆ’ã€‚æ¯ä¸ªæœåŠ¡åŒ…å«ï¼š

- âœ… **å·²å®ç°åŠŸèƒ½æ¸…å•**
- ğŸ”„ **å¾…å®Œå–„åŠŸèƒ½**
- ğŸš€ **è¿­ä»£è®¡åˆ’**ï¼ˆåŒ…å«è®¾è®¡æ–¹æ¡ˆå’Œç¤ºä¾‹ä»£ç ï¼‰
- ğŸ“Š **æ€§èƒ½æŒ‡æ ‡å’ŒéªŒæ”¶æ ‡å‡†**

---

## 1. Agent Engine

### 1.1 å½“å‰å®ç°çŠ¶æ€

#### âœ… å·²å®ç°åŠŸèƒ½

| åŠŸèƒ½æ¨¡å— | å®ç°çŠ¶æ€ | è¯´æ˜ |
|---------|---------|------|
| ReAct Agentæ‰§è¡Œ | âœ… å®Œæˆ | Thought-Action-Observationå¾ªç¯ |
| å·¥å…·ç®¡ç†ç³»ç»Ÿ | âœ… å®Œæˆ | å†…ç½®è®¡ç®—å™¨ã€æœç´¢ã€çŸ¥è¯†åº“æŸ¥è¯¢ |
| LLMé›†æˆ | âœ… å®Œæˆ | OpenAI APIæ”¯æŒ |
| ä»»åŠ¡ç®¡ç† | âœ… å®Œæˆ | åŒæ­¥/å¼‚æ­¥æ‰§è¡Œã€çŠ¶æ€æŸ¥è¯¢ |
| Plan & Execute Agent | âœ… å®Œæˆ | è®¡åˆ’åˆ†è§£å’Œæ‰§è¡Œ |
| å·¥å…·è°ƒç”¨ç³»ç»Ÿ | âœ… å®Œæˆ | æœç´¢ã€è®¡ç®—å™¨ã€çŸ¥è¯†åº“ç­‰ |
| è®°å¿†ç³»ç»Ÿ | âœ… å®Œæˆ | å¯¹è¯å†å²ã€å·¥ä½œè®°å¿† |
| WebSocketæ”¯æŒ | âœ… å®Œæˆ | å®æ—¶äº¤äº’ |

#### ğŸ”„ å¾…å®Œå–„åŠŸèƒ½

| ä¼˜å…ˆçº§ | åŠŸèƒ½ | çŠ¶æ€ | é¢„è®¡å·¥ä½œé‡ |
|-------|------|------|-----------|
| P0 | æµå¼å“åº”ä¼˜åŒ– | æ¡†æ¶å·²æœ‰ | 2å¤© |
| P0 | å·¥å…·è°ƒç”¨å®¹é”™æœºåˆ¶ | éƒ¨åˆ†å®ç° | 3å¤© |
| P1 | å¤šAgentåä½œ | æœªå®ç° | 5å¤© |
| P1 | äººå·¥åé¦ˆå¾ªç¯ | æœªå®ç° | 4å¤© |
| P2 | Agentè®­ç»ƒå’Œä¼˜åŒ– | æœªå®ç° | 10å¤© |
| P2 | åˆ†å¸ƒå¼Agentæ‰§è¡Œ | æœªå®ç° | 7å¤© |

### 1.2 è¿­ä»£è®¡åˆ’

#### Sprint 1: æµå¼å“åº”å’Œå®¹é”™å¢å¼ºï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: å®Œå–„æµå¼å“åº”ï¼Œå¢åŠ å·¥å…·è°ƒç”¨å®¹é”™

**ä»»åŠ¡æ¸…å•**:

1. **æµå¼å“åº”ä¼˜åŒ–** (2å¤©)

```python
# File: app/services/agent_service.py

from typing import AsyncIterator
import asyncio

class AgentService:
    async def execute_stream(
        self,
        task: AgentTask
    ) -> AsyncIterator[AgentStepResult]:
        """æµå¼æ‰§è¡ŒAgentä»»åŠ¡ï¼Œå®æ—¶è¿”å›æ¯ä¸€æ­¥ç»“æœ"""
        
        # åˆå§‹åŒ–
        context = self._init_context(task)
        iteration = 0
        
        while iteration < task.max_iterations:
            # 1. Thoughté˜¶æ®µ - æµå¼è¿”å›
            thought_chunk = ""
            async for chunk in self.llm_service.chat_stream(
                messages=context.messages,
                model=task.model
            ):
                thought_chunk += chunk
                yield AgentStepResult(
                    step_type="thought",
                    content=chunk,
                    is_partial=True
                )
            
            # 2. è§£æAction
            action = self._parse_action(thought_chunk)
            if action is None:
                # æœ€ç»ˆç­”æ¡ˆ
                yield AgentStepResult(
                    step_type="final_answer",
                    content=thought_chunk,
                    is_partial=False
                )
                break
            
            yield AgentStepResult(
                step_type="action",
                tool_name=action.tool_name,
                parameters=action.parameters,
                is_partial=False
            )
            
            # 3. æ‰§è¡ŒToolï¼ˆå¸¦å®¹é”™ï¼‰
            try:
                observation = await self._execute_tool_with_retry(
                    tool_name=action.tool_name,
                    parameters=action.parameters
                )
            except ToolExecutionError as e:
                # é”™è¯¯ä½œä¸ºObservationè¿”å›
                observation = f"Error: {str(e)}"
            
            yield AgentStepResult(
                step_type="observation",
                content=observation,
                is_partial=False
            )
            
            # 4. æ›´æ–°ä¸Šä¸‹æ–‡
            context.add_step(thought_chunk, action, observation)
            iteration += 1
        
        yield AgentStepResult(
            step_type="completed",
            content=context.final_answer,
            is_partial=False
        )
```

2. **å·¥å…·è°ƒç”¨å®¹é”™æœºåˆ¶** (3å¤©)

```python
# File: app/services/tool_service.py

from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)

class ToolService:
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((TimeoutError, ConnectionError))
    )
    async def execute_tool(
        self,
        tool_name: str,
        parameters: Dict[str, Any],
        timeout: int = 30
    ) -> Any:
        """æ‰§è¡Œå·¥å…·ï¼Œå¸¦é‡è¯•å’Œè¶…æ—¶æ§åˆ¶"""
        
        # 1. éªŒè¯å·¥å…·å­˜åœ¨
        if tool_name not in self.tools:
            raise ToolNotFoundError(f"Tool '{tool_name}' not found")
        
        tool = self.tools[tool_name]
        
        # 2. å‚æ•°éªŒè¯
        try:
            validated_params = self._validate_parameters(tool, parameters)
        except ValidationError as e:
            raise ToolParameterError(f"Invalid parameters: {str(e)}")
        
        # 3. æ‰§è¡Œå·¥å…·ï¼ˆå¸¦è¶…æ—¶ï¼‰
        try:
            async with asyncio.timeout(timeout):
                result = await tool.function(**validated_params)
                return result
        except asyncio.TimeoutError:
            raise ToolTimeoutError(f"Tool '{tool_name}' timed out after {timeout}s")
        except Exception as e:
            # è®°å½•é”™è¯¯æ—¥å¿—
            logger.error(f"Tool '{tool_name}' execution failed: {str(e)}")
            raise ToolExecutionError(f"Tool execution failed: {str(e)}")
    
    async def _execute_tool_with_retry(
        self,
        tool_name: str,
        parameters: Dict[str, Any]
    ) -> str:
        """æ‰§è¡Œå·¥å…·ï¼Œå¤±è´¥æ—¶è¿”å›å‹å¥½é”™è¯¯ä¿¡æ¯"""
        try:
            result = await self.execute_tool(tool_name, parameters)
            return self._format_result(result)
        except ToolNotFoundError as e:
            return f"âŒ å·¥å…·ä¸å­˜åœ¨: {str(e)}"
        except ToolParameterError as e:
            return f"âŒ å‚æ•°é”™è¯¯: {str(e)}"
        except ToolTimeoutError as e:
            return f"â±ï¸ æ‰§è¡Œè¶…æ—¶: {str(e)}"
        except ToolExecutionError as e:
            return f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}"
```

#### Sprint 2: å¤šAgentåä½œï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: å®ç°å¤šAgentåä½œæ¨¡å¼

**è®¾è®¡æ–¹æ¡ˆ**:

```python
# File: app/models/multi_agent.py

from enum import Enum
from typing import List, Dict

class AgentRole(str, Enum):
    """Agentè§’è‰²"""
    COORDINATOR = "coordinator"  # åè°ƒå™¨
    RESEARCHER = "researcher"    # ç ”ç©¶å‘˜
    ANALYST = "analyst"          # åˆ†æå¸ˆ
    EXECUTOR = "executor"        # æ‰§è¡Œè€…

class MultiAgentTask(BaseModel):
    """å¤šAgentä»»åŠ¡"""
    task_id: str
    description: str
    agents: List[AgentConfig]  # å‚ä¸çš„Agenté…ç½®
    workflow: Dict[str, Any]   # å·¥ä½œæµå®šä¹‰
    max_rounds: int = 10       # æœ€å¤§åä½œè½®æ•°

class AgentConfig(BaseModel):
    """Agenté…ç½®"""
    agent_id: str
    role: AgentRole
    model: str
    tools: List[str]
    system_prompt: str

# File: app/services/multi_agent_service.py

class MultiAgentService:
    """å¤šAgentåä½œæœåŠ¡"""
    
    async def execute_multi_agent_task(
        self,
        task: MultiAgentTask
    ) -> MultiAgentResult:
        """æ‰§è¡Œå¤šAgentåä½œä»»åŠ¡"""
        
        # 1. åˆå§‹åŒ–æ‰€æœ‰Agent
        agents = {}
        for agent_config in task.agents:
            agents[agent_config.agent_id] = self._create_agent(agent_config)
        
        # 2. è·å–åè°ƒå™¨
        coordinator = agents.get("coordinator")
        if not coordinator:
            raise ValueError("Multi-agent task requires a coordinator")
        
        # 3. åä½œå¾ªç¯
        context = MultiAgentContext()
        for round_num in range(task.max_rounds):
            # åè°ƒå™¨å†³å®šä¸‹ä¸€æ­¥
            next_action = await coordinator.decide_next_action(context)
            
            if next_action.type == "complete":
                break
            
            # æ‰§è¡ŒAction
            if next_action.type == "delegate":
                # å§”æ´¾ç»™å…¶ä»–Agent
                target_agent = agents[next_action.target_agent_id]
                result = await target_agent.execute(next_action.subtask)
                context.add_result(next_action.target_agent_id, result)
            
            elif next_action.type == "synthesize":
                # åè°ƒå™¨ç»¼åˆç»“æœ
                final_answer = await coordinator.synthesize(context)
                return MultiAgentResult(
                    answer=final_answer,
                    steps=context.steps,
                    rounds=round_num + 1
                )
        
        return MultiAgentResult(
            answer=context.get_final_answer(),
            steps=context.steps,
            rounds=task.max_rounds
        )
```

**ç¤ºä¾‹å·¥ä½œæµ**:

```yaml
# å¤šAgentåä½œå·¥ä½œæµç¤ºä¾‹
workflow:
  name: "Research and Analysis"
  agents:
    - agent_id: coordinator
      role: coordinator
      model: gpt-4
      system_prompt: "You are a coordinator managing multiple specialized agents."
    
    - agent_id: researcher
      role: researcher
      model: gpt-3.5-turbo
      tools: [search, knowledge_base]
      system_prompt: "You are a researcher. Find relevant information."
    
    - agent_id: analyst
      role: analyst
      model: gpt-4
      tools: [calculator, data_analysis]
      system_prompt: "You are an analyst. Analyze data and provide insights."
  
  steps:
    - step: 1
      agent: coordinator
      action: "Break down the task into subtasks"
    
    - step: 2
      agent: researcher
      action: "Research each subtask"
    
    - step: 3
      agent: analyst
      action: "Analyze research results"
    
    - step: 4
      agent: coordinator
      action: "Synthesize final answer"
```

#### Sprint 3: äººå·¥åé¦ˆå¾ªç¯ï¼ˆRLHFï¼‰ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: å®ç°äººå·¥åé¦ˆå¾ªç¯ï¼ŒæŒç»­ä¼˜åŒ–Agentè¡¨ç°

```python
# File: app/services/feedback_service.py

from datetime import datetime

class FeedbackService:
    """äººå·¥åé¦ˆæœåŠ¡"""
    
    async def submit_feedback(
        self,
        task_id: str,
        user_id: str,
        rating: int,  # 1-5æ˜Ÿ
        feedback_text: Optional[str] = None,
        correct_answer: Optional[str] = None
    ) -> Feedback:
        """æäº¤äººå·¥åé¦ˆ"""
        
        feedback = Feedback(
            id=generate_id(),
            task_id=task_id,
            user_id=user_id,
            rating=rating,
            feedback_text=feedback_text,
            correct_answer=correct_answer,
            created_at=datetime.utcnow()
        )
        
        # 1. ä¿å­˜åé¦ˆåˆ°æ•°æ®åº“
        await self.feedback_repo.create(feedback)
        
        # 2. å¦‚æœè¯„åˆ†ä½ï¼Œæ ‡è®°ä¸ºéœ€è¦æ”¹è¿›
        if rating <= 2:
            await self._flag_for_improvement(task_id)
        
        # 3. å¦‚æœæä¾›äº†æ­£ç¡®ç­”æ¡ˆï¼Œåˆ›å»ºè®­ç»ƒæ ·æœ¬
        if correct_answer:
            await self._create_training_sample(task_id, correct_answer)
        
        return feedback
    
    async def get_improvement_candidates(
        self,
        limit: int = 100
    ) -> List[TaskFeedback]:
        """è·å–éœ€è¦æ”¹è¿›çš„ä»»åŠ¡"""
        
        # æŸ¥è¯¢ä½è¯„åˆ†ä»»åŠ¡
        return await self.feedback_repo.get_low_rated_tasks(
            rating_threshold=2,
            limit=limit
        )
    
    async def apply_learnings(
        self,
        task_id: str
    ):
        """åº”ç”¨åé¦ˆå­¦ä¹ æ”¹è¿›æç¤ºè¯"""
        
        # 1. è·å–ä»»åŠ¡å’Œåé¦ˆ
        task = await self.task_repo.get(task_id)
        feedbacks = await self.feedback_repo.get_by_task(task_id)
        
        # 2. åˆ†æå¤±è´¥åŸå› 
        analysis = await self._analyze_failure(task, feedbacks)
        
        # 3. ç”Ÿæˆæ”¹è¿›å»ºè®®
        improvements = await self._generate_improvements(analysis)
        
        # 4. æ›´æ–°æç¤ºè¯æ¨¡æ¿
        await self._update_prompt_template(task.type, improvements)
```

### 1.3 æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | éªŒæ”¶æ ‡å‡† |
|-----|--------|--------|----------|
| å¹³å‡æ‰§è¡Œæ—¶é—´ | ~5s | < 3s | P95 < 5s |
| å·¥å…·è°ƒç”¨æˆåŠŸç‡ | 90% | > 95% | é”™è¯¯ç‡ < 5% |
| å¹¶å‘æ”¯æŒ | æœªæµ‹è¯• | > 50 | 50å¹¶å‘æ— é™çº§ |
| æµå¼é¦–å­—èŠ‚å»¶è¿Ÿ | N/A | < 500ms | TTFB < 500ms |

---

## 2. Voice Engine

### 2.1 å½“å‰å®ç°çŠ¶æ€

#### âœ… å·²å®ç°åŠŸèƒ½

| åŠŸèƒ½æ¨¡å— | å®ç°çŠ¶æ€ | è¯´æ˜ |
|---------|---------|------|
| ASR - Faster Whisper | âœ… å®Œæˆ | æ‰¹é‡/æ–‡ä»¶ä¸Šä¼ è¯†åˆ« |
| ASR - Azure Speech | âœ… å®Œæˆ | é«˜ç²¾åº¦è¯†åˆ«ï¼Œè‡ªåŠ¨é™çº§ |
| TTS - Edge TTS | âœ… å®Œæˆ | æ‰¹é‡/æµå¼åˆæˆ |
| TTS - Azure Neural | âœ… å®Œæˆ | Neuralè¯­éŸ³åˆæˆ |
| VAD - Silero | âœ… å®Œæˆ | å®æ—¶è¯­éŸ³æ´»åŠ¨æ£€æµ‹ |
| æµå¼ASR | âœ… å®Œæˆ | WebSocketå®æ—¶è¯†åˆ« |
| æ™ºèƒ½ç¼“å­˜ | âœ… å®Œæˆ | TTSç»“æœç¼“å­˜ |

#### ğŸ”„ å¾…å®Œå–„åŠŸèƒ½

| ä¼˜å…ˆçº§ | åŠŸèƒ½ | çŠ¶æ€ | é¢„è®¡å·¥ä½œé‡ |
|-------|------|------|-----------|
| P0 | è¯´è¯äººåˆ†ç¦» | æœªå®ç° | 4å¤© |
| P1 | æƒ…æ„Ÿè¯†åˆ« | æœªå®ç° | 3å¤© |
| P1 | å™ªéŸ³æŠ‘åˆ¶ | æœªå®ç° | 3å¤© |
| P2 | å®æ—¶è¯­éŸ³ç¿»è¯‘ | æœªå®ç° | 5å¤© |
| P2 | å£°çº¹è¯†åˆ« | æœªå®ç° | 7å¤© |

### 2.2 è¿­ä»£è®¡åˆ’

#### Sprint 1: è¯´è¯äººåˆ†ç¦»ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: å®ç°å¤šè¯´è¯äººè¯†åˆ«å’Œåˆ†ç¦»

```python
# File: app/services/speaker_diarization_service.py

from pyannote.audio import Pipeline
import torch

class SpeakerDiarizationService:
    """è¯´è¯äººåˆ†ç¦»æœåŠ¡"""
    
    def __init__(self):
        # åŠ è½½pyannote.audioé¢„è®­ç»ƒæ¨¡å‹
        self.pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization",
            use_auth_token="YOUR_HF_TOKEN"
        )
    
    async def diarize(
        self,
        audio_data: bytes,
        num_speakers: Optional[int] = None
    ) -> DiarizationResult:
        """è¯´è¯äººåˆ†ç¦»"""
        
        # 1. ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        temp_path = f"/tmp/audio_{generate_id()}.wav"
        with open(temp_path, "wb") as f:
            f.write(audio_data)
        
        # 2. æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
        diarization = self.pipeline(
            temp_path,
            num_speakers=num_speakers
        )
        
        # 3. è§£æç»“æœ
        segments = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segments.append(SpeakerSegment(
                start_ms=turn.start * 1000,
                end_ms=turn.end * 1000,
                speaker_id=speaker,
                duration_ms=(turn.end - turn.start) * 1000
            ))
        
        # 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_path)
        
        return DiarizationResult(
            segments=segments,
            num_speakers=len(set(seg.speaker_id for seg in segments))
        )
    
    async def diarize_and_transcribe(
        self,
        audio_data: bytes,
        language: str = "zh"
    ) -> TranscriptWithSpeakers:
        """è¯´è¯äººåˆ†ç¦» + è¯­éŸ³è¯†åˆ«"""
        
        # 1. è¯´è¯äººåˆ†ç¦»
        diarization_result = await self.diarize(audio_data)
        
        # 2. ä¸ºæ¯ä¸ªç‰‡æ®µè¯†åˆ«
        transcripts = []
        for segment in diarization_result.segments:
            # æå–ç‰‡æ®µéŸ³é¢‘
            segment_audio = self._extract_audio_segment(
                audio_data,
                segment.start_ms,
                segment.end_ms
            )
            
            # ASRè¯†åˆ«
            asr_result = await self.asr_service.recognize_from_bytes(
                segment_audio,
                language=language
            )
            
            transcripts.append(SpeakerTranscript(
                speaker_id=segment.speaker_id,
                start_ms=segment.start_ms,
                end_ms=segment.end_ms,
                text=asr_result.text,
                confidence=asr_result.confidence
            ))
        
        return TranscriptWithSpeakers(
            transcripts=transcripts,
            num_speakers=diarization_result.num_speakers
        )
```

#### Sprint 2: æƒ…æ„Ÿè¯†åˆ«ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: è¯†åˆ«è¯­éŸ³æƒ…æ„Ÿï¼ˆæ„¤æ€’ã€æ‚²ä¼¤ã€é«˜å…´ç­‰ï¼‰

```python
# File: app/services/emotion_recognition_service.py

import librosa
import numpy as np
from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor

class EmotionRecognitionService:
    """æƒ…æ„Ÿè¯†åˆ«æœåŠ¡"""
    
    def __init__(self):
        # åŠ è½½é¢„è®­ç»ƒçš„æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹
        self.processor = Wav2Vec2Processor.from_pretrained(
            "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
        )
        self.model = Wav2Vec2ForSequenceClassification.from_pretrained(
            "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
        )
        
        self.emotions = ["angry", "calm", "disgust", "fearful", "happy", "neutral", "sad", "surprised"]
    
    async def recognize_emotion(
        self,
        audio_data: bytes,
        sample_rate: int = 16000
    ) -> EmotionResult:
        """è¯†åˆ«è¯­éŸ³æƒ…æ„Ÿ"""
        
        # 1. åŠ è½½éŸ³é¢‘
        audio, sr = librosa.load(
            io.BytesIO(audio_data),
            sr=sample_rate
        )
        
        # 2. é¢„å¤„ç†
        inputs = self.processor(
            audio,
            sampling_rate=sample_rate,
            return_tensors="pt",
            padding=True
        )
        
        # 3. æ¨¡å‹æ¨ç†
        with torch.no_grad():
            logits = self.model(**inputs).logits
            predictions = torch.nn.functional.softmax(logits, dim=-1)
        
        # 4. è§£æç»“æœ
        emotion_scores = {}
        for i, emotion in enumerate(self.emotions):
            emotion_scores[emotion] = float(predictions[0][i])
        
        # è·å–ä¸»è¦æƒ…æ„Ÿ
        primary_emotion = max(emotion_scores.items(), key=lambda x: x[1])
        
        return EmotionResult(
            primary_emotion=primary_emotion[0],
            confidence=primary_emotion[1],
            all_emotions=emotion_scores
        )
```

#### Sprint 3: å™ªéŸ³æŠ‘åˆ¶ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: å®æ—¶éŸ³é¢‘é™å™ª

```python
# File: app/services/noise_suppression_service.py

import noisereduce as nr
import soundfile as sf

class NoiseSuppressionService:
    """å™ªéŸ³æŠ‘åˆ¶æœåŠ¡"""
    
    async def reduce_noise(
        self,
        audio_data: bytes,
        sample_rate: int = 16000,
        stationary: bool = True
    ) -> bytes:
        """é™å™ªå¤„ç†"""
        
        # 1. åŠ è½½éŸ³é¢‘
        audio, sr = librosa.load(
            io.BytesIO(audio_data),
            sr=sample_rate
        )
        
        # 2. é™å™ª
        if stationary:
            # å¹³ç¨³å™ªéŸ³ï¼ˆå¦‚é£æ‰‡ã€ç©ºè°ƒï¼‰
            reduced_audio = nr.reduce_noise(
                y=audio,
                sr=sr,
                stationary=True,
                prop_decrease=1.0
            )
        else:
            # éå¹³ç¨³å™ªéŸ³ï¼ˆå¦‚çªå‘å£°éŸ³ï¼‰
            reduced_audio = nr.reduce_noise(
                y=audio,
                sr=sr,
                stationary=False,
                use_torch=True
            )
        
        # 3. è½¬æ¢å›bytes
        output_buffer = io.BytesIO()
        sf.write(output_buffer, reduced_audio, sr, format='WAV')
        output_buffer.seek(0)
        
        return output_buffer.read()
```

### 2.3 APIæ¥å£ç¤ºä¾‹

```python
# File: app/routers/voice_advanced.py

from fastapi import APIRouter, UploadFile, File

router = APIRouter(prefix="/api/v1/voice/advanced", tags=["Voice Advanced"])

@router.post("/diarize", response_model=DiarizationResult)
async def diarize_audio(
    file: UploadFile = File(...),
    num_speakers: Optional[int] = None
):
    """è¯´è¯äººåˆ†ç¦»"""
    audio_data = await file.read()
    return await speaker_diarization_service.diarize(
        audio_data,
        num_speakers=num_speakers
    )

@router.post("/diarize-and-transcribe", response_model=TranscriptWithSpeakers)
async def diarize_and_transcribe(
    file: UploadFile = File(...),
    language: str = "zh"
):
    """è¯´è¯äººåˆ†ç¦» + è¯­éŸ³è¯†åˆ«"""
    audio_data = await file.read()
    return await speaker_diarization_service.diarize_and_transcribe(
        audio_data,
        language=language
    )

@router.post("/emotion", response_model=EmotionResult)
async def recognize_emotion(
    file: UploadFile = File(...)
):
    """æƒ…æ„Ÿè¯†åˆ«"""
    audio_data = await file.read()
    return await emotion_recognition_service.recognize_emotion(audio_data)

@router.post("/denoise", response_model=AudioResponse)
async def reduce_noise(
    file: UploadFile = File(...),
    stationary: bool = True
):
    """é™å™ªå¤„ç†"""
    audio_data = await file.read()
    reduced_audio = await noise_suppression_service.reduce_noise(
        audio_data,
        stationary=stationary
    )
    
    return AudioResponse(
        audio_base64=base64.b64encode(reduced_audio).decode(),
        sample_rate=16000
    )
```

### 2.4 æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | éªŒæ”¶æ ‡å‡† |
|-----|--------|--------|----------|
| ASRå»¶è¿Ÿ | ~500ms | < 300ms | P95 < 500ms |
| TTSå»¶è¿Ÿ | ~800ms | < 500ms | P95 < 1s |
| è¯´è¯äººåˆ†ç¦»å‡†ç¡®ç‡ | N/A | > 85% | F1 > 0.85 |
| æƒ…æ„Ÿè¯†åˆ«å‡†ç¡®ç‡ | N/A | > 70% | Top-1 > 70% |

---

## 3. RAG Engine

### 3.1 å½“å‰å®ç°çŠ¶æ€

#### âœ… å·²å®ç°åŠŸèƒ½

| åŠŸèƒ½æ¨¡å— | å®ç°çŠ¶æ€ | è¯´æ˜ |
|---------|---------|------|
| å®Œæ•´RAGæµç¨‹ | âœ… å®Œæˆ | æ£€ç´¢â†’é‡æ’â†’ç”Ÿæˆ |
| æŸ¥è¯¢ç†è§£ | âœ… å®Œæˆ | æŸ¥è¯¢æ‰©å±•ã€å…³é”®è¯æå– |
| æ£€ç´¢å¢å¼º | âœ… å®Œæˆ | å¤šæŸ¥è¯¢èåˆã€å»é‡æ’åº |
| ä¸Šä¸‹æ–‡ç®¡ç† | âœ… å®Œæˆ | æ™ºèƒ½ç»„è£…ã€é•¿åº¦æ§åˆ¶ |
| ç”ŸæˆæœåŠ¡ | âœ… å®Œæˆ | æµå¼å“åº”æ”¯æŒ |

#### ğŸ”„ å¾…å®Œå–„åŠŸèƒ½

| ä¼˜å…ˆçº§ | åŠŸèƒ½ | çŠ¶æ€ | é¢„è®¡å·¥ä½œé‡ |
|-------|------|------|-----------|
| P0 | Cross-Encoderé‡æ’åº | éƒ¨åˆ†å®ç° | 2å¤© |
| P0 | è¯­ä¹‰ç¼“å­˜ | æœªå®ç° | 3å¤© |
| P1 | è‡ªé€‚åº”æ£€ç´¢ | æœªå®ç° | 4å¤© |
| P1 | æ··åˆæ£€ç´¢ï¼ˆBM25+å‘é‡ï¼‰ | æœªå®ç° | 3å¤© |
| P2 | å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ | æœªå®ç° | 5å¤© |
| P2 | ç­”æ¡ˆåå¤„ç† | æœªå®ç° | 2å¤© |

### 3.2 è¿­ä»£è®¡åˆ’

#### Sprint 1: Cross-Encoderé‡æ’åºå’Œè¯­ä¹‰ç¼“å­˜ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: å®Œå–„é‡æ’åºï¼Œå®ç°è¯­ä¹‰ç¼“å­˜

**1. Cross-Encoderé‡æ’åº**

```python
# File: app/services/rerank_service.py

from sentence_transformers import CrossEncoder

class RerankService:
    """é‡æ’åºæœåŠ¡"""
    
    def __init__(self):
        # åŠ è½½Cross-Encoderæ¨¡å‹
        self.cross_encoder = CrossEncoder(
            'cross-encoder/ms-marco-MiniLM-L-12-v2',
            max_length=512
        )
    
    async def rerank(
        self,
        query: str,
        documents: List[RetrievedDocument],
        top_k: int = 10
    ) -> List[RetrievedDocument]:
        """ä½¿ç”¨Cross-Encoderé‡æ’åº"""
        
        # 1. æ„å»ºquery-documentå¯¹
        pairs = [(query, doc.content) for doc in documents]
        
        # 2. è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        scores = self.cross_encoder.predict(pairs)
        
        # 3. æŒ‰åˆ†æ•°æ’åº
        for doc, score in zip(documents, scores):
            doc.rerank_score = float(score)
        
        documents_sorted = sorted(
            documents,
            key=lambda x: x.rerank_score,
            reverse=True
        )
        
        return documents_sorted[:top_k]
```

**2. è¯­ä¹‰ç¼“å­˜**

```python
# File: app/services/semantic_cache_service.py

import redis
from sentence_transformers import SentenceTransformer

class SemanticCacheService:
    """è¯­ä¹‰ç¼“å­˜æœåŠ¡"""
    
    def __init__(self):
        self.redis_client = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            decode_responses=True
        )
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.similarity_threshold = 0.9  # ç›¸ä¼¼åº¦é˜ˆå€¼
    
    async def get_cached_answer(
        self,
        query: str
    ) -> Optional[CachedAnswer]:
        """è·å–ç¼“å­˜çš„ç­”æ¡ˆ"""
        
        # 1. æŸ¥è¯¢embedding
        query_embedding = self.embedding_model.encode(query)
        
        # 2. ä»Redisè·å–æ‰€æœ‰ç¼“å­˜çš„æŸ¥è¯¢
        cached_queries = self._get_all_cached_queries()
        
        # 3. è®¡ç®—ç›¸ä¼¼åº¦
        for cached_query in cached_queries:
            similarity = self._cosine_similarity(
                query_embedding,
                cached_query.embedding
            )
            
            if similarity >= self.similarity_threshold:
                # å‘½ä¸­ç¼“å­˜
                cached_answer = self.redis_client.get(
                    f"semantic_cache:{cached_query.id}"
                )
                return CachedAnswer(
                    answer=cached_answer,
                    similarity=similarity,
                    original_query=cached_query.query
                )
        
        return None
    
    async def set_cached_answer(
        self,
        query: str,
        answer: str,
        ttl: int = 3600
    ):
        """è®¾ç½®ç¼“å­˜ç­”æ¡ˆ"""
        
        # 1. è®¡ç®—query embedding
        query_embedding = self.embedding_model.encode(query)
        
        # 2. ç”Ÿæˆç¼“å­˜ID
        cache_id = hashlib.md5(query.encode()).hexdigest()
        
        # 3. ä¿å­˜åˆ°Redis
        self.redis_client.setex(
            f"semantic_cache:{cache_id}",
            ttl,
            answer
        )
        
        # 4. ä¿å­˜queryå’Œembedding
        self.redis_client.setex(
            f"semantic_cache:query:{cache_id}",
            ttl,
            json.dumps({
                "query": query,
                "embedding": query_embedding.tolist()
            })
        )
```

**é›†æˆåˆ°RAGæµç¨‹**:

```python
# File: app/services/rag_service.py

class RAGService:
    async def generate(
        self,
        request: RAGRequest
    ) -> RAGResponse:
        """RAGç”Ÿæˆï¼ˆå¸¦è¯­ä¹‰ç¼“å­˜ï¼‰"""
        
        # 1. æ£€æŸ¥è¯­ä¹‰ç¼“å­˜
        cached_answer = await self.semantic_cache.get_cached_answer(request.query)
        if cached_answer:
            return RAGResponse(
                query=request.query,
                answer=cached_answer.answer,
                sources=[],
                from_cache=True,
                cache_similarity=cached_answer.similarity
            )
        
        # 2. æŸ¥è¯¢æ‰©å±•
        if request.enable_query_expansion:
            expanded_queries = await self.query_service.expand_query(
                request.query,
                num_expansions=2
            )
        else:
            expanded_queries = [request.query]
        
        # 3. æ£€ç´¢
        all_documents = []
        for query in expanded_queries:
            docs = await self.retrieval_client.search(
                query=query,
                tenant_id=request.tenant_id,
                knowledge_base_id=request.knowledge_base_id,
                top_k=request.top_k
            )
            all_documents.extend(docs)
        
        # 4. å»é‡å’Œæ’åº
        unique_documents = self._deduplicate(all_documents)
        
        # 5. é‡æ’åº
        if request.enable_rerank:
            reranked_documents = await self.rerank_service.rerank(
                query=request.query,
                documents=unique_documents,
                top_k=request.rerank_top_k
            )
        else:
            reranked_documents = unique_documents[:request.top_k]
        
        # 6. æ„å»ºä¸Šä¸‹æ–‡
        context = await self.context_service.build_context(
            documents=reranked_documents,
            max_length=4000
        )
        
        # 7. ç”Ÿæˆç­”æ¡ˆ
        answer = await self.generator_service.generate(
            query=request.query,
            context=context,
            history=request.history,
            model=request.model
        )
        
        # 8. ç¼“å­˜ç­”æ¡ˆ
        await self.semantic_cache.set_cached_answer(
            query=request.query,
            answer=answer,
            ttl=3600
        )
        
        return RAGResponse(
            query=request.query,
            answer=answer,
            sources=reranked_documents,
            from_cache=False
        )
```

#### Sprint 2: è‡ªé€‚åº”æ£€ç´¢å’Œæ··åˆæ£€ç´¢ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: æ ¹æ®æŸ¥è¯¢éš¾åº¦è‡ªé€‚åº”è°ƒæ•´æ£€ç´¢ç­–ç•¥ï¼Œå®ç°æ··åˆæ£€ç´¢

```python
# File: app/services/adaptive_retrieval_service.py

class AdaptiveRetrievalService:
    """è‡ªé€‚åº”æ£€ç´¢æœåŠ¡"""
    
    async def adaptive_search(
        self,
        query: str,
        tenant_id: str,
        knowledge_base_id: str
    ) -> List[RetrievedDocument]:
        """è‡ªé€‚åº”æ£€ç´¢"""
        
        # 1. åˆ†ææŸ¥è¯¢å¤æ‚åº¦
        complexity = await self._analyze_query_complexity(query)
        
        # 2. æ ¹æ®å¤æ‚åº¦é€‰æ‹©ç­–ç•¥
        if complexity.level == "simple":
            # ç®€å•æŸ¥è¯¢ï¼šä»…å‘é‡æ£€ç´¢ï¼Œtop 5
            documents = await self.vector_search(query, top_k=5)
        
        elif complexity.level == "medium":
            # ä¸­ç­‰æŸ¥è¯¢ï¼šæ··åˆæ£€ç´¢ï¼Œtop 10
            documents = await self.hybrid_search(query, top_k=10)
        
        else:  # complex
            # å¤æ‚æŸ¥è¯¢ï¼šæ··åˆæ£€ç´¢ + æŸ¥è¯¢æ‰©å±• + é‡æ’åºï¼Œtop 20
            expanded_queries = await self.expand_query(query)
            all_docs = []
            for q in expanded_queries:
                docs = await self.hybrid_search(q, top_k=10)
                all_docs.extend(docs)
            
            # å»é‡
            unique_docs = self._deduplicate(all_docs)
            
            # é‡æ’åº
            documents = await self.rerank(query, unique_docs, top_k=20)
        
        return documents
    
    async def _analyze_query_complexity(
        self,
        query: str
    ) -> QueryComplexity:
        """åˆ†ææŸ¥è¯¢å¤æ‚åº¦"""
        
        # å¯å‘å¼è§„åˆ™
        factors = {
            "length": len(query.split()),
            "has_numbers": bool(re.search(r'\d', query)),
            "has_comparison": any(w in query for w in ["æ¯”è¾ƒ", "å¯¹æ¯”", "åŒºåˆ«"]),
            "has_aggregation": any(w in query for w in ["æ€»ç»“", "æ±‡æ€»", "ç»Ÿè®¡"]),
            "has_temporal": any(w in query for w in ["æœ€è¿‘", "æœ€æ–°", "å†å²"])
        }
        
        # è®¡ç®—å¤æ‚åº¦åˆ†æ•°
        score = 0
        if factors["length"] > 20:
            score += 2
        if factors["has_comparison"]:
            score += 2
        if factors["has_aggregation"]:
            score += 3
        if factors["has_temporal"]:
            score += 1
        
        # åˆ¤æ–­çº§åˆ«
        if score <= 2:
            level = "simple"
        elif score <= 5:
            level = "medium"
        else:
            level = "complex"
        
        return QueryComplexity(level=level, score=score, factors=factors)
```

**æ··åˆæ£€ç´¢å®ç°**:

```python
# File: app/services/hybrid_search_service.py

class HybridSearchService:
    """æ··åˆæ£€ç´¢æœåŠ¡ï¼ˆå‘é‡ + BM25ï¼‰"""
    
    async def hybrid_search(
        self,
        query: str,
        tenant_id: str,
        knowledge_base_id: str,
        top_k: int = 10,
        alpha: float = 0.5  # å‘é‡æƒé‡
    ) -> List[RetrievedDocument]:
        """æ··åˆæ£€ç´¢"""
        
        # 1. å¹¶è¡Œæ‰§è¡Œå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢
        vector_task = self._vector_search(query, top_k=top_k * 2)
        bm25_task = self._bm25_search(query, top_k=top_k * 2)
        
        vector_docs, bm25_docs = await asyncio.gather(vector_task, bm25_task)
        
        # 2. å½’ä¸€åŒ–åˆ†æ•°
        vector_docs = self._normalize_scores(vector_docs)
        bm25_docs = self._normalize_scores(bm25_docs)
        
        # 3. èåˆåˆ†æ•°
        doc_scores = {}
        for doc in vector_docs:
            doc_scores[doc.chunk_id] = {
                "doc": doc,
                "vector_score": doc.score,
                "bm25_score": 0.0
            }
        
        for doc in bm25_docs:
            if doc.chunk_id in doc_scores:
                doc_scores[doc.chunk_id]["bm25_score"] = doc.score
            else:
                doc_scores[doc.chunk_id] = {
                    "doc": doc,
                    "vector_score": 0.0,
                    "bm25_score": doc.score
                }
        
        # 4. è®¡ç®—æ··åˆåˆ†æ•°
        for chunk_id, scores in doc_scores.items():
            hybrid_score = (
                alpha * scores["vector_score"] +
                (1 - alpha) * scores["bm25_score"]
            )
            scores["doc"].score = hybrid_score
        
        # 5. æŒ‰æ··åˆåˆ†æ•°æ’åº
        hybrid_docs = [s["doc"] for s in doc_scores.values()]
        hybrid_docs_sorted = sorted(
            hybrid_docs,
            key=lambda x: x.score,
            reverse=True
        )
        
        return hybrid_docs_sorted[:top_k]
```

### 3.3 æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | éªŒæ”¶æ ‡å‡† |
|-----|--------|--------|----------|
| ç«¯åˆ°ç«¯å»¶è¿Ÿ | ~2.5s | < 2s | P95 < 3s |
| æ£€ç´¢å¬å›ç‡ | 90% | > 95% | MRR > 0.9 |
| ç­”æ¡ˆå‡†ç¡®ç‡ | 85% | > 90% | F1 > 0.9 |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | > 30% | å‡å°‘30%è¯·æ±‚ |

---

## 4. Retrieval Service

### 4.1 å½“å‰å®ç°çŠ¶æ€

#### âœ… å·²å®ç°åŠŸèƒ½

| åŠŸèƒ½æ¨¡å— | å®ç°çŠ¶æ€ | è¯´æ˜ |
|---------|---------|------|
| å‘é‡æ£€ç´¢ | âœ… å®Œæˆ | Milvus HNSWç´¢å¼• |
| BM25æ£€ç´¢ | âœ… å®Œæˆ | Elasticsearchå…¨æ–‡æ£€ç´¢ |
| RRFèåˆ | âœ… å®Œæˆ | Reciprocal Rank Fusion |
| Cross-Encoderé‡æ’ | âœ… å®Œæˆ | MiniLM-L-12-v2 |
| å¤šç§Ÿæˆ·éš”ç¦» | âœ… å®Œæˆ | tenant_idè¿‡æ»¤ |

#### ğŸ”„ å¾…å®Œå–„åŠŸèƒ½

| ä¼˜å…ˆçº§ | åŠŸèƒ½ | çŠ¶æ€ | é¢„è®¡å·¥ä½œé‡ |
|-------|------|------|-----------|
| P0 | é›†æˆEmbeddingæœåŠ¡ | æœªå®ç° | 2å¤© |
| P1 | æŸ¥è¯¢æ”¹å†™ | æœªå®ç° | 3å¤© |
| P1 | ä¸ªæ€§åŒ–æ£€ç´¢ | æœªå®ç° | 5å¤© |
| P2 | å¤šæ¨¡æ€æ£€ç´¢ | æœªå®ç° | 7å¤© |

### 4.2 è¿­ä»£è®¡åˆ’

#### Sprint 1: é›†æˆEmbeddingæœåŠ¡ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: è‡ªåŠ¨è·å–æŸ¥è¯¢å‘é‡ï¼Œæ— éœ€è°ƒç”¨æ–¹æä¾›

```python
# File: app/services/embedding_service.py

from sentence_transformers import SentenceTransformer

class EmbeddingService:
    """EmbeddingæœåŠ¡"""
    
    def __init__(self):
        # åŠ è½½BGE-M3æ¨¡å‹ï¼ˆä¸­æ–‡ä¼˜åŒ–ï¼‰
        self.model = SentenceTransformer('BAAI/bge-m3')
    
    async def embed_query(
        self,
        query: str
    ) -> List[float]:
        """æŸ¥è¯¢å‘é‡åŒ–"""
        
        # æ·»åŠ æŸ¥è¯¢æŒ‡ä»¤
        query_with_instruction = f"Represent this sentence for searching relevant passages: {query}"
        
        embedding = self.model.encode(
            query_with_instruction,
            normalize_embeddings=True
        )
        
        return embedding.tolist()
    
    async def embed_batch(
        self,
        texts: List[str],
        is_query: bool = False
    ) -> List[List[float]]:
        """æ‰¹é‡å‘é‡åŒ–"""
        
        if is_query:
            texts = [f"Represent this sentence for searching relevant passages: {t}" for t in texts]
        
        embeddings = self.model.encode(
            texts,
            normalize_embeddings=True,
            batch_size=32
        )
        
        return embeddings.tolist()

# é›†æˆåˆ°æ£€ç´¢æœåŠ¡
class RetrievalService:
    async def vector_search(
        self,
        request: VectorSearchRequest
    ) -> List[RetrievedDocument]:
        """å‘é‡æ£€ç´¢ï¼ˆè‡ªåŠ¨Embeddingï¼‰"""
        
        # 1. å¦‚æœæ²¡æœ‰æä¾›embeddingï¼Œè‡ªåŠ¨ç”Ÿæˆ
        if request.query_embedding is None:
            query_embedding = await self.embedding_service.embed_query(request.query)
        else:
            query_embedding = request.query_embedding
        
        # 2. è°ƒç”¨Milvusæ£€ç´¢
        documents = await self.vector_service.search(
            collection_name=request.collection_name,
            query_vector=query_embedding,
            top_k=request.top_k,
            filters=request.filters
        )
        
        return documents
```

#### Sprint 2: æŸ¥è¯¢æ”¹å†™ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: è‡ªåŠ¨ä¼˜åŒ–æŸ¥è¯¢ï¼Œæå‡æ£€ç´¢æ•ˆæœ

```python
# File: app/services/query_rewriter_service.py

class QueryRewriterService:
    """æŸ¥è¯¢æ”¹å†™æœåŠ¡"""
    
    async def rewrite_query(
        self,
        query: str,
        context: Optional[List[str]] = None
    ) -> RewrittenQuery:
        """æŸ¥è¯¢æ”¹å†™"""
        
        # æ„å»ºæ”¹å†™æç¤ºè¯
        prompt = self._build_rewrite_prompt(query, context)
        
        # è°ƒç”¨LLMæ”¹å†™
        response = await self.llm_service.chat(
            messages=[
                {"role": "system", "content": "You are a query rewriter that improves search queries."},
                {"role": "user", "content": prompt}
            ],
            model="gpt-3.5-turbo",
            temperature=0.3
        )
        
        rewritten = response["choices"][0]["message"]["content"]
        
        return RewrittenQuery(
            original=query,
            rewritten=rewritten
        )
    
    def _build_rewrite_prompt(
        self,
        query: str,
        context: Optional[List[str]]
    ) -> str:
        """æ„å»ºæ”¹å†™æç¤ºè¯"""
        
        prompt = f"""è¯·æ”¹å†™ä»¥ä¸‹æŸ¥è¯¢ï¼Œä½¿å…¶æ›´é€‚åˆè¯­ä¹‰æ£€ç´¢ï¼š

åŸå§‹æŸ¥è¯¢: {query}
"""
        
        if context:
            prompt += f"\nå¯¹è¯ä¸Šä¸‹æ–‡:\n" + "\n".join(context)
        
        prompt += """

æ”¹å†™è¦æ±‚ï¼š
1. è¡¥å…¨ç¼ºå¤±çš„ä¸»è¯­æˆ–å®¾è¯­
2. å°†å£è¯­åŒ–è¡¨è¾¾è½¬ä¸ºä¹¦é¢è¯­
3. æ˜ç¡®æŸ¥è¯¢æ„å›¾
4. ä¿ç•™å…³é”®ä¿¡æ¯

æ”¹å†™åçš„æŸ¥è¯¢ï¼š"""
        
        return prompt
```

---

## 5. Model Adapter

### 5.1 å½“å‰å®ç°çŠ¶æ€

#### âœ… å·²å®ç°åŠŸèƒ½

| åŠŸèƒ½æ¨¡å— | å®ç°çŠ¶æ€ | è¯´æ˜ |
|---------|---------|------|
| å¤šæä¾›å•†æ”¯æŒ | âœ… å®Œæˆ | OpenAIã€Anthropicã€Azureç­‰ |
| ç»Ÿä¸€æ¥å£ | âœ… å®Œæˆ | Chatã€Completionã€Embedding |
| è‡ªåŠ¨è·¯ç”± | âœ… å®Œæˆ | æ ¹æ®æ¨¡å‹åç§°é€‰æ‹©æä¾›å•† |
| æµå¼æ”¯æŒ | âœ… å®Œæˆ | SSEæµå¼å“åº” |

#### ğŸ”„ å¾…å®Œå–„åŠŸèƒ½

| ä¼˜å…ˆçº§ | åŠŸèƒ½ | çŠ¶æ€ | é¢„è®¡å·¥ä½œé‡ |
|-------|------|------|-----------|
| P0 | å›½äº§æ¨¡å‹å®Œå–„ | éƒ¨åˆ†å®ç° | 3å¤© |
| P0 | è¯·æ±‚ç¼“å­˜ | æœªå®ç° | 2å¤© |
| P1 | é‡è¯•æœºåˆ¶ | æœªå®ç° | 2å¤© |
| P1 | æ™ºèƒ½é™çº§ | æœªå®ç° | 3å¤© |
| P2 | æˆæœ¬ä¼˜åŒ–è·¯ç”± | æœªå®ç° | 4å¤© |

### 5.2 è¿­ä»£è®¡åˆ’

#### Sprint 1: å›½äº§æ¨¡å‹å®Œå–„å’Œè¯·æ±‚ç¼“å­˜ï¼ˆ1å‘¨ï¼‰

**1. æ™ºè°±AIé€‚é…å™¨å®Œå–„**

```python
# File: app/adapters/zhipu_adapter.py

class ZhipuAdapter(BaseAdapter):
    """æ™ºè°±AIé€‚é…å™¨"""
    
    async def chat(
        self,
        request: ChatRequest
    ) -> ChatResponse:
        """æ™ºè°±GLM-4èŠå¤©"""
        
        # 1. è½¬æ¢æ¶ˆæ¯æ ¼å¼
        zhipu_messages = self._convert_messages(request.messages)
        
        # 2. æ„å»ºè¯·æ±‚
        payload = {
            "model": request.model,
            "messages": zhipu_messages,
            "temperature": request.temperature,
            "max_tokens": request.max_tokens,
            "stream": request.stream
        }
        
        # 3. è°ƒç”¨æ™ºè°±API
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://open.bigmodel.cn/api/paas/v4/chat/completions",
                json=payload,
                headers={
                    "Authorization": f"Bearer {settings.ZHIPU_API_KEY}",
                    "Content-Type": "application/json"
                },
                timeout=60.0
            )
            response.raise_for_status()
            result = response.json()
        
        # 4. è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
        return ChatResponse(
            id=result["id"],
            model=result["model"],
            provider="zhipu",
            choices=[
                Choice(
                    index=0,
                    message=Message(
                        role="assistant",
                        content=result["choices"][0]["message"]["content"]
                    ),
                    finish_reason=result["choices"][0]["finish_reason"]
                )
            ],
            usage=Usage(
                prompt_tokens=result["usage"]["prompt_tokens"],
                completion_tokens=result["usage"]["completion_tokens"],
                total_tokens=result["usage"]["total_tokens"]
            )
        )
```

**2. è¯·æ±‚ç¼“å­˜å®ç°**

```python
# File: app/services/cache_service.py

import hashlib
import json

class RequestCacheService:
    """è¯·æ±‚ç¼“å­˜æœåŠ¡"""
    
    def __init__(self):
        self.redis_client = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT
        )
    
    def _generate_cache_key(
        self,
        request: ChatRequest
    ) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        
        # åºåˆ—åŒ–è¯·æ±‚
        request_dict = {
            "model": request.model,
            "messages": [m.dict() for m in request.messages],
            "temperature": request.temperature,
            "max_tokens": request.max_tokens
        }
        request_str = json.dumps(request_dict, sort_keys=True)
        
        # ç”Ÿæˆå“ˆå¸Œ
        return f"model_adapter:cache:{hashlib.sha256(request_str.encode()).hexdigest()}"
    
    async def get_cached_response(
        self,
        request: ChatRequest
    ) -> Optional[ChatResponse]:
        """è·å–ç¼“å­˜çš„å“åº”"""
        
        # 1. ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._generate_cache_key(request)
        
        # 2. ä»Redisè·å–
        cached_data = self.redis_client.get(cache_key)
        if cached_data:
            return ChatResponse.parse_raw(cached_data)
        
        return None
    
    async def set_cached_response(
        self,
        request: ChatRequest,
        response: ChatResponse,
        ttl: int = 3600
    ):
        """è®¾ç½®ç¼“å­˜å“åº”"""
        
        cache_key = self._generate_cache_key(request)
        self.redis_client.setex(
            cache_key,
            ttl,
            response.json()
        )
```

### 5.3 æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | éªŒæ”¶æ ‡å‡† |
|-----|--------|--------|----------|
| å¹³å‡å“åº”æ—¶é—´ | ~1.5s | < 1.2s | P95 < 2s |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | > 40% | å‡å°‘40%è¯·æ±‚ |
| é”™è¯¯ç‡ | < 1% | < 0.5% | å¯ç”¨æ€§99.5% |

---

## 6-9. å…¶ä»–æœåŠ¡ç®€è¦è®¡åˆ’

### 6. Indexing Service

**P0ä»»åŠ¡**:
- å®Œå–„PDFè¡¨æ ¼å’Œå›¾ç‰‡è§£æ
- å®ç°æ™ºèƒ½åˆ†å—ç­–ç•¥
- æ·»åŠ å‘é‡ç¼“å­˜

**P1ä»»åŠ¡**:
- æ”¯æŒæ›´å¤šæ–‡æ¡£æ ¼å¼ï¼ˆPPTã€Excelï¼‰
- å®ä½“è¯†åˆ«å’ŒçŸ¥è¯†å›¾è°±å¢å¼º
- å¢é‡ç´¢å¼•

### 7. Multimodal Engine

**P0ä»»åŠ¡**:
- EasyOCRé›†æˆ
- æ‰¹é‡OCRå¤„ç†
- ç»“æœç¼“å­˜

**P1ä»»åŠ¡**:
- ä¸“ç”¨ç›®æ ‡æ£€æµ‹ï¼ˆYOLOï¼‰
- å›¾åƒåˆ†å‰²
- æ‰¹é‡å¤„ç†

### 8. Vector Store Adapter

**P0ä»»åŠ¡**:
- æ·»åŠ ç¼“å­˜å±‚ï¼ˆRedisï¼‰
- æ‰¹é‡æ“ä½œä¼˜åŒ–
- é‡è¯•æœºåˆ¶

**P1ä»»åŠ¡**:
- æ·»åŠ æ›´å¤šåç«¯ï¼ˆQdrant, Weaviateï¼‰
- æµå¼æ’å…¥æ”¯æŒ
- è‡ªåŠ¨åˆ†ç‰‡å’Œè´Ÿè½½å‡è¡¡

### 9. Knowledge Service (Python)

**P0ä»»åŠ¡**:
- Protoå®šä¹‰å®Œå–„
- é›†æˆæ–‡ä»¶è§£æå™¨
- å®ç°æ™ºèƒ½åˆ†å—

**P1ä»»åŠ¡**:
- é›†æˆå‘é‡åŒ–æœåŠ¡
- æ·»åŠ pgvectoræ”¯æŒ
- æ–‡æ¡£æ‘˜è¦ç”Ÿæˆ

---

## æ€»ä½“æ—¶é—´çº¿

### Phase 1: æ ¸å¿ƒåŠŸèƒ½å®Œå–„ï¼ˆ1-2ä¸ªæœˆï¼‰

**Week 1-2**: Agent Engineæµå¼å“åº” + Voice Engineè¯´è¯äººåˆ†ç¦»
**Week 3-4**: RAG Engineé‡æ’åºå’Œç¼“å­˜ + Retrieval Serviceé›†æˆ
**Week 5-6**: Model Adapterå›½äº§æ¨¡å‹ + Indexing Service PDFè§£æ
**Week 7-8**: Multimodal Engineç›®æ ‡æ£€æµ‹ + Vector Store Adapterä¼˜åŒ–

### Phase 2: é«˜çº§åŠŸèƒ½å¼€å‘ï¼ˆ2-3ä¸ªæœˆï¼‰

**Week 9-12**: å¤šAgentåä½œ + æƒ…æ„Ÿè¯†åˆ« + è‡ªé€‚åº”æ£€ç´¢
**Week 13-16**: äººå·¥åé¦ˆå¾ªç¯ + ä¸ªæ€§åŒ–æ£€ç´¢ + æ™ºèƒ½é™çº§

### Phase 3: æ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯•ï¼ˆ1ä¸ªæœˆï¼‰

**Week 17-20**: æ€§èƒ½æµ‹è¯•ã€å‹åŠ›æµ‹è¯•ã€ä¼˜åŒ–è°ƒä¼˜

---

## éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

- âœ… æ‰€æœ‰P0åŠŸèƒ½å®ç°å¹¶æµ‹è¯•é€šè¿‡
- âœ… æ‰€æœ‰P1åŠŸèƒ½è‡³å°‘å®Œæˆ80%
- âœ… APIæ–‡æ¡£å®Œæ•´
- âœ… å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%

### æ€§èƒ½éªŒæ”¶

- âœ… æ»¡è¶³æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡ç›®æ ‡å€¼
- âœ… å¹¶å‘å‹åŠ›æµ‹è¯•é€šè¿‡
- âœ… å†…å­˜å’ŒCPUä½¿ç”¨åœ¨åˆç†èŒƒå›´

### è´¨é‡éªŒæ”¶

- âœ… ä»£ç å®¡æŸ¥é€šè¿‡
- âœ… å®‰å…¨æ‰«ææ— é«˜å±æ¼æ´
- âœ… ç›‘æ§å’Œå‘Šè­¦é…ç½®å®Œæ•´

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0  
**æœ€åæ›´æ–°**: 2025-10-27  
**ç»´æŠ¤è€…**: VoiceHelper Team


