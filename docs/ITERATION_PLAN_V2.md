# VoiceAssistant åŠŸèƒ½è¿ç§»è¿­ä»£è®¡åˆ’ v2.0

> **ç”Ÿæˆæ—¶é—´**: 2025-10-27
> **åŸºäº**: voicehelper v0.9.2 åŠŸèƒ½å¯¹æ¯”åˆ†æ
> **å½“å‰ç‰ˆæœ¬**: VoiceAssistant v2.0.0
> **ç›®æ ‡ç‰ˆæœ¬**: v2.3.0
> **é¢„è®¡å‘¨æœŸ**: 10 å‘¨ (2.5 ä¸ªæœˆ)

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

æœ¬è¿­ä»£è®¡åˆ’åŸºäºå¯¹ [voicehelper](https://github.com/haoyunlt/voicehelper) é¡¹ç›®çš„æ·±åº¦åˆ†æï¼Œè¯†åˆ«å‡º **15 é¡¹**å€¼å¾—è¿ç§»çš„åŠŸèƒ½ç‰¹æ€§ï¼ŒæŒ‰ä¼˜å…ˆçº§åˆ†ä¸º P0/P1/P2 ä¸‰ä¸ªç­‰çº§ï¼Œè§„åˆ’ä¸º **3 ä¸ªç‰ˆæœ¬**ï¼ˆv2.1.0/v2.2.0/v2.3.0ï¼‰é€æ­¥äº¤ä»˜ã€‚

### æ ¸å¿ƒç›®æ ‡

- âœ… æå‡ç³»ç»Ÿç¨³å®šæ€§å’Œå¯é æ€§
- âœ… å¢å¼º AI æ ¸å¿ƒèƒ½åŠ›ï¼ˆè¯­éŸ³ã€è®°å¿†ã€æ¨¡å‹ï¼‰
- âœ… å®Œå–„ç§»åŠ¨ç«¯æ”¯æŒ
- âœ… ä¼˜åŒ–å¼€å‘è€…ä½“éªŒ

### æ€»ä½“è¿›åº¦

```
æ€»å·¥æ—¶é¢„ä¼°: 120-150 äººå¤©
å½“å‰çŠ¶æ€:  å‡†å¤‡å¯åŠ¨
å®Œæˆåº¦:    [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
```

---

## ğŸ¯ ç‰ˆæœ¬è§„åˆ’æ€»è§ˆ

| ç‰ˆæœ¬   | ä¸»é¢˜     | æ—¶é—´çº¿    | åŠŸèƒ½æ•° | ä¼˜å…ˆçº§ | çŠ¶æ€      |
| ------ | -------- | --------- | ------ | ------ | --------- |
| v2.1.0 | æ ¸å¿ƒå¢å¼º | Week 1-3  | 7 é¡¹   | P0     | ğŸ“‹ è§„åˆ’ä¸­ |
| v2.2.0 | åŠŸèƒ½æ‰©å±• | Week 4-7  | 5 é¡¹   | P1     | ğŸ“‹ è§„åˆ’ä¸­ |
| v2.3.0 | ä¼˜åŒ–æå‡ | Week 8-10 | 3 é¡¹   | P2     | ğŸ“‹ è§„åˆ’ä¸­ |

---

## ğŸ“¦ v2.1.0 æ ¸å¿ƒå¢å¼º (Week 1-3)

**å‘å¸ƒç›®æ ‡æ—¥æœŸ**: 3 å‘¨å
**æ ¸å¿ƒä»·å€¼**: æå‡ç³»ç»Ÿç¨³å®šæ€§ã€AI èƒ½åŠ›å’Œå®‰å…¨æ€§

### Sprint 1: ç³»ç»Ÿå¯é æ€§ (Week 1)

#### ğŸ¯ Sprint ç›®æ ‡

- æå‡ Agent ä»»åŠ¡ç®¡ç†çš„å¯é æ€§
- å®ç°å…¨å±€åˆ†å¸ƒå¼é™æµ
- å¢å¼º Agent é•¿æœŸè®°å¿†èƒ½åŠ›

#### ğŸ“‹ ä»»åŠ¡æ¸…å•

##### 1. ä»»åŠ¡çŠ¶æ€ Redis æŒä¹…åŒ–

**è´Ÿè´£äºº**: Backend Team
**é¢„ä¼°å·¥æ—¶**: 2-3 å¤©
**ä¼˜å…ˆçº§**: P0

**è¯¦ç»†è¯´æ˜**:

- å½“å‰ Agent Engine çš„ä»»åŠ¡çŠ¶æ€å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼ŒæœåŠ¡é‡å¯åä»»åŠ¡ä¸¢å¤±
- voicehelper ä½¿ç”¨ Redis æŒä¹…åŒ–ä»»åŠ¡çŠ¶æ€ï¼Œæä¾›æ›´å¥½çš„å¯é æ€§

**å®ç°è¦ç‚¹**:

```python
# algo/agent-engine/app/core/task_manager.py

class RedisTaskManager:
    """Redis æŒä¹…åŒ–ä»»åŠ¡ç®¡ç†å™¨"""

    def __init__(self, redis_client):
        self.redis = redis_client
        self.task_prefix = "agent:task:"
        self.task_index = "agent:tasks:index"

    async def create_task(self, task: AgentTask) -> str:
        """åˆ›å»ºä»»åŠ¡å¹¶æŒä¹…åŒ–"""
        task_id = str(uuid.uuid4())
        task_key = f"{self.task_prefix}{task_id}"

        # ä¿å­˜ä»»åŠ¡æ•°æ®
        await self.redis.hset(task_key, mapping={
            "id": task_id,
            "user_id": task.user_id,
            "tenant_id": task.tenant_id,
            "status": "pending",
            "created_at": datetime.utcnow().isoformat(),
            "payload": json.dumps(task.dict())
        })

        # æ·»åŠ åˆ°ç´¢å¼•ï¼ˆæŒ‰ç”¨æˆ·ï¼‰
        await self.redis.sadd(
            f"{self.task_index}:user:{task.user_id}",
            task_id
        )

        # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ7å¤©ï¼‰
        await self.redis.expire(task_key, 7 * 24 * 3600)

        return task_id

    async def update_task_status(self, task_id: str, status: str, result: dict = None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        task_key = f"{self.task_prefix}{task_id}"

        updates = {
            "status": status,
            "updated_at": datetime.utcnow().isoformat()
        }

        if result:
            updates["result"] = json.dumps(result)

        await self.redis.hset(task_key, mapping=updates)

    async def get_task(self, task_id: str) -> Optional[AgentTask]:
        """è·å–ä»»åŠ¡"""
        task_key = f"{self.task_prefix}{task_id}"
        data = await self.redis.hgetall(task_key)

        if not data:
            return None

        return AgentTask.parse_obj(json.loads(data["payload"]))

    async def list_user_tasks(self, user_id: str, status: str = None) -> List[AgentTask]:
        """æŸ¥è¯¢ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨"""
        task_ids = await self.redis.smembers(f"{self.task_index}:user:{user_id}")

        tasks = []
        for task_id in task_ids:
            task = await self.get_task(task_id)
            if task and (status is None or task.status == status):
                tasks.append(task)

        return sorted(tasks, key=lambda t: t.created_at, reverse=True)
```

**API æ¥å£**:

```python
# algo/agent-engine/app/api/task_routes.py

@router.post("/tasks", response_model=TaskResponse)
async def create_task(request: CreateTaskRequest, task_manager: RedisTaskManager = Depends()):
    """åˆ›å»º Agent ä»»åŠ¡"""
    task_id = await task_manager.create_task(request.task)
    return TaskResponse(task_id=task_id, status="pending")

@router.get("/tasks/{task_id}", response_model=TaskDetail)
async def get_task(task_id: str, task_manager: RedisTaskManager = Depends()):
    """æŸ¥è¯¢ä»»åŠ¡è¯¦æƒ…"""
    task = await task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    return task

@router.get("/tasks", response_model=List[TaskSummary])
async def list_tasks(
    user_id: str = Query(...),
    status: Optional[str] = Query(None),
    task_manager: RedisTaskManager = Depends()
):
    """æŸ¥è¯¢ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨"""
    tasks = await task_manager.list_user_tasks(user_id, status)
    return [TaskSummary.from_task(t) for t in tasks]
```

**æµ‹è¯•è¦æ±‚**:

- å•å…ƒæµ‹è¯•: ä»»åŠ¡ CRUD æ“ä½œ
- é›†æˆæµ‹è¯•: Redis è¿æ¥å¤±è´¥é™çº§
- æ€§èƒ½æµ‹è¯•: 1000 å¹¶å‘ä»»åŠ¡åˆ›å»º
- å¯é æ€§æµ‹è¯•: æœåŠ¡é‡å¯åä»»åŠ¡æ¢å¤

**éªŒæ”¶æ ‡å‡†**:

- [ ] ä»»åŠ¡åˆ›å»ºåå†™å…¥ Redis
- [ ] æœåŠ¡é‡å¯åä»»åŠ¡çŠ¶æ€ä¸ä¸¢å¤±
- [ ] æ”¯æŒæŒ‰ç”¨æˆ·ã€çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡
- [ ] ä»»åŠ¡è‡ªåŠ¨è¿‡æœŸï¼ˆ7 å¤©ï¼‰
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] API æ–‡æ¡£æ›´æ–°

---

##### 2. åˆ†å¸ƒå¼é™æµå™¨ (Redis)

**è´Ÿè´£äºº**: Backend Team
**é¢„ä¼°å·¥æ—¶**: 3-4 å¤©
**ä¼˜å…ˆçº§**: P0

**è¯¦ç»†è¯´æ˜**:

- å½“å‰ API Gateway ä½¿ç”¨æœ¬åœ°å†…å­˜é™æµï¼Œå¤šå®ä¾‹ç¯å¢ƒä¸‹æ— æ³•å…¨å±€é™æµ
- voicehelper ä½¿ç”¨ Redis å®ç°åˆ†å¸ƒå¼é™æµï¼Œæ”¯æŒå…¨å±€æµé‡æ§åˆ¶

**å®ç°è¦ç‚¹**:

```go
// pkg/middleware/rate_limiter.go

package middleware

import (
    "context"
    "fmt"
    "time"

    "github.com/go-redis/redis/v8"
    "github.com/go-kratos/kratos/v2/errors"
    "github.com/go-kratos/kratos/v2/middleware"
    "github.com/go-kratos/kratos/v2/transport"
)

// RateLimiterConfig é™æµé…ç½®
type RateLimiterConfig struct {
    // æ¯ç§’è¯·æ±‚æ•°
    RequestsPerSecond int
    // çªå‘å®¹é‡
    Burst int
    // Redis å®¢æˆ·ç«¯
    Redis *redis.Client
    // é™æµç»´åº¦æå–å‡½æ•°
    KeyExtractor func(ctx context.Context) (string, error)
}

// RateLimiter åˆ†å¸ƒå¼é™æµä¸­é—´ä»¶
func RateLimiter(config *RateLimiterConfig) middleware.Middleware {
    return func(handler middleware.Handler) middleware.Handler {
        return func(ctx context.Context, req interface{}) (interface{}, error) {
            // æå–é™æµ Key (user_id, tenant_id, ip, api_key ç­‰)
            key, err := config.KeyExtractor(ctx)
            if err != nil {
                return nil, err
            }

            // ä»¤ç‰Œæ¡¶ç®—æ³• (Token Bucket)
            allowed, err := checkRateLimit(ctx, config.Redis, key, config.RequestsPerSecond, config.Burst)
            if err != nil {
                return nil, errors.InternalServer("RATE_LIMIT_ERROR", err.Error())
            }

            if !allowed {
                return nil, errors.TooManyRequests("RATE_LIMIT_EXCEEDED", "Too many requests, please try again later")
            }

            return handler(ctx, req)
        }
    }
}

// checkRateLimit ä½¿ç”¨ Redis å®ç°ä»¤ç‰Œæ¡¶ç®—æ³•
func checkRateLimit(ctx context.Context, rdb *redis.Client, key string, rate int, burst int) (bool, error) {
    luaScript := `
local key = KEYS[1]
local rate = tonumber(ARGV[1])    -- æ¯ç§’ç”Ÿæˆ token æ•°
local burst = tonumber(ARGV[2])   -- æ¡¶å®¹é‡
local now = tonumber(ARGV[3])     -- å½“å‰æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
local requested = 1               -- æœ¬æ¬¡è¯·æ±‚æ¶ˆè€— 1 token

local bucket = redis.call('HMGET', key, 'tokens', 'last_refill')
local tokens = tonumber(bucket[1]) or burst
local last_refill = tonumber(bucket[2]) or now

-- è®¡ç®—è·ç¦»ä¸Šæ¬¡è¡¥å……çš„æ—¶é—´é—´éš”
local delta = math.max(0, now - last_refill)
-- è®¡ç®—åº”è¡¥å……çš„ token æ•°é‡
local refill = (delta / 1000) * rate
tokens = math.min(burst, tokens + refill)

-- æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ token
if tokens >= requested then
    tokens = tokens - requested
    redis.call('HMSET', key, 'tokens', tokens, 'last_refill', now)
    redis.call('EXPIRE', key, 60)  -- è®¾ç½®è¿‡æœŸæ—¶é—´
    return 1  -- å…è®¸é€šè¿‡
else
    return 0  -- é™æµ
end
`

    now := time.Now().UnixNano() / 1e6 // æ¯«ç§’
    result, err := rdb.Eval(ctx, luaScript, []string{fmt.Sprintf("ratelimit:%s", key)}, rate, burst, now).Result()
    if err != nil {
        return false, err
    }

    return result.(int64) == 1, nil
}

// å†…ç½® Key æå–å™¨

// ByUserID æŒ‰ç”¨æˆ· ID é™æµ
func ByUserID(ctx context.Context) (string, error) {
    if tr, ok := transport.FromServerContext(ctx); ok {
        userID := tr.RequestHeader().Get("X-User-ID")
        if userID != "" {
            return fmt.Sprintf("user:%s", userID), nil
        }
    }
    return "", errors.BadRequest("MISSING_USER_ID", "User ID not found in context")
}

// ByTenantID æŒ‰ç§Ÿæˆ· ID é™æµ
func ByTenantID(ctx context.Context) (string, error) {
    if tr, ok := transport.FromServerContext(ctx); ok {
        tenantID := tr.RequestHeader().Get("X-Tenant-ID")
        if tenantID != "" {
            return fmt.Sprintf("tenant:%s", tenantID), nil
        }
    }
    return "", errors.BadRequest("MISSING_TENANT_ID", "Tenant ID not found in context")
}

// ByIP æŒ‰ IP åœ°å€é™æµ
func ByIP(ctx context.Context) (string, error) {
    if tr, ok := transport.FromServerContext(ctx); ok {
        ip := tr.RequestHeader().Get("X-Forwarded-For")
        if ip == "" {
            ip = tr.RequestHeader().Get("X-Real-IP")
        }
        if ip != "" {
            return fmt.Sprintf("ip:%s", ip), nil
        }
    }
    return "", errors.BadRequest("MISSING_IP", "IP address not found in context")
}
```

**ä½¿ç”¨ç¤ºä¾‹**:

```go
// cmd/ai-orchestrator/internal/server/grpc.go

import (
    "voicehelper/pkg/middleware"
)

func NewGRPCServer(c *conf.Server, redis *redis.Client) *grpc.Server {
    var opts = []grpc.ServerOption{
        grpc.Middleware(
            // ç”¨æˆ·çº§åˆ«é™æµ: 100 req/s, burst 50
            middleware.RateLimiter(&middleware.RateLimiterConfig{
                RequestsPerSecond: 100,
                Burst:             50,
                Redis:             redis,
                KeyExtractor:      middleware.ByUserID,
            }),
            // ç§Ÿæˆ·çº§åˆ«é™æµ: 10000 req/s, burst 1000
            middleware.RateLimiter(&middleware.RateLimiterConfig{
                RequestsPerSecond: 10000,
                Burst:             1000,
                Redis:             redis,
                KeyExtractor:      middleware.ByTenantID,
            }),
        ),
    }
    srv := grpc.NewServer(opts...)
    return srv
}
```

**æµ‹è¯•è¦æ±‚**:

- å•å…ƒæµ‹è¯•: Lua è„šæœ¬é€»è¾‘
- é›†æˆæµ‹è¯•: å¤šå®ä¾‹é™æµä¸€è‡´æ€§
- å‹åŠ›æµ‹è¯•: å¹¶å‘è¯·æ±‚é™æµå‡†ç¡®æ€§
- æ•…éšœæµ‹è¯•: Redis ä¸å¯ç”¨æ—¶é™çº§

**éªŒæ”¶æ ‡å‡†**:

- [ ] ä»¤ç‰Œæ¡¶ç®—æ³•æ­£ç¡®å®ç°
- [ ] å¤šå®ä¾‹ç¯å¢ƒå…¨å±€é™æµç”Ÿæ•ˆ
- [ ] æ”¯æŒç”¨æˆ·/ç§Ÿæˆ·/IP å¤šç»´åº¦é™æµ
- [ ] Redis æ•…éšœæ—¶ä¼˜é›…é™çº§ï¼ˆæ”¾è¡Œæˆ–æ‹’ç»ï¼‰
- [ ] é™æµå“åº”åŒ…å« `X-RateLimit-*` Headers
- [ ] æ€§èƒ½å¼€é”€ < 5ms (P95)

---

##### 3. é•¿æœŸè®°å¿†æ—¶é—´è¡°å‡æœºåˆ¶

**è´Ÿè´£äºº**: AI Team
**é¢„ä¼°å·¥æ—¶**: 2 å¤©
**ä¼˜å…ˆçº§**: P0

**è¯¦ç»†è¯´æ˜**:

- å½“å‰ Agent é•¿æœŸè®°å¿†è¯„åˆ†å›ºå®šï¼Œä¸ç¬¦åˆäººç±»è®°å¿†é—å¿˜è§„å¾‹
- voicehelper å®ç°æ—¶é—´è¡°å‡æœºåˆ¶ï¼Œè®°å¿†é‡è¦æ€§éšæ—¶é—´é€’å‡

**å®ç°è¦ç‚¹**:

```python
# algo/agent-engine/app/core/memory/decay_manager.py

import math
from datetime import datetime, timedelta
from typing import List, Optional

class MemoryDecayManager:
    """è®°å¿†è¡°å‡ç®¡ç†å™¨

    åŸºäº Ebbinghaus é—å¿˜æ›²çº¿å®ç°è®°å¿†è¡°å‡:
    R(t) = e^(-t/S)

    å…¶ä¸­:
    - R(t): t æ—¶åˆ»çš„è®°å¿†å¼ºåº¦
    - t: è·ç¦»åˆ›å»ºæ—¶é—´çš„å¤©æ•°
    - S: è®°å¿†ç¨³å®šæ€§å‚æ•° (é»˜è®¤ 7 å¤©)
    """

    def __init__(self, stability_days: float = 7.0):
        self.stability_days = stability_days

    def calculate_decay_score(
        self,
        created_at: datetime,
        importance: float = 1.0,
        access_count: int = 0,
        last_accessed: Optional[datetime] = None
    ) -> float:
        """è®¡ç®—è¡°å‡åçš„è®°å¿†åˆ†æ•°

        Args:
            created_at: è®°å¿†åˆ›å»ºæ—¶é—´
            importance: åˆå§‹é‡è¦æ€§ (0.0-1.0)
            access_count: è®¿é—®æ¬¡æ•°
            last_accessed: æœ€åè®¿é—®æ—¶é—´

        Returns:
            è¡°å‡åçš„åˆ†æ•° (0.0-1.0)
        """
        # 1. åŸºç¡€è¡°å‡ï¼ˆEbbinghaus æ›²çº¿ï¼‰
        days_passed = (datetime.utcnow() - created_at).total_seconds() / 86400
        base_decay = math.exp(-days_passed / self.stability_days)

        # 2. é‡è®¿å¢å¼ºï¼ˆæ¯æ¬¡è®¿é—®å»¶é•¿è®°å¿†å¯¿å‘½ï¼‰
        access_boost = 1.0 + (access_count * 0.1)  # æ¯è®¿é—®ä¸€æ¬¡ +10%
        access_boost = min(access_boost, 3.0)  # æœ€å¤š 3 å€

        # 3. è¿‘æœŸè®¿é—®å¢å¼º
        recency_boost = 1.0
        if last_accessed:
            days_since_access = (datetime.utcnow() - last_accessed).total_seconds() / 86400
            recency_boost = 1.0 + math.exp(-days_since_access / 3.0)

        # ç»¼åˆåˆ†æ•°
        final_score = importance * base_decay * access_boost * recency_boost

        return min(final_score, 1.0)

    def should_forget(self, score: float, threshold: float = 0.1) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é—å¿˜"""
        return score < threshold

    def get_retention_days(self, importance: float) -> int:
        """è®¡ç®—è®°å¿†ä¿ç•™å¤©æ•°"""
        # é‡è¦æ€§è¶Šé«˜ï¼Œä¿ç•™è¶Šä¹…
        if importance >= 0.9:
            return 365  # 1 å¹´
        elif importance >= 0.7:
            return 90   # 3 ä¸ªæœˆ
        elif importance >= 0.5:
            return 30   # 1 ä¸ªæœˆ
        else:
            return 7    # 1 å‘¨

# é›†æˆåˆ° VectorMemory

class VectorMemory:
    """å‘é‡è®°å¿†å­˜å‚¨ï¼ˆé›†æˆè¡°å‡æœºåˆ¶ï¼‰"""

    def __init__(self, faiss_index, metadata_store, decay_manager: MemoryDecayManager):
        self.index = faiss_index
        self.metadata = metadata_store
        self.decay_manager = decay_manager

    async def add_memory(
        self,
        content: str,
        embedding: np.ndarray,
        importance: float = 0.5,
        metadata: dict = None
    ) -> str:
        """æ·»åŠ è®°å¿†"""
        memory_id = str(uuid.uuid4())

        # å­˜å‚¨å‘é‡
        self.index.add(embedding)

        # å­˜å‚¨å…ƒæ•°æ®
        memory_metadata = {
            "id": memory_id,
            "content": content,
            "importance": importance,
            "created_at": datetime.utcnow().isoformat(),
            "access_count": 0,
            "last_accessed": None,
            "metadata": metadata or {}
        }
        await self.metadata.set(f"memory:{memory_id}", json.dumps(memory_metadata))

        return memory_id

    async def recall_memory(
        self,
        query_embedding: np.ndarray,
        top_k: int = 10,
        min_score: float = 0.1
    ) -> List[Memory]:
        """å¬å›è®°å¿†ï¼ˆè€ƒè™‘è¡°å‡ï¼‰"""
        # 1. å‘é‡æ£€ç´¢ï¼ˆå¬å› top_k * 3ï¼Œåç»­è¿‡æ»¤ï¼‰
        distances, indices = self.index.search(query_embedding, top_k * 3)

        # 2. åŠ è½½å…ƒæ•°æ®å¹¶è®¡ç®—è¡°å‡åˆ†æ•°
        memories = []
        for idx, distance in zip(indices[0], distances[0]):
            memory_data = await self.metadata.get(f"memory:{idx}")
            if not memory_data:
                continue

            meta = json.loads(memory_data)

            # è®¡ç®—è¡°å‡åçš„åˆ†æ•°
            decay_score = self.decay_manager.calculate_decay_score(
                created_at=datetime.fromisoformat(meta["created_at"]),
                importance=meta["importance"],
                access_count=meta["access_count"],
                last_accessed=datetime.fromisoformat(meta["last_accessed"]) if meta["last_accessed"] else None
            )

            # ç»¼åˆç›¸ä¼¼åº¦å’Œè¡°å‡åˆ†æ•°
            final_score = distance * decay_score

            if final_score >= min_score:
                memories.append(Memory(
                    id=meta["id"],
                    content=meta["content"],
                    score=final_score,
                    metadata=meta["metadata"]
                ))

                # æ›´æ–°è®¿é—®ç»Ÿè®¡
                meta["access_count"] += 1
                meta["last_accessed"] = datetime.utcnow().isoformat()
                await self.metadata.set(f"memory:{meta['id']}", json.dumps(meta))

        # 3. æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å› top_k
        memories.sort(key=lambda m: m.score, reverse=True)
        return memories[:top_k]

    async def cleanup_forgotten_memories(self):
        """æ¸…ç†å·²é—å¿˜çš„è®°å¿†ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰"""
        all_memory_keys = await self.metadata.keys("memory:*")

        forgotten_count = 0
        for key in all_memory_keys:
            memory_data = await self.metadata.get(key)
            meta = json.loads(memory_data)

            decay_score = self.decay_manager.calculate_decay_score(
                created_at=datetime.fromisoformat(meta["created_at"]),
                importance=meta["importance"],
                access_count=meta["access_count"],
                last_accessed=datetime.fromisoformat(meta["last_accessed"]) if meta["last_accessed"] else None
            )

            if self.decay_manager.should_forget(decay_score):
                await self.metadata.delete(key)
                forgotten_count += 1

        logger.info(f"Cleaned up {forgotten_count} forgotten memories")
        return forgotten_count
```

**å®šæ—¶æ¸…ç†ä»»åŠ¡**:

```python
# algo/agent-engine/app/tasks/memory_cleanup.py

from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

@scheduler.scheduled_job('cron', hour=3, minute=0)  # æ¯å¤©å‡Œæ™¨ 3 ç‚¹
async def cleanup_forgotten_memories():
    """æ¸…ç†é—å¿˜çš„è®°å¿†"""
    vector_memory = get_vector_memory()  # ä¾èµ–æ³¨å…¥
    count = await vector_memory.cleanup_forgotten_memories()
    logger.info(f"Memory cleanup completed: {count} memories removed")
```

**éªŒæ”¶æ ‡å‡†**:

- [ ] è®°å¿†åˆ†æ•°éšæ—¶é—´é€’å‡
- [ ] é‡è®¿è®°å¿†ä¼šå¢å¼ºè®°å¿†å¼ºåº¦
- [ ] ä½åˆ†è®°å¿†è‡ªåŠ¨æ¸…ç†
- [ ] é‡è¦è®°å¿†ä¿ç•™æ›´ä¹…
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–è¡°å‡ç®—æ³•
- [ ] æ€§èƒ½æµ‹è¯•: 1000 è®°å¿†å¬å› < 100ms

---

### Sprint 2: è¯­éŸ³èƒ½åŠ›æå‡ (Week 2)

#### ğŸ¯ Sprint ç›®æ ‡

- é›†æˆ Silero VAD æ·±åº¦å­¦ä¹ æ¨¡å‹
- å®ç°æµå¼ VAD æ£€æµ‹
- æä¾› VAD ç½®ä¿¡åº¦è¯„åˆ†

#### ğŸ“‹ ä»»åŠ¡æ¸…å•

##### 4. Silero VAD æ·±åº¦å­¦ä¹ è¯­éŸ³æ£€æµ‹

**è´Ÿè´£äºº**: AI Team
**é¢„ä¼°å·¥æ—¶**: 3-5 å¤©
**ä¼˜å…ˆçº§**: P0

**è¯¦ç»†è¯´æ˜**:

- å½“å‰ä½¿ç”¨åŸºç¡€ VADï¼ˆèƒ½é‡æ£€æµ‹ï¼‰ï¼Œå‡†ç¡®ç‡çº¦ 85%
- voicehelper ä½¿ç”¨ Silero VAD æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå‡†ç¡®ç‡ > 95%

**å®ç°è¦ç‚¹**:

```python
# algo/voice-engine/app/core/vad_engine.py

import torch
import torchaudio
from typing import List, Tuple

class SileroVADEngine:
    """Silero VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹å¼•æ“

    æ¨¡å‹: https://github.com/snakers4/silero-vad
    å‡†ç¡®ç‡: > 95%
    å»¶è¿Ÿ: < 50ms (CPU)
    """

    def __init__(self, model_path: str = "models/silero_vad.jit", threshold: float = 0.5):
        # åŠ è½½æ¨¡å‹
        self.model, self.utils = torch.hub.load(
            repo_or_dir='snakers4/silero-vad',
            model='silero_vad',
            force_reload=False,
            onnx=False
        )
        self.model.eval()

        # æå–å·¥å…·å‡½æ•°
        (self.get_speech_timestamps,
         self.save_audio,
         self.read_audio,
         self.VADIterator,
         self.collect_chunks) = self.utils

        self.threshold = threshold
        self.sample_rate = 16000

    def detect_speech(self, audio: np.ndarray) -> List[dict]:
        """æ£€æµ‹è¯­éŸ³æ®µè½

        Args:
            audio: éŸ³é¢‘æ•°æ® (numpy array, 16kHz)

        Returns:
            è¯­éŸ³æ®µåˆ—è¡¨: [
                {'start': 0.5, 'end': 2.3, 'confidence': 0.95},
                ...
            ]
        """
        # è½¬æ¢ä¸º PyTorch Tensor
        if isinstance(audio, np.ndarray):
            audio_tensor = torch.from_numpy(audio).float()
        else:
            audio_tensor = audio

        # æ£€æµ‹è¯­éŸ³æ—¶é—´æˆ³
        speech_timestamps = self.get_speech_timestamps(
            audio_tensor,
            self.model,
            sampling_rate=self.sample_rate,
            threshold=self.threshold,
            min_speech_duration_ms=250,  # æœ€å°è¯­éŸ³æ®µ 250ms
            min_silence_duration_ms=100,  # æœ€å°é™éŸ³æ®µ 100ms
            window_size_samples=512,      # çª—å£å¤§å° 32ms
            speech_pad_ms=30              # è¯­éŸ³è¾¹ç¼˜å¡«å…… 30ms
        )

        # æ ¼å¼åŒ–è¾“å‡º
        segments = []
        for ts in speech_timestamps:
            segments.append({
                'start': ts['start'] / self.sample_rate,
                'end': ts['end'] / self.sample_rate,
                'confidence': self._calculate_confidence(audio_tensor[ts['start']:ts['end']])
            })

        return segments

    def _calculate_confidence(self, audio_chunk: torch.Tensor) -> float:
        """è®¡ç®—è¯­éŸ³ç½®ä¿¡åº¦"""
        with torch.no_grad():
            # æ¨¡å‹è¾“å‡ºï¼šè¯­éŸ³æ¦‚ç‡
            speech_prob = self.model(audio_chunk, self.sample_rate).item()
        return speech_prob

    def detect_stream(self, audio_chunk: np.ndarray, context: dict = None) -> Tuple[bool, float, dict]:
        """æµå¼æ£€æµ‹ï¼ˆé€‚ç”¨äº WebSocketï¼‰

        Args:
            audio_chunk: éŸ³é¢‘å— (512 samples = 32ms @ 16kHz)
            context: ä¸Šä¸‹æ–‡çŠ¶æ€ï¼ˆVAD éœ€è¦ä¿æŒçŠ¶æ€ï¼‰

        Returns:
            (is_speech, confidence, new_context)
        """
        if context is None:
            # åˆå§‹åŒ–æµå¼æ£€æµ‹å™¨
            vad_iterator = self.VADIterator(self.model, threshold=self.threshold)
            context = {'vad_iterator': vad_iterator}

        vad_iterator = context['vad_iterator']

        # æ£€æµ‹å½“å‰éŸ³é¢‘å—
        audio_tensor = torch.from_numpy(audio_chunk).float()
        speech_dict = vad_iterator(audio_tensor, return_seconds=False)

        # è§£æç»“æœ
        if speech_dict:
            is_speech = True
            confidence = self._calculate_confidence(audio_tensor)
        else:
            is_speech = False
            confidence = 0.0

        return is_speech, confidence, context

# FastAPI è·¯ç”±

from fastapi import UploadFile, File
from pydantic import BaseModel

class VADRequest(BaseModel):
    audio_url: str
    threshold: float = 0.5

class VADSegment(BaseModel):
    start: float
    end: float
    confidence: float

class VADResponse(BaseModel):
    segments: List[VADSegment]
    total_speech_duration: float
    speech_ratio: float

@router.post("/vad/detect", response_model=VADResponse)
async def detect_vad(request: VADRequest):
    """æ‰¹é‡ VAD æ£€æµ‹"""
    # ä¸‹è½½éŸ³é¢‘
    audio = await download_audio(request.audio_url)

    # VAD æ£€æµ‹
    vad_engine = get_vad_engine()
    segments = vad_engine.detect_speech(audio)

    # ç»Ÿè®¡
    total_duration = len(audio) / vad_engine.sample_rate
    speech_duration = sum(s['end'] - s['start'] for s in segments)
    speech_ratio = speech_duration / total_duration

    return VADResponse(
        segments=[VADSegment(**s) for s in segments],
        total_speech_duration=speech_duration,
        speech_ratio=speech_ratio
    )

@router.websocket("/vad/stream")
async def stream_vad(websocket: WebSocket):
    """æµå¼ VAD (WebSocket)"""
    await websocket.accept()

    vad_engine = get_vad_engine()
    context = None

    try:
        while True:
            # æ¥æ”¶éŸ³é¢‘å— (512 samples = 32ms)
            audio_chunk = await websocket.receive_bytes()
            audio_array = np.frombuffer(audio_chunk, dtype=np.float32)

            # æµå¼æ£€æµ‹
            is_speech, confidence, context = vad_engine.detect_stream(audio_array, context)

            # å‘é€ç»“æœ
            await websocket.send_json({
                "is_speech": is_speech,
                "confidence": float(confidence),
                "timestamp": time.time()
            })

    except WebSocketDisconnect:
        logger.info("VAD WebSocket disconnected")
```

**æ¨¡å‹éƒ¨ç½²**:

```dockerfile
# algo/voice-engine/Dockerfile

FROM python:3.11-slim

# å®‰è£… PyTorch (CPU)
RUN pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu

# ä¸‹è½½ Silero VAD æ¨¡å‹
RUN python -c "import torch; torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad')"

# ... å…¶ä»–ä¾èµ– ...
```

**æ€§èƒ½ä¼˜åŒ–**:

```python
# æ‰¹é‡æ¨ç†ä¼˜åŒ–
class BatchedVADEngine(SileroVADEngine):
    """æ‰¹é‡ VAD æ¨ç†ï¼ˆæå‡ååï¼‰"""

    def detect_batch(self, audio_list: List[np.ndarray]) -> List[List[dict]]:
        """æ‰¹é‡æ£€æµ‹"""
        # å¡«å……åˆ°ç›¸åŒé•¿åº¦
        max_len = max(len(audio) for audio in audio_list)
        padded_audios = [
            np.pad(audio, (0, max_len - len(audio)), 'constant')
            for audio in audio_list
        ]

        # æ‰¹é‡æ¨ç†
        audio_tensor = torch.from_numpy(np.stack(padded_audios)).float()

        with torch.no_grad():
            # å¹¶è¡Œæ£€æµ‹
            results = []
            for audio in audio_tensor:
                segments = self.detect_speech(audio.numpy())
                results.append(segments)

        return results
```

**éªŒæ”¶æ ‡å‡†**:

- [ ] Silero VAD æ¨¡å‹æ­£ç¡®åŠ è½½
- [ ] æ‰¹é‡æ£€æµ‹å‡†ç¡®ç‡ > 95%
- [ ] æµå¼æ£€æµ‹å»¶è¿Ÿ < 50ms (P95)
- [ ] WebSocket æ¥å£ç¨³å®šè¿è¡Œ
- [ ] ç½®ä¿¡åº¦è¯„åˆ†åˆç†
- [ ] æ¨¡å‹æ–‡ä»¶å¤§å° < 50MB
- [ ] å†…å­˜å ç”¨ < 200MB

---

##### 5. æ™ºè°± AI GLM-4 ç³»åˆ—æ¨¡å‹æ”¯æŒ

**è´Ÿè´£äºº**: AI Team
**é¢„ä¼°å·¥æ—¶**: 2-3 å¤©
**ä¼˜å…ˆçº§**: P1

[... è¯¦ç»†å®ç°æ–¹æ¡ˆ ...]

---

##### 6. æ–‡æ¡£ç‰ˆæœ¬ç®¡ç† (MVP)

**è´Ÿè´£äºº**: Backend Team
**é¢„ä¼°å·¥æ—¶**: 5-7 å¤©
**ä¼˜å…ˆçº§**: P1

[... è¯¦ç»†å®ç°æ–¹æ¡ˆ ...]

---

##### 7. ç—…æ¯’æ‰«æ (ClamAV)

**è´Ÿè´£äºº**: Backend Team
**é¢„ä¼°å·¥æ—¶**: 3-5 å¤©
**ä¼˜å…ˆçº§**: P1

[... è¯¦ç»†å®ç°æ–¹æ¡ˆ ...]

---

## ğŸ“¦ v2.2.0 åŠŸèƒ½æ‰©å±• (Week 4-7)

[... è¯¦ç»†å®ç°æ–¹æ¡ˆ ...]

---

## ğŸ“¦ v2.3.0 ä¼˜åŒ–æå‡ (Week 8-10)

[... è¯¦ç»†å®ç°æ–¹æ¡ˆ ...]

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ª

| Week | Sprint         | è®¡åˆ’ä»»åŠ¡            | çŠ¶æ€      | å®Œæˆåº¦ |
| ---- | -------------- | ------------------- | --------- | ------ |
| 1    | ç³»ç»Ÿå¯é æ€§     | Redis ä»»åŠ¡æŒä¹…åŒ–    | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
|      |                | åˆ†å¸ƒå¼é™æµå™¨        | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
|      |                | è®°å¿†æ—¶é—´è¡°å‡        | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
| 2    | è¯­éŸ³èƒ½åŠ›æå‡   | Silero VAD          | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
|      |                | æµå¼ VAD            | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
| 3    | æ¨¡å‹ä¸æ–‡æ¡£å¢å¼º | GLM-4 æ”¯æŒ          | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
|      |                | æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†        | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
|      |                | ç—…æ¯’æ‰«æ            | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
| 4-5  | ç§»åŠ¨ç«¯æ¨é€     | FCM/APNs            | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
| 6-7  | æƒ…æ„Ÿè¯†åˆ«       | å£°å­¦ç‰¹å¾ + æƒ…æ„Ÿåˆ†ç±» | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
| 8-9  | å¼€å‘å·¥å…·       | CLI å·¥å…· + éƒ¨ç½²è„šæœ¬ | ğŸ“‹ å¾…å¼€å§‹ | 0%     |
| 10   | æ€§èƒ½ä¼˜åŒ–       | æ‰¹é‡ä¼˜åŒ– + æ ¼å¼è½¬æ¢ | ğŸ“‹ å¾…å¼€å§‹ | 0%     |

---

## ğŸ¯ KPI ä¸éªŒæ”¶

### æŠ€æœ¯æŒ‡æ ‡

| æŒ‡æ ‡               | åŸºçº¿ (v2.0.0) | ç›®æ ‡ (v2.3.0) | æå‡ | å½“å‰ |
| ------------------ | ------------- | ------------- | ---- | ---- |
| VAD å‡†ç¡®ç‡         | ~85%          | > 95%         | +10% | -    |
| ä»»åŠ¡æŒä¹…åŒ–         | âŒ å†…å­˜       | âœ… Redis      | -    | -    |
| åˆ†å¸ƒå¼é™æµ         | âŒ æœ¬åœ°       | âœ… å…¨å±€       | -    | -    |
| æ¨¡å‹æ”¯æŒæ•°         | 5 å‚å•†        | 6 å‚å•†        | +1   | -    |
| æ–‡æ¡£å®‰å…¨æ‰«æ       | âŒ            | âœ… ClamAV     | -    | -    |
| éƒ¨ç½²æ—¶é—´           | ~30min        | < 5min        | -83% | -    |
| è®°å¿†å¬å›å‡†ç¡®ç‡     | ~70%          | > 85%         | +15% | -    |
| æƒ…æ„Ÿè¯†åˆ«å‡†ç¡®ç‡     | N/A           | > 80%         | -    | -    |
| Push é€šçŸ¥åˆ°è¾¾ç‡    | N/A           | > 95%         | -    | -    |
| æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†é‡‡ç”¨ç‡ | N/A           | > 50%         | -    | -    |

---

## ğŸš¨ é£é™©ç®¡ç†

### æŠ€æœ¯é£é™©

| é£é™©é¡¹              | ç­‰çº§ | å½±å“                 | ç¼“è§£æªæ–½                | è´£ä»»äºº  |
| ------------------- | ---- | -------------------- | ----------------------- | ------- |
| Silero VAD æ¨¡å‹ä½“ç§¯ | é«˜   | é•œåƒä½“ç§¯å¢åŠ  ~40MB   | ç‹¬ç«‹æ¨¡å‹æœåŠ¡ / æŒ‰éœ€åŠ è½½ | AI Team |
| æƒ…æ„Ÿè¯†åˆ«å®æ—¶æ€§      | é«˜   | æ¨ç†å»¶è¿Ÿå¯èƒ½ > 200ms | è½»é‡çº§æ¨¡å‹ / GPU åŠ é€Ÿ   | AI Team |
| Push é€šçŸ¥åˆè§„æ€§     | ä¸­   | ä¸åŒåœ°åŒºæ”¿ç­–å·®å¼‚     | åŒºåŸŸé…ç½® / åˆè§„å®¡è®¡     | Backend |
| æ–‡æ¡£ç‰ˆæœ¬å­˜å‚¨æˆæœ¬    | ä¸­   | å¤šç‰ˆæœ¬å­˜å‚¨æˆæœ¬ä¸Šå‡   | å‹ç¼©ç®—æ³• / ç‰ˆæœ¬æ•°é‡é™åˆ¶ | Backend |
| Redis å•ç‚¹æ•…éšœ      | ä¸­   | ä»»åŠ¡/é™æµä¸å¯ç”¨      | Redis Sentinel é«˜å¯ç”¨   | SRE     |
| CLI å·¥å…·å…¼å®¹æ€§      | ä½   | ä¸åŒ OS è„šæœ¬å·®å¼‚     | Go ç¼–å†™è·¨å¹³å° CLI       | Backend |

---

## ğŸ“š å‚è€ƒèµ„æ–™

### æŠ€æœ¯æ–‡æ¡£

- [Silero VAD GitHub](https://github.com/snakers4/silero-vad)
- [æ™ºè°± AI GLM-4 API](https://open.bigmodel.cn/dev/api)
- [ClamAV å®˜æ–¹æ–‡æ¡£](https://docs.clamav.net/)
- [FCM Documentation](https://firebase.google.com/docs/cloud-messaging)
- [APNs Documentation](https://developer.apple.com/documentation/usernotifications)
- [Redis åˆ†å¸ƒå¼é™æµ](https://redis.io/docs/manual/patterns/distributed-locks/)

### voicehelper å‚è€ƒ

- **GitHub**: https://github.com/haoyunlt/voicehelper
- **ç‰ˆæœ¬**: v0.9.2
- **å¯¹æ¯”æŠ¥å‘Š**: `docs/reports/voicehelper-feature-comparison.md`

---

## ğŸ“ å˜æ›´æ—¥å¿—

| æ—¥æœŸ       | ç‰ˆæœ¬   | å˜æ›´å†…å®¹ | ä½œè€…         |
| ---------- | ------ | -------- | ------------ |
| 2025-10-27 | v1.0.0 | åˆå§‹ç‰ˆæœ¬ | AI Assistant |

---

**æ–‡æ¡£æ‰€æœ‰è€…**: AI æ¶æ„å›¢é˜Ÿ
**ä¸‹æ¬¡å®¡æ ¸**: Sprint 1 ç»“æŸå
