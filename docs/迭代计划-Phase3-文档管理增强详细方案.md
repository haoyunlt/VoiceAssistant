# Phase 3: æ–‡æ¡£ç®¡ç†å¢å¼º - è¯¦ç»†å®æ–½æ–¹æ¡ˆ

---

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

- **é˜¶æ®µ**: Phase 3
- **æ—¶é—´**: Q1 2025, Week 9-12 (4å‘¨)
- **ç›®æ ‡**: å¢å¼ºæ–‡æ¡£å¤„ç†èƒ½åŠ›
- **ä¼˜å…ˆçº§**: ğŸŸ¡ P1 - ä¸­ä¼˜å…ˆçº§
- **å‰ç½®ä¾èµ–**: Phase 1 (API Gateway)ã€Phase 2 (è®¤è¯æˆæƒ)
- **è´Ÿè´£äºº**: åç«¯å¼€å‘ç»„
- **çŠ¶æ€**: ğŸ“‹ å¾…å¼€å§‹

---

## ğŸ¯ Phaseç›®æ ‡

### ä¸»è¦ç›®æ ‡
å¯¹é½VoiceHelperçš„Document Serviceèƒ½åŠ›ï¼Œå®ç°å®Œæ•´çš„æ–‡æ¡£ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼š
1. MinIOå¯¹è±¡å­˜å‚¨é›†æˆ
2. ClamAVç—…æ¯’æ‰«æ
3. å¼‚æ­¥å¤„ç†æµæ°´çº¿
4. æ–‡æ¡£çŠ¶æ€ç®¡ç†
5. æ™ºèƒ½åˆ†å—ä¼˜åŒ–

### æˆåŠŸæ ‡å‡†
1. âœ… MinIOæ­£å¸¸å·¥ä½œï¼Œæ–‡ä»¶æˆåŠŸä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨
2. âœ… ClamAVç—…æ¯’æ‰«æé›†æˆï¼Œæ¶æ„æ–‡ä»¶è¢«æ‹’ç»
3. âœ… å¼‚æ­¥å¤„ç†æµæ°´çº¿æ­£å¸¸ï¼ŒçŠ¶æ€æ­£ç¡®è½¬æ¢
4. âœ… æ–‡æ¡£çŠ¶æ€æœºå®Œæ•´ï¼Œæ”¯æŒ5ç§çŠ¶æ€
5. âœ… æ™ºèƒ½åˆ†å—ç®—æ³•ä¼˜åŒ–ï¼Œåˆ†å—è´¨é‡æå‡
6. âœ… å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 70%
7. âœ… é›†æˆæµ‹è¯•é€šè¿‡ç‡ 100%

---

## ğŸ“ æ¶æ„è®¾è®¡

### ç›®æ ‡æ¶æ„

```mermaid
flowchart TB
    Client[å®¢æˆ·ç«¯]

    subgraph KnowledgeService["Knowledge Service (Port 9003)"]
        Handler[Document Handler]

        subgraph CoreServices["æ ¸å¿ƒæœåŠ¡"]
            DocService[Document Service<br/>æ–‡æ¡£ç®¡ç†]
            StorageService[Storage Service<br/>å­˜å‚¨ç®¡ç†]
            VirusScanner[Virus Scanner<br/>ç—…æ¯’æ‰«æ]
            DocProcessor[Document Processor<br/>æ–‡æ¡£å¤„ç†]
            VectorService[Vector Service<br/>å‘é‡åŒ–]
        end

        subgraph Pipeline["å¤„ç†æµæ°´çº¿"]
            Upload[1. ä¸Šä¼ æ–‡ä»¶]
            Scan[2. ç—…æ¯’æ‰«æ]
            Extract[3. æ–‡æœ¬æå–]
            Chunk[4. æ™ºèƒ½åˆ†å—]
            Vectorize[5. å‘é‡åŒ–]
            Index[6. å»ºç«‹ç´¢å¼•]

            Upload --> Scan --> Extract --> Chunk --> Vectorize --> Index
        end

        Handler --> DocService
        DocService --> StorageService
        DocService --> VirusScanner
        DocService --> DocProcessor
        DocService --> VectorService
    end

    subgraph ExternalServices["å¤–éƒ¨æœåŠ¡"]
        MinIO[MinIO<br/>Port 9000]
        LocalStorage[Local Storage<br/>æœ¬åœ°å­˜å‚¨é™çº§]
        ClamAV[ClamAV<br/>Port 3310]
        Milvus[Milvus<br/>Port 19530]
    end

    subgraph Database["æ•°æ®å­˜å‚¨"]
        PostgreSQL[(PostgreSQL<br/>æ–‡æ¡£å…ƒæ•°æ®)]
    end

    Client --> Handler

    StorageService -->|ä¼˜å…ˆ| MinIO
    StorageService -->|é™çº§| LocalStorage
    VirusScanner --> ClamAV
    VectorService --> Milvus
    DocService --> PostgreSQL

    style Pipeline fill:#e1f5ff
    style CoreServices fill:#fff4e1
    style ExternalServices fill:#e1ffe1
```

### å¢å¼ºçš„Knowledge Serviceç»“æ„

```
cmd/knowledge-service/
â”œâ”€â”€ main.go
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.go
â””â”€â”€ internal/
    â”œâ”€â”€ handler/
    â”‚   â””â”€â”€ document_handler.go        # ç°æœ‰ï¼Œéœ€å¢å¼º
    â”œâ”€â”€ service/
    â”‚   â”œâ”€â”€ document_service.go        # ç°æœ‰ï¼Œéœ€å¢å¼º
    â”‚   â”œâ”€â”€ storage_service.go         # æ–°å¢ â­
    â”‚   â”œâ”€â”€ virus_scanner.go           # æ–°å¢ â­
    â”‚   â”œâ”€â”€ document_processor.go      # æ–°å¢ â­
    â”‚   â””â”€â”€ vector_service.go          # æ–°å¢ â­
    â”œâ”€â”€ worker/
    â”‚   â””â”€â”€ document_worker.go         # æ–°å¢ â­
    â”œâ”€â”€ repository/
    â”‚   â”œâ”€â”€ document_repository.go     # ç°æœ‰
    â”‚   â””â”€â”€ chunk_repository.go        # æ–°å¢ â­
    â””â”€â”€ model/
        â”œâ”€â”€ document.go                # ç°æœ‰ï¼Œéœ€å¢å¼º
        â””â”€â”€ document_chunk.go          # æ–°å¢ â­
```

---

## ğŸ“… è¯¦ç»†ä»»åŠ¡åˆ†è§£

### Week 1: MinIOå¯¹è±¡å­˜å‚¨é›†æˆï¼ˆ5å¤©ï¼‰

#### Task 1.1: MinIOéƒ¨ç½²ä¸é…ç½® (1å¤©)

**ç›®æ ‡**: éƒ¨ç½²MinIOåˆ°Kubernetes

**MinIO Deployment**:
```yaml
# deployments/k8s/infrastructure/minio/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: voiceassistant-prod
  labels:
    app: minio
spec:
  replicas: 1  # å•æœºæ¨¡å¼ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®4èŠ‚ç‚¹åˆ†å¸ƒå¼
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
      - name: minio
        image: minio/minio:RELEASE.2024-01-01T00-00-00Z
        args:
        - server
        - /data
        - --console-address
        - ":9001"
        ports:
        - containerPort: 9000
          name: api
        - containerPort: 9001
          name: console
        env:
        - name: MINIO_ROOT_USER
          valueFrom:
            secretKeyRef:
              name: minio-secrets
              key: root-user
        - name: MINIO_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: minio-secrets
              key: root-password
        volumeMounts:
        - name: data
          mountPath: /data
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /minio/health/live
            port: 9000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /minio/health/ready
            port: 9000
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: minio-pvc
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: minio-pvc
  namespace: voiceassistant-prod
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: standard
---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: voiceassistant-prod
spec:
  type: ClusterIP
  ports:
  - port: 9000
    targetPort: 9000
    name: api
  - port: 9001
    targetPort: 9001
    name: console
  selector:
    app: minio
---
apiVersion: v1
kind: Secret
metadata:
  name: minio-secrets
  namespace: voiceassistant-prod
type: Opaque
stringData:
  root-user: minioadmin
  root-password: minioadmin123
```

**éƒ¨ç½²MinIO**:
```bash
kubectl apply -f deployments/k8s/infrastructure/minio/

# ç­‰å¾…Podå°±ç»ª
kubectl wait --for=condition=ready pod -l app=minio -n voiceassistant-prod --timeout=300s

# è®¿é—®æ§åˆ¶å°ï¼ˆç«¯å£è½¬å‘ï¼‰
kubectl port-forward svc/minio 9001:9001 -n voiceassistant-prod

# è®¿é—® http://localhost:9001 (minioadmin/minioadmin123)
```

#### Task 1.2: å®ç°Storage Service (2å¤©)

**é…ç½®ç»“æ„**:
```go
// cmd/knowledge-service/config/config.go
type StorageConfig struct {
    Type         string `mapstructure:"type" default:"local"` // local or minio
    BasePath     string `mapstructure:"base_path" default:"./data/documents"`
    MinIO        MinIOConfig
}

type MinIOConfig struct {
    Endpoint   string `mapstructure:"endpoint" default:"minio:9000"`
    AccessKey  string `mapstructure:"access_key"`
    SecretKey  string `mapstructure:"secret_key"`
    Bucket     string `mapstructure:"bucket" default:"documents"`
    UseSSL     bool   `mapstructure:"use_ssl" default:"false"`
}
```

**Storage Serviceå®ç°**:
```go
// cmd/knowledge-service/internal/service/storage_service.go
package service

import (
    "bytes"
    "context"
    "fmt"
    "io"
    "os"
    "path/filepath"

    "github.com/minio/minio-go/v7"
    "github.com/minio/minio-go/v7/pkg/credentials"
    "github.com/sirupsen/logrus"
)

type StorageService struct {
    storageType  string // local/minio
    basePath     string // æœ¬åœ°å­˜å‚¨åŸºç¡€è·¯å¾„
    minioClient  *minio.Client
    minioBucket  string
    minioEnabled bool
    logger       *logrus.Logger
}

func NewStorageService(config *config.StorageConfig, logger *logrus.Logger) (*StorageService, error) {
    s := &StorageService{
        storageType:  config.Type,
        basePath:     config.BasePath,
        minioEnabled: false,
        logger:       logger,
    }

    // ç¡®ä¿æœ¬åœ°å­˜å‚¨ç›®å½•å­˜åœ¨
    if err := os.MkdirAll(s.basePath, 0755); err != nil {
        return nil, fmt.Errorf("failed to create base path: %w", err)
    }

    // å¦‚æœé…ç½®äº†MinIOï¼Œåˆå§‹åŒ–MinIOå®¢æˆ·ç«¯
    if config.Type == "minio" {
        if err := s.initMinIO(&config.MinIO); err != nil {
            logger.Warnf("MinIOåˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°å­˜å‚¨: %v", err)
            s.storageType = "local"
        } else {
            s.minioEnabled = true
            logger.Info("MinIOå­˜å‚¨å·²å¯ç”¨")
        }
    }

    return s, nil
}

// initMinIO åˆå§‹åŒ–MinIOå®¢æˆ·ç«¯
func (s *StorageService) initMinIO(config *config.MinIOConfig) error {
    // åˆ›å»ºMinIOå®¢æˆ·ç«¯
    minioClient, err := minio.New(config.Endpoint, &minio.Options{
        Creds:  credentials.NewStaticV4(config.AccessKey, config.SecretKey, ""),
        Secure: config.UseSSL,
    })
    if err != nil {
        return fmt.Errorf("failed to create minio client: %w", err)
    }

    s.minioClient = minioClient
    s.minioBucket = config.Bucket

    // æ£€æŸ¥bucketæ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
    ctx := context.Background()
    exists, err := minioClient.BucketExists(ctx, config.Bucket)
    if err != nil {
        return fmt.Errorf("failed to check bucket: %w", err)
    }

    if !exists {
        if err := minioClient.MakeBucket(ctx, config.Bucket, minio.MakeBucketOptions{}); err != nil {
            return fmt.Errorf("failed to create bucket: %w", err)
        }
        s.logger.Infof("åˆ›å»ºMinIO bucket: %s", config.Bucket)
    }

    return nil
}

// Upload ä¸Šä¼ æ–‡ä»¶ï¼ˆè‡ªåŠ¨é€‰æ‹©å­˜å‚¨æ–¹å¼ï¼‰
func (s *StorageService) Upload(ctx context.Context, fileName string, content []byte) (string, error) {
    if s.minioEnabled {
        return s.uploadToMinIO(ctx, fileName, content)
    }
    return s.uploadToLocal(ctx, fileName, content)
}

// uploadToMinIO ä¸Šä¼ åˆ°MinIO
func (s *StorageService) uploadToMinIO(ctx context.Context, fileName string, content []byte) (string, error) {
    _, err := s.minioClient.PutObject(
        ctx,
        s.minioBucket,
        fileName,
        bytes.NewReader(content),
        int64(len(content)),
        minio.PutObjectOptions{
            ContentType: "application/octet-stream",
        },
    )
    if err != nil {
        return "", fmt.Errorf("failed to upload to MinIO: %w", err)
    }

    // è¿”å›MinIO URL
    url := fmt.Sprintf("minio://%s/%s", s.minioBucket, fileName)

    s.logger.WithFields(logrus.Fields{
        "file_name": fileName,
        "size":      len(content),
        "storage":   "minio",
    }).Info("File uploaded")

    return url, nil
}

// uploadToLocal ä¸Šä¼ åˆ°æœ¬åœ°å­˜å‚¨
func (s *StorageService) uploadToLocal(ctx context.Context, fileName string, content []byte) (string, error) {
    filePath := filepath.Join(s.basePath, fileName)

    if err := os.WriteFile(filePath, content, 0644); err != nil {
        return "", fmt.Errorf("failed to write file: %w", err)
    }

    s.logger.WithFields(logrus.Fields{
        "file_name": fileName,
        "size":      len(content),
        "storage":   "local",
    }).Info("File uploaded")

    return filePath, nil
}

// Download ä¸‹è½½æ–‡ä»¶
func (s *StorageService) Download(ctx context.Context, fileURL string) ([]byte, error) {
    // åˆ¤æ–­æ˜¯MinIO URLè¿˜æ˜¯æœ¬åœ°è·¯å¾„
    if s.isMinIOURL(fileURL) {
        return s.downloadFromMinIO(ctx, fileURL)
    }
    return s.downloadFromLocal(ctx, fileURL)
}

// downloadFromMinIO ä»MinIOä¸‹è½½
func (s *StorageService) downloadFromMinIO(ctx context.Context, fileURL string) ([]byte, error) {
    // è§£æMinIO URL: minio://bucket/filename
    fileName := s.extractFileNameFromMinIOURL(fileURL)

    object, err := s.minioClient.GetObject(ctx, s.minioBucket, fileName, minio.GetObjectOptions{})
    if err != nil {
        return nil, fmt.Errorf("failed to get object: %w", err)
    }
    defer object.Close()

    content, err := io.ReadAll(object)
    if err != nil {
        return nil, fmt.Errorf("failed to read object: %w", err)
    }

    return content, nil
}

// downloadFromLocal ä»æœ¬åœ°ä¸‹è½½
func (s *StorageService) downloadFromLocal(ctx context.Context, filePath string) ([]byte, error) {
    content, err := os.ReadFile(filePath)
    if err != nil {
        return nil, fmt.Errorf("failed to read file: %w", err)
    }

    return content, nil
}

// Delete åˆ é™¤æ–‡ä»¶
func (s *StorageService) Delete(ctx context.Context, fileURL string) error {
    if s.isMinIOURL(fileURL) {
        return s.deleteFromMinIO(ctx, fileURL)
    }
    return s.deleteFromLocal(ctx, fileURL)
}

// deleteFromMinIO ä»MinIOåˆ é™¤
func (s *StorageService) deleteFromMinIO(ctx context.Context, fileURL string) error {
    fileName := s.extractFileNameFromMinIOURL(fileURL)

    if err := s.minioClient.RemoveObject(ctx, s.minioBucket, fileName, minio.RemoveObjectOptions{}); err != nil {
        return fmt.Errorf("failed to remove object: %w", err)
    }

    return nil
}

// deleteFromLocal ä»æœ¬åœ°åˆ é™¤
func (s *StorageService) deleteFromLocal(ctx context.Context, filePath string) error {
    if err := os.Remove(filePath); err != nil {
        return fmt.Errorf("failed to remove file: %w", err)
    }

    return nil
}

// isMinIOURL åˆ¤æ–­æ˜¯å¦ä¸ºMinIO URL
func (s *StorageService) isMinIOURL(url string) bool {
    return len(url) > 8 && url[:8] == "minio://"
}

// extractFileNameFromMinIOURL ä»MinIO URLæå–æ–‡ä»¶å
// minio://bucket/filename -> filename
func (s *StorageService) extractFileNameFromMinIOURL(url string) string {
    // minio://bucket/filename
    parts := strings.Split(url, "/")
    if len(parts) >= 4 {
        return strings.Join(parts[3:], "/")
    }
    return ""
}
```

**å•å…ƒæµ‹è¯•**:
```go
// cmd/knowledge-service/internal/service/storage_service_test.go
package service_test

import (
    "context"
    "testing"

    "github.com/stretchr/testify/assert"

    "voiceassistant/cmd/knowledge-service/config"
    "voiceassistant/cmd/knowledge-service/internal/service"
)

func TestStorageService_LocalStorage(t *testing.T) {
    cfg := &config.StorageConfig{
        Type:     "local",
        BasePath: "./testdata",
    }

    storageService, err := service.NewStorageService(cfg, logrus.New())
    assert.NoError(t, err)
    defer os.RemoveAll("./testdata")

    ctx := context.Background()

    // æµ‹è¯•ä¸Šä¼ 
    content := []byte("test content")
    fileURL, err := storageService.Upload(ctx, "test.txt", content)
    assert.NoError(t, err)
    assert.NotEmpty(t, fileURL)

    // æµ‹è¯•ä¸‹è½½
    downloaded, err := storageService.Download(ctx, fileURL)
    assert.NoError(t, err)
    assert.Equal(t, content, downloaded)

    // æµ‹è¯•åˆ é™¤
    err = storageService.Delete(ctx, fileURL)
    assert.NoError(t, err)
}
```

#### Task 1.3: é›†æˆåˆ°Document Handler (2å¤©)

**æ›´æ–°Documentæ¨¡å‹**:
```go
// cmd/knowledge-service/internal/model/document.go
package model

import "time"

type Document struct {
    ID          string    `json:"id" gorm:"primaryKey"`
    UserID      string    `json:"user_id" gorm:"index;not null"`
    TenantID    string    `json:"tenant_id" gorm:"index"`
    Title       string    `json:"title" gorm:"not null"`
    FileName    string    `json:"file_name"`
    FileType    string    `json:"file_type"`
    FileSize    int64     `json:"file_size"`
    FilePath    string    `json:"file_path"`    // MinIO URLæˆ–æœ¬åœ°è·¯å¾„
    Status      string    `json:"status" gorm:"index;default:'uploaded'"` // æ–°å¢çŠ¶æ€å­—æ®µ â­
    ErrorMsg    string    `json:"error_msg"`    // æ–°å¢é”™è¯¯ä¿¡æ¯ â­
    ChunkCount  int       `json:"chunk_count"`  // æ–°å¢åˆ†å—æ•°é‡ â­
    CreatedAt   time.Time `json:"created_at"`
    UpdatedAt   time.Time `json:"updated_at"`
}

// æ–‡æ¡£çŠ¶æ€å¸¸é‡
const (
    StatusUploaded   = "uploaded"    // å·²ä¸Šä¼ 
    StatusProcessing = "processing"  // å¤„ç†ä¸­
    StatusCompleted  = "completed"   // å·²å®Œæˆ
    StatusFailed     = "failed"      // å¤±è´¥
    StatusInfected   = "infected"    // å‘ç°ç—…æ¯’
)
```

**æ›´æ–°Document Handler**:
```go
// cmd/knowledge-service/internal/handler/document_handler.go
func (h *DocumentHandler) Upload(c *gin.Context) {
    // 1. è·å–ç”¨æˆ·ä¿¡æ¯
    userID := c.GetString("user_id")
    tenantID := c.GetString("tenant_id")

    // 2. è¯»å–ä¸Šä¼ æ–‡ä»¶
    file, header, err := c.Request.FormFile("file")
    if err != nil {
        c.JSON(400, gin.H{"code": 400, "message": "Failed to read file"})
        return
    }
    defer file.Close()

    // 3. éªŒè¯æ–‡ä»¶å¤§å°
    maxSize := int64(100 * 1024 * 1024) // 100MB
    if header.Size > maxSize {
        c.JSON(400, gin.H{"code": 400, "message": "File too large"})
        return
    }

    // 4. ç”Ÿæˆæ–‡æ¡£IDå’Œæ–‡ä»¶å
    documentID := uuid.New().String()
    fileExt := filepath.Ext(header.Filename)
    fileName := documentID + fileExt

    // 5. è¯»å–æ–‡ä»¶å†…å®¹
    fileContent, err := io.ReadAll(file)
    if err != nil {
        c.JSON(500, gin.H{"code": 500, "message": "Failed to read file content"})
        return
    }

    // 6. ä¸Šä¼ åˆ°å­˜å‚¨ï¼ˆMinIOæˆ–æœ¬åœ°ï¼‰
    fileURL, err := h.storageService.Upload(c.Request.Context(), fileName, fileContent)
    if err != nil {
        c.JSON(500, gin.H{"code": 500, "message": "Failed to upload file"})
        return
    }

    // 7. åˆ›å»ºæ–‡æ¡£è®°å½•
    document := &model.Document{
        ID:        documentID,
        UserID:    userID,
        TenantID:  tenantID,
        Title:     header.Filename,
        FileName:  header.Filename,
        FileType:  fileExt[1:],
        FileSize:  header.Size,
        FilePath:  fileURL,
        Status:    model.StatusUploaded,
        CreatedAt: time.Now(),
        UpdatedAt: time.Now(),
    }

    if err := h.documentService.CreateDocument(c.Request.Context(), document); err != nil {
        c.JSON(500, gin.H{"code": 500, "message": "Failed to create document"})
        return
    }

    // 8. å¼‚æ­¥å¤„ç†æ–‡æ¡£ï¼ˆç—…æ¯’æ‰«æã€æ–‡æœ¬æå–ã€å‘é‡åŒ–ï¼‰
    go h.documentWorker.ProcessDocument(context.Background(), documentID)

    c.JSON(201, gin.H{
        "code":    201,
        "message": "Document uploaded successfully",
        "data":    gin.H{"document": document},
    })
}
```

**äº¤ä»˜ç‰©**:
- âœ… MinIO Kuberneteséƒ¨ç½²æ–‡ä»¶
- âœ… StorageServiceå®Œæ•´å®ç°
- âœ… Documentæ¨¡å‹å¢å¼ºï¼ˆStatuså­—æ®µï¼‰
- âœ… Document Handleræ›´æ–°
- âœ… å•å…ƒæµ‹è¯•
- âœ… é…ç½®æ–‡æ¡£

---

### Week 2: ClamAVç—…æ¯’æ‰«æï¼ˆ5å¤©ï¼‰

#### Task 2.1: ClamAVéƒ¨ç½² (1å¤©)

**ClamAV Deployment**:
```yaml
# deployments/k8s/infrastructure/clamav/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: clamav
  namespace: voiceassistant-prod
  labels:
    app: clamav
spec:
  replicas: 2
  selector:
    matchLabels:
      app: clamav
  template:
    metadata:
      labels:
        app: clamav
    spec:
      containers:
      - name: clamav
        image: clamav/clamav:latest
        ports:
        - containerPort: 3310
          name: clamd
        env:
        - name: CLAMAV_NO_FRESHCLAM
          value: "false"
        - name: FRESHCLAM_CHECKS
          value: "24"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        volumeMounts:
        - name: virus-db
          mountPath: /var/lib/clamav
        livenessProbe:
          tcpSocket:
            port: 3310
          initialDelaySeconds: 120
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - /usr/local/bin/clamdcheck.sh
          initialDelaySeconds: 120
          periodSeconds: 30
      volumes:
      - name: virus-db
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: clamav
  namespace: voiceassistant-prod
spec:
  type: ClusterIP
  ports:
  - port: 3310
    targetPort: 3310
    name: clamd
  selector:
    app: clamav
```

**éƒ¨ç½²ClamAV**:
```bash
kubectl apply -f deployments/k8s/infrastructure/clamav/

# ç­‰å¾…ç—…æ¯’åº“æ›´æ–°å®Œæˆï¼ˆå¯èƒ½éœ€è¦10-15åˆ†é’Ÿï¼‰
kubectl logs -f deployment/clamav -n voiceassistant-prod
```

#### Task 2.2: å®ç°Virus Scanner (2å¤©)

**Virus Scannerå®ç°**:
```go
// cmd/knowledge-service/internal/service/virus_scanner.go
package service

import (
    "context"
    "fmt"
    "os/exec"
    "strings"
    "time"

    "github.com/sirupsen/logrus"
)

type VirusScanner struct {
    enabled        bool
    scannerType    string // "clamav" or "mock"
    clamavHost     string
    clamavPort     int
    maxFileSize    int64
    scanTimeout    time.Duration
    logger         *logrus.Logger
}

type ScanResult struct {
    IsClean      bool
    VirusFound   string
    ScanDuration time.Duration
    Scanner      string
    Timestamp    time.Time
}

func NewVirusScanner(config *config.VirusScanConfig, logger *logrus.Logger) *VirusScanner {
    scanner := &VirusScanner{
        enabled:      config.Enabled,
        scannerType:  config.Type,
        clamavHost:   config.ClamAVHost,
        clamavPort:   config.ClamAVPort,
        maxFileSize:  config.MaxFileSize,
        scanTimeout:  config.ScanTimeout,
        logger:       logger,
    }

    if scanner.enabled {
        logger.Infof("ç—…æ¯’æ‰«æå·²å¯ç”¨: type=%s", scanner.scannerType)
    } else {
        logger.Info("ç—…æ¯’æ‰«ææœªå¯ç”¨")
    }

    return scanner
}

// ScanFile æ‰«ææ–‡ä»¶
func (s *VirusScanner) ScanFile(ctx context.Context, filePath string, fileContent []byte) (*ScanResult, error) {
    start := time.Now()

    // å¦‚æœæœªå¯ç”¨ï¼Œè¿”å›cleanç»“æœ
    if !s.enabled {
        return &ScanResult{
            IsClean:      true,
            Scanner:      "disabled",
            ScanDuration: time.Since(start),
            Timestamp:    time.Now(),
        }, nil
    }

    // æ£€æŸ¥æ–‡ä»¶å¤§å°
    if int64(len(fileContent)) > s.maxFileSize {
        return nil, fmt.Errorf("æ–‡ä»¶è¿‡å¤§: %d bytes (max: %d)",
            len(fileContent), s.maxFileSize)
    }

    // æ ¹æ®scannerç±»å‹è°ƒç”¨ä¸åŒçš„æ‰«ææ–¹æ³•
    var result *ScanResult
    var err error

    switch s.scannerType {
    case "clamav":
        result, err = s.scanWithClamAV(ctx, filePath, fileContent)
    case "mock":
        result, err = s.scanWithMock(ctx, filePath, fileContent)
    default:
        result, err = s.scanWithMock(ctx, filePath, fileContent)
    }

    if err != nil {
        return nil, err
    }

    result.ScanDuration = time.Since(start)
    result.Timestamp = time.Now()

    s.logger.WithFields(logrus.Fields{
        "file_path": filePath,
        "is_clean":  result.IsClean,
        "virus":     result.VirusFound,
        "duration":  result.ScanDuration.Milliseconds(),
    }).Info("File scanned")

    return result, nil
}

// scanWithClamAV ä½¿ç”¨ClamAVæ‰«æ
func (s *VirusScanner) scanWithClamAV(ctx context.Context, filePath string, fileContent []byte) (*ScanResult, error) {
    // åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    tmpFile, err := os.CreateTemp("", "scan-*.tmp")
    if err != nil {
        return nil, err
    }
    defer os.Remove(tmpFile.Name())

    if _, err := tmpFile.Write(fileContent); err != nil {
        return nil, err
    }
    tmpFile.Close()

    // ä½¿ç”¨clamdscanå‘½ä»¤æ‰«æ
    ctx, cancel := context.WithTimeout(ctx, s.scanTimeout)
    defer cancel()

    cmd := exec.CommandContext(ctx,
        "clamdscan",
        "--fdpass",
        "--no-summary",
        tmpFile.Name(),
    )

    output, err := cmd.CombinedOutput()
    outputStr := string(output)

    if err != nil {
        // clamdscanè¿”å›1è¡¨ç¤ºå‘ç°ç—…æ¯’
        if strings.Contains(outputStr, "FOUND") {
            virusName := s.extractVirusName(outputStr)
            return &ScanResult{
                IsClean:    false,
                VirusFound: virusName,
                Scanner:    "clamav",
            }, nil
        }
        return nil, fmt.Errorf("clamdscan failed: %w, output: %s", err, outputStr)
    }

    // æ‰«æé€šè¿‡
    return &ScanResult{
        IsClean: true,
        Scanner: "clamav",
    }, nil
}

// scanWithMock Mockæ‰«æï¼ˆç”¨äºå¼€å‘/æµ‹è¯•ï¼‰
func (s *VirusScanner) scanWithMock(ctx context.Context, filePath string, fileContent []byte) (*ScanResult, error) {
    // æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«"virus"æˆ–"eicar"ï¼ˆEICARæµ‹è¯•æ–‡ä»¶ï¼‰
    if strings.Contains(strings.ToLower(filePath), "virus") ||
       strings.Contains(strings.ToLower(filePath), "eicar") ||
       bytes.Contains(fileContent, []byte("X5O!P%@AP[4\\PZX54(P^)7CC)7}$EICAR")) {
        return &ScanResult{
            IsClean:    false,
            VirusFound: "Test.Virus.EICAR",
            Scanner:    "mock",
        }, nil
    }

    return &ScanResult{
        IsClean: true,
        Scanner: "mock",
    }, nil
}

// extractVirusName ä»ClamAVè¾“å‡ºæå–ç—…æ¯’åç§°
func (s *VirusScanner) extractVirusName(output string) string {
    // è¾“å‡ºæ ¼å¼: /path/to/file: Virus.Name FOUND
    lines := strings.Split(output, "\n")
    for _, line := range lines {
        if strings.Contains(line, "FOUND") {
            parts := strings.Split(line, ":")
            if len(parts) >= 2 {
                virusInfo := strings.TrimSpace(parts[1])
                virusName := strings.Replace(virusInfo, " FOUND", "", 1)
                return strings.TrimSpace(virusName)
            }
        }
    }
    return "Unknown"
}
```

**é…ç½®**:
```yaml
# configs/knowledge-service.yaml
virus_scan:
  enabled: true
  type: "clamav"  # clamav or mock
  clamav_host: "clamav.voiceassistant-prod.svc.cluster.local"
  clamav_port: 3310
  max_file_size: 104857600  # 100MB
  scan_timeout: "30s"
```

#### Task 2.3: é›†æˆåˆ°å¤„ç†æµæ°´çº¿ (2å¤©)

**Document Workerå®ç°**:
```go
// cmd/knowledge-service/internal/worker/document_worker.go
package worker

import (
    "context"

    "voiceassistant/cmd/knowledge-service/internal/model"
    "voiceassistant/cmd/knowledge-service/internal/service"
)

type DocumentWorker struct {
    documentService   *service.DocumentService
    storageService    *service.StorageService
    virusScanner      *service.VirusScanner
    documentProcessor *service.DocumentProcessor
    vectorService     *service.VectorService
    logger            *logrus.Logger
}

func NewDocumentWorker(
    documentService *service.DocumentService,
    storageService *service.StorageService,
    virusScanner *service.VirusScanner,
    documentProcessor *service.DocumentProcessor,
    vectorService *service.VectorService,
    logger *logrus.Logger,
) *DocumentWorker {
    return &DocumentWorker{
        documentService:   documentService,
        storageService:    storageService,
        virusScanner:      virusScanner,
        documentProcessor: documentProcessor,
        vectorService:     vectorService,
        logger:            logger,
    }
}

// ProcessDocument å¤„ç†æ–‡æ¡£
func (w *DocumentWorker) ProcessDocument(ctx context.Context, documentID string) error {
    w.logger.WithField("document_id", documentID).Info("å¼€å§‹å¤„ç†æ–‡æ¡£")

    // 1. æ›´æ–°çŠ¶æ€: processing
    if err := w.documentService.UpdateStatus(ctx, documentID, model.StatusProcessing, ""); err != nil {
        return err
    }

    // 2. è·å–æ–‡æ¡£ä¿¡æ¯
    document, err := w.documentService.GetDocument(ctx, documentID)
    if err != nil {
        return err
    }

    // 3. ä¸‹è½½æ–‡ä»¶
    fileContent, err := w.storageService.Download(ctx, document.FilePath)
    if err != nil {
        w.documentService.UpdateStatus(ctx, documentID, model.StatusFailed,
            fmt.Sprintf("ä¸‹è½½å¤±è´¥: %v", err))
        return err
    }

    // 4. ç—…æ¯’æ‰«æ
    scanResult, err := w.virusScanner.ScanFile(ctx, document.FilePath, fileContent)
    if err != nil {
        w.documentService.UpdateStatus(ctx, documentID, model.StatusFailed,
            fmt.Sprintf("æ‰«æå¤±è´¥: %v", err))
        return err
    }

    if !scanResult.IsClean {
        // å‘ç°ç—…æ¯’ï¼Œæ›´æ–°çŠ¶æ€å¹¶åœæ­¢å¤„ç†
        w.documentService.UpdateStatus(ctx, documentID, model.StatusInfected,
            fmt.Sprintf("å‘ç°ç—…æ¯’: %s", scanResult.VirusFound))
        w.logger.WithFields(logrus.Fields{
            "document_id": documentID,
            "virus":       scanResult.VirusFound,
        }).Warn("æ–‡æ¡£åŒ…å«ç—…æ¯’")
        return nil
    }

    // 5. æ–‡æ¡£å¤„ç†ï¼ˆæ–‡æœ¬æå–ã€åˆ†å—ï¼‰
    processed, err := w.documentProcessor.ProcessDocument(ctx, document.FilePath, document.FileType, fileContent)
    if err != nil {
        w.documentService.UpdateStatus(ctx, documentID, model.StatusFailed,
            fmt.Sprintf("å¤„ç†å¤±è´¥: %v", err))
        return err
    }

    // 6. å‘é‡åŒ–å¹¶ä¿å­˜
    if err := w.generateAndSaveEmbeddings(ctx, documentID, document, processed.Chunks); err != nil {
        w.documentService.UpdateStatus(ctx, documentID, model.StatusFailed,
            fmt.Sprintf("å‘é‡åŒ–å¤±è´¥: %v", err))
        return err
    }

    // 7. æ›´æ–°çŠ¶æ€: completed
    if err := w.documentService.UpdateStatusWithChunks(ctx, documentID, model.StatusCompleted, "", len(processed.Chunks)); err != nil {
        return err
    }

    w.logger.WithFields(logrus.Fields{
        "document_id": documentID,
        "chunks":      len(processed.Chunks),
    }).Info("æ–‡æ¡£å¤„ç†å®Œæˆ")

    return nil
}

// generateAndSaveEmbeddings ç”Ÿæˆå¹¶ä¿å­˜Embeddings
func (w *DocumentWorker) generateAndSaveEmbeddings(
    ctx context.Context,
    documentID string,
    document *model.Document,
    chunks []string,
) error {
    w.logger.Infof("ç”Ÿæˆembeddings: %s (%d chunks)", documentID, len(chunks))

    for i, chunk := range chunks {
        chunkID := fmt.Sprintf("%s_chunk_%d", documentID, i)

        // ç”Ÿæˆembedding
        embedding, err := w.vectorService.GenerateEmbedding(ctx, chunk)
        if err != nil {
            w.logger.Warnf("ç”Ÿæˆembeddingå¤±è´¥ (chunk %d): %v", i, err)
            continue
        }

        // ä¿å­˜chunkåˆ°æ•°æ®åº“
        chunkModel := &model.DocumentChunk{
            ID:         chunkID,
            DocumentID: documentID,
            ChunkIndex: i,
            Content:    chunk,
            CreatedAt:  time.Now(),
        }

        if err := w.documentService.SaveChunk(ctx, chunkModel); err != nil {
            w.logger.Warnf("ä¿å­˜chunkå¤±è´¥: %v", err)
            continue
        }

        // ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        if err := w.vectorService.InsertVector(ctx, chunkID, embedding); err != nil {
            w.logger.Warnf("ä¿å­˜å‘é‡å¤±è´¥: %v", err)
            continue
        }
    }

    return nil
}
```

**äº¤ä»˜ç‰©**:
- âœ… ClamAV Kuberneteséƒ¨ç½²æ–‡ä»¶
- âœ… VirusScannerå®Œæ•´å®ç°
- âœ… DocumentWorkerå®ç°ï¼ˆåŒ…å«ç—…æ¯’æ‰«æï¼‰
- âœ… ç—…æ¯’æ£€æµ‹æµ‹è¯•ï¼ˆEICARæµ‹è¯•æ–‡ä»¶ï¼‰
- âœ… é…ç½®æ–‡æ¡£

---

### Week 3: æ–‡æ¡£å¤„ç†ä¸æ™ºèƒ½åˆ†å—ï¼ˆ5å¤©ï¼‰

#### Task 3.1: å®ç°Document Processor (2å¤©)

**Document Processorå®ç°**:
```go
// cmd/knowledge-service/internal/service/document_processor.go
package service

import (
    "bytes"
    "context"
    "fmt"
    "strings"

    "github.com/ledongthuc/pdf"
    "github.com/sirupsen/logrus"
)

type DocumentProcessor struct {
    storageService *StorageService
    maxChunkSize   int
    chunkOverlap   int
    minChunkSize   int
    logger         *logrus.Logger
}

type ProcessedDocument struct {
    FullText   string
    Chunks     []string
    ChunkCount int
    CharCount  int
}

func NewDocumentProcessor(storageService *StorageService, logger *logrus.Logger) *DocumentProcessor {
    return &DocumentProcessor{
        storageService: storageService,
        maxChunkSize:   1000, // æ¯ä¸ªchunkæœ€å¤š1000ä¸ªå­—ç¬¦
        chunkOverlap:   200,  // chunkä¹‹é—´é‡å 200ä¸ªå­—ç¬¦
        minChunkSize:   100,  // æœ€å°chunkå¤§å°
        logger:         logger,
    }
}

// ProcessDocument å¤„ç†æ–‡æ¡£
func (p *DocumentProcessor) ProcessDocument(
    ctx context.Context,
    filePath, fileType string,
    fileContent []byte,
) (*ProcessedDocument, error) {
    p.logger.WithFields(logrus.Fields{
        "file_path": filePath,
        "file_type": fileType,
        "file_size": len(fileContent),
    }).Info("å¼€å§‹å¤„ç†æ–‡æ¡£")

    // 1. æ ¹æ®æ–‡ä»¶ç±»å‹æå–æ–‡æœ¬
    text, err := p.extractText(fileContent, fileType)
    if err != nil {
        return nil, fmt.Errorf("æ–‡æœ¬æå–å¤±è´¥: %w", err)
    }

    // 2. æ–‡æœ¬åˆ†å—
    chunks := p.splitTextIntoChunks(text)

    p.logger.WithFields(logrus.Fields{
        "file_path": filePath,
        "chars":     len(text),
        "chunks":    len(chunks),
    }).Info("æ–‡æ¡£å¤„ç†å®Œæˆ")

    return &ProcessedDocument{
        FullText:   text,
        Chunks:     chunks,
        ChunkCount: len(chunks),
        CharCount:  len(text),
    }, nil
}

// extractText æå–æ–‡æœ¬
func (p *DocumentProcessor) extractText(fileContent []byte, fileType string) (string, error) {
    switch strings.ToLower(fileType) {
    case "pdf":
        return p.extractTextFromPDF(fileContent)
    case "txt", "text":
        return string(fileContent), nil
    case "md", "markdown":
        return string(fileContent), nil
    case "html", "htm":
        return p.extractTextFromHTML(fileContent)
    default:
        // å°è¯•ä½œä¸ºçº¯æ–‡æœ¬å¤„ç†
        return string(fileContent), nil
    }
}

// extractTextFromPDF ä»PDFæå–æ–‡æœ¬
func (p *DocumentProcessor) extractTextFromPDF(content []byte) (string, error) {
    bytesReader := bytes.NewReader(content)
    reader, err := pdf.NewReader(bytesReader, int64(len(content)))
    if err != nil {
        return "", err
    }

    var text strings.Builder
    numPages := reader.NumPage()

    for pageNum := 1; pageNum <= numPages; pageNum++ {
        page := reader.Page(pageNum)
        if page.V.IsNull() {
            continue
        }

        pageText, err := page.GetPlainText(nil)
        if err != nil {
            p.logger.Warnf("æå–ç¬¬%dé¡µå¤±è´¥: %v", pageNum, err)
            continue
        }

        text.WriteString(pageText)
        text.WriteString("\n\n")
    }

    return text.String(), nil
}

// extractTextFromHTML ä»HTMLæå–æ–‡æœ¬
func (p *DocumentProcessor) extractTextFromHTML(content []byte) (string, error) {
    // ç®€å•å®ç°ï¼šç§»é™¤HTMLæ ‡ç­¾
    text := string(content)
    text = strings.ReplaceAll(text, "<script", "<removed")
    text = strings.ReplaceAll(text, "</script>", "</removed>")
    text = strings.ReplaceAll(text, "<style", "<removed")
    text = strings.ReplaceAll(text, "</style>", "</removed>")

    // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤æ ‡ç­¾
    re := regexp.MustCompile(`<[^>]*>`)
    text = re.ReplaceAllString(text, " ")

    // æ¸…ç†å¤šä½™ç©ºç™½
    text = strings.Join(strings.Fields(text), " ")

    return text, nil
}

// splitTextIntoChunks æ™ºèƒ½åˆ†å—
func (p *DocumentProcessor) splitTextIntoChunks(text string) []string {
    var chunks []string

    // å¦‚æœæ–‡æœ¬çŸ­äºmaxChunkSizeï¼Œç›´æ¥è¿”å›
    if len(text) <= p.maxChunkSize {
        if len(text) >= p.minChunkSize {
            return []string{text}
        }
        return []string{}
    }

    // æ»‘åŠ¨çª—å£åˆ†å—
    for i := 0; i < len(text); i += p.maxChunkSize - p.chunkOverlap {
        end := i + p.maxChunkSize
        if end > len(text) {
            end = len(text)
        }

        chunk := text[i:end]

        // åªä¿ç•™è¾¾åˆ°æœ€å°å¤§å°çš„chunk
        if len(chunk) >= p.minChunkSize {
            chunks = append(chunks, chunk)
        }

        // å¦‚æœå·²ç»åˆ°è¾¾æœ«å°¾ï¼Œé€€å‡º
        if end == len(text) {
            break
        }
    }

    return chunks
}
```

#### Task 3.2: ä¼˜åŒ–åˆ†å—ç®—æ³• (2å¤©)

**è¯­ä¹‰è¾¹ç•Œåˆ†å—**:
```go
// splitTextIntoChunksWithSemanticBoundary è¯­ä¹‰è¾¹ç•Œåˆ†å—
func (p *DocumentProcessor) splitTextIntoChunksWithSemanticBoundary(text string) []string {
    var chunks []string

    // 1. æŒ‰æ®µè½åˆ†å‰²
    paragraphs := p.splitIntoParagraphs(text)

    currentChunk := ""

    for _, para := range paragraphs {
        // å¦‚æœå½“å‰chunk + æ®µè½ <= maxChunkSizeï¼Œæ·»åŠ æ®µè½
        if len(currentChunk)+len(para) <= p.maxChunkSize {
            if currentChunk != "" {
                currentChunk += "\n\n"
            }
            currentChunk += para
        } else {
            // ä¿å­˜å½“å‰chunk
            if len(currentChunk) >= p.minChunkSize {
                chunks = append(chunks, currentChunk)
            }

            // å¼€å§‹æ–°chunk
            if len(para) <= p.maxChunkSize {
                currentChunk = para
            } else {
                // æ®µè½å¤ªé•¿ï¼ŒæŒ‰å¥å­åˆ†å‰²
                sentences := p.splitIntoSentences(para)
                currentChunk = ""
                for _, sent := range sentences {
                    if len(currentChunk)+len(sent) <= p.maxChunkSize {
                        if currentChunk != "" {
                            currentChunk += " "
                        }
                        currentChunk += sent
                    } else {
                        if len(currentChunk) >= p.minChunkSize {
                            chunks = append(chunks, currentChunk)
                        }
                        currentChunk = sent
                    }
                }
            }
        }
    }

    // ä¿å­˜æœ€åä¸€ä¸ªchunk
    if len(currentChunk) >= p.minChunkSize {
        chunks = append(chunks, currentChunk)
    }

    return chunks
}

// splitIntoParagraphs æŒ‰æ®µè½åˆ†å‰²
func (p *DocumentProcessor) splitIntoParagraphs(text string) []string {
    // æŒ‰åŒæ¢è¡Œç¬¦åˆ†å‰²
    paragraphs := strings.Split(text, "\n\n")

    // æ¸…ç†ç©ºæ®µè½
    var result []string
    for _, para := range paragraphs {
        para = strings.TrimSpace(para)
        if para != "" {
            result = append(result, para)
        }
    }

    return result
}

// splitIntoSentences æŒ‰å¥å­åˆ†å‰²
func (p *DocumentProcessor) splitIntoSentences(text string) []string {
    // ç®€å•å®ç°ï¼šæŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
    text = strings.ReplaceAll(text, "ã€‚", "ã€‚\n")
    text = strings.ReplaceAll(text, "ï¼", "ï¼\n")
    text = strings.ReplaceAll(text, "ï¼Ÿ", "ï¼Ÿ\n")
    text = strings.ReplaceAll(text, ". ", ".\n")
    text = strings.ReplaceAll(text, "! ", "!\n")
    text = strings.ReplaceAll(text, "? ", "?\n")

    sentences := strings.Split(text, "\n")

    // æ¸…ç†ç©ºå¥å­
    var result []string
    for _, sent := range sentences {
        sent = strings.TrimSpace(sent)
        if sent != "" {
            result = append(result, sent)
        }
    }

    return result
}
```

#### Task 3.3: æ–‡æ¡£çŠ¶æ€ç®¡ç†API (1å¤©)

**æ–°å¢APIç«¯ç‚¹**:
```go
// cmd/knowledge-service/internal/handler/document_handler.go

// GetDocumentStatus è·å–æ–‡æ¡£çŠ¶æ€
func (h *DocumentHandler) GetDocumentStatus(c *gin.Context) {
    documentID := c.Param("id")

    document, err := h.documentService.GetDocument(c.Request.Context(), documentID)
    if err != nil {
        c.JSON(404, gin.H{"code": 404, "message": "Document not found"})
        return
    }

    c.JSON(200, gin.H{
        "code":    200,
        "message": "Success",
        "data": gin.H{
            "document_id": document.ID,
            "status":      document.Status,
            "error_msg":   document.ErrorMsg,
            "chunk_count": document.ChunkCount,
            "created_at":  document.CreatedAt,
            "updated_at":  document.UpdatedAt,
        },
    })
}
```

**è·¯ç”±æ³¨å†Œ**:
```go
// main.go
documents := v1.Group("/documents")
{
    documents.POST("", handler.Upload)
    documents.GET("", handler.List)
    documents.GET("/:id", handler.Get)
    documents.GET("/:id/status", handler.GetDocumentStatus)  // æ–°å¢
    documents.DELETE("/:id", handler.Delete)
}
```

**äº¤ä»˜ç‰©**:
- âœ… DocumentProcessorå®Œæ•´å®ç°
- âœ… PDF/HTML/TXTæ–‡æœ¬æå–
- âœ… è¯­ä¹‰è¾¹ç•Œåˆ†å—ç®—æ³•
- âœ… æ–‡æ¡£çŠ¶æ€æŸ¥è¯¢API
- âœ… å•å…ƒæµ‹è¯•
- âœ… åˆ†å—è´¨é‡è¯„ä¼°

---

### Week 4: æµ‹è¯•ã€æ–‡æ¡£ä¸ä¼˜åŒ–ï¼ˆ5å¤©ï¼‰

#### Task 4.1: å•å…ƒæµ‹è¯• (2å¤©)

**StorageServiceæµ‹è¯•**:
```go
// å·²åœ¨Task 1.2æä¾›
```

**VirusScanneræµ‹è¯•**:
```go
func TestVirusScanner_EICAR(t *testing.T) {
    scanner := service.NewVirusScanner(&config.VirusScanConfig{
        Enabled: true,
        Type:    "mock",
    }, logrus.New())

    // EICARæµ‹è¯•æ–‡ä»¶å†…å®¹
    eicarContent := []byte(`X5O!P%@AP[4\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*`)

    result, err := scanner.ScanFile(context.Background(), "eicar.txt", eicarContent)
    assert.NoError(t, err)
    assert.False(t, result.IsClean)
    assert.Contains(t, result.VirusFound, "EICAR")
}
```

**DocumentProcessoræµ‹è¯•**:
```go
func TestDocumentProcessor_SplitChunks(t *testing.T) {
    processor := service.NewDocumentProcessor(nil, logrus.New())

    // ç”Ÿæˆæµ‹è¯•æ–‡æœ¬ï¼ˆ2500å­—ç¬¦ï¼‰
    text := strings.Repeat("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚", 250)

    chunks := processor.splitTextIntoChunks(text)

    // éªŒè¯åˆ†å—æ•°é‡
    assert.Greater(t, len(chunks), 1)

    // éªŒè¯æ¯ä¸ªchunkå¤§å°
    for i, chunk := range chunks {
        assert.LessOrEqual(t, len(chunk), processor.maxChunkSize,
            "chunk %d size exceeded", i)
        assert.GreaterOrEqual(t, len(chunk), processor.minChunkSize,
            "chunk %d size too small", i)
    }
}
```

#### Task 4.2: é›†æˆæµ‹è¯• (2å¤©)

**å®Œæ•´æµç¨‹æµ‹è¯•**:
```go
func TestDocumentWorkflow_E2E(t *testing.T) {
    // 1. ä¸Šä¼ æ–‡æ¡£
    // 2. ç­‰å¾…å¤„ç†å®Œæˆ
    // 3. éªŒè¯çŠ¶æ€
    // 4. éªŒè¯åˆ†å—
    // 5. éªŒè¯å‘é‡
}
```

#### Task 4.3: æ–‡æ¡£ä¸éƒ¨ç½² (1å¤©)

**APIæ–‡æ¡£æ›´æ–°**:
- æ–°å¢MinIOé…ç½®è¯´æ˜
- æ–°å¢ç—…æ¯’æ‰«æé…ç½®
- æ–°å¢æ–‡æ¡£çŠ¶æ€APIæ–‡æ¡£

**éƒ¨ç½²æ–‡æ¡£**:
- MinIOéƒ¨ç½²æŒ‡å—
- ClamAVéƒ¨ç½²æŒ‡å—
- æ•…éšœæ’æŸ¥æ‰‹å†Œ

**äº¤ä»˜ç‰©**:
- âœ… å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡>70%ï¼‰
- âœ… é›†æˆæµ‹è¯•
- âœ… APIæ–‡æ¡£æ›´æ–°
- âœ… éƒ¨ç½²æ–‡æ¡£
- âœ… æ•…éšœæ’æŸ¥æ‰‹å†Œ

---

## ğŸ“Š éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

| åŠŸèƒ½ | éªŒæ”¶æ ‡å‡† | éªŒæ”¶æ–¹æ³• |
|-----|---------|---------|
| MinIOå­˜å‚¨ | æ–‡ä»¶æˆåŠŸä¸Šä¼ åˆ°MinIO | æŸ¥çœ‹MinIOæ§åˆ¶å° |
| å­˜å‚¨é™çº§ | MinIOä¸å¯ç”¨æ—¶ä½¿ç”¨æœ¬åœ°å­˜å‚¨ | åœæ­¢MinIOæœåŠ¡æµ‹è¯• |
| ç—…æ¯’æ‰«æ | EICARæµ‹è¯•æ–‡ä»¶è¢«æ‹’ç» | ä¸Šä¼ EICARæ–‡ä»¶ |
| ç—…æ¯’æ‰«æå¤±è´¥é™çº§ | ClamAVä¸å¯ç”¨æ—¶ä»èƒ½ä¸Šä¼  | åœæ­¢ClamAVæœåŠ¡æµ‹è¯• |
| æ–‡æ¡£å¤„ç† | PDF/TXTæ–‡ä»¶æ­£ç¡®æå–æ–‡æœ¬ | ä¸Šä¼ æµ‹è¯•æ–‡ä»¶ |
| æ™ºèƒ½åˆ†å— | åˆ†å—åœ¨è¯­ä¹‰è¾¹ç•Œ | äººå·¥è¯„ä¼° |
| çŠ¶æ€ç®¡ç† | çŠ¶æ€æ­£ç¡®è½¬æ¢ | æŸ¥è¯¢æ–‡æ¡£çŠ¶æ€API |
| å¼‚æ­¥å¤„ç† | å¤„ç†æµæ°´çº¿æ­£å¸¸å·¥ä½œ | ä¸Šä¼ æ–‡æ¡£åæŸ¥çœ‹æ—¥å¿— |

### æ€§èƒ½éªŒæ”¶

| æŒ‡æ ‡ | ç›®æ ‡ | å®é™… | éªŒæ”¶æ–¹æ³• |
|-----|------|------|---------|
| æ–‡æ¡£ä¸Šä¼ å»¶è¿Ÿ | <2s | TBD | å‹æµ‹ |
| ç—…æ¯’æ‰«æå»¶è¿Ÿ | <5s | TBD | å•æ–‡ä»¶æµ‹è¯• |
| PDFæå–å»¶è¿Ÿ | <10s (100é¡µ) | TBD | æµ‹è¯•æ–‡ä»¶ |
| åˆ†å—å»¶è¿Ÿ | <1s (1ä¸‡å­—ç¬¦) | TBD | å•å…ƒæµ‹è¯• |
| å‘é‡åŒ–å»¶è¿Ÿ | <50ms/chunk | TBD | å•å…ƒæµ‹è¯• |

### è´¨é‡éªŒæ”¶

| æŒ‡æ ‡ | ç›®æ ‡ | å®é™… | éªŒæ”¶æ–¹æ³• |
|-----|------|------|---------|
| å•å…ƒæµ‹è¯•è¦†ç›–ç‡ | >70% | TBD | `go test -cover` |
| é›†æˆæµ‹è¯•é€šè¿‡ç‡ | 100% | TBD | CI/CD |
| ä»£ç è¯„å®¡é€šè¿‡ | 100% | TBD | Pull Request |
| æ–‡æ¡£å®Œæ•´æ€§ | 100% | TBD | äººå·¥æ£€æŸ¥ |

---

## âš ï¸ é£é™©ä¸ç¼“è§£

### æŠ€æœ¯é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|-----|------|------|---------|
| MinIOå•ç‚¹æ•…éšœ | é«˜ | ä½ | æœ¬åœ°å­˜å‚¨é™çº§ï¼Œåˆ†å¸ƒå¼éƒ¨ç½² |
| ClamAVæ€§èƒ½ç“¶é¢ˆ | ä¸­ | ä¸­ | å¼‚æ­¥æ‰«æï¼Œè¶…æ—¶é™çº§ |
| å¤§æ–‡ä»¶å¤„ç†OOM | é«˜ | ä¸­ | é™åˆ¶æ–‡ä»¶å¤§å°ï¼Œæµå¼å¤„ç† |
| PDFæå–å¤±è´¥ | ä½ | ä¸­ | é”™è¯¯å¤„ç†ï¼Œä¿å­˜åŸæ–‡ä»¶ |

---

## ğŸ“– ç›¸å…³æ–‡æ¡£

- [VoiceHelper-02-DocumentService.md](../VoiceHelper-02-DocumentService.md)
- [MinIO Documentation](https://min.io/docs/)
- [ClamAV Documentation](https://docs.clamav.net/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-01-27
**ç»´æŠ¤è€…**: VoiceAssistantåç«¯å›¢é˜Ÿ
