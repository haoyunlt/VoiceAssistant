# VoiceAssistant ç®—æ³•æœåŠ¡è¿­ä»£è®¡åˆ’ä¸è¯¦ç»†å®æ–½æ–¹æ¡ˆ

---

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-10-27
**é€‚ç”¨é¡¹ç›®**: VoiceAssistant
**è§„åˆ’å‘¨æœŸ**: 2025 Q1 - Q3 (6ä¸ªæœˆ)
**ç›¸å…³æ–‡æ¡£**: [ç®—æ³•æœåŠ¡åŠŸèƒ½å¯¹æ¯”æŠ¥å‘Š](./algo-services-comparison-report.md)

---

## ğŸ¯ ç›®æ ‡ä¸èŒƒå›´

### æ€»ä½“ç›®æ ‡

å¯¹é½VoiceHelperç®—æ³•æœåŠ¡åŠŸèƒ½ï¼Œæå‡VoiceAssistantçš„AIèƒ½åŠ›ï¼Œé‡ç‚¹å®ç°ï¼š
1. Neo4jçŸ¥è¯†å›¾è°±é›†æˆä¸ä¸‰è·¯å¹¶è¡Œæ£€ç´¢
2. LangGraphçŠ¶æ€æœºå·¥ä½œæµ
3. WebSocketå®æ—¶è¯­éŸ³æµ
4. ç¤¾åŒºæ£€æµ‹ä¸å¢é‡ç´¢å¼•
5. æƒ…æ„Ÿè¯†åˆ«ä¸é«˜çº§è¯­éŸ³å¤„ç†

### æˆåŠŸæ ‡å‡†

| æŒ‡æ ‡ç±»åˆ« | æŒ‡æ ‡åç§° | ç›®æ ‡å€¼ | å¤‡æ³¨ |
|---------|----------|--------|------|
| **åŠŸèƒ½å¯¹é½åº¦** | æ•´ä½“å¯¹é½ç‡ | â‰¥ 85% | å¯¹æ ‡VoiceHelper |
| **æ€§èƒ½æŒ‡æ ‡** | æ··åˆæ£€ç´¢P95å»¶è¿Ÿ | < 500ms | Vector+BM25+Graph |
| **æ€§èƒ½æŒ‡æ ‡** | å®æ—¶è¯­éŸ³æµå»¶è¿Ÿ | < 100ms | VADè§¦å‘åˆ°è¯†åˆ« |
| **è´¨é‡æŒ‡æ ‡** | çŸ¥è¯†å›¾è°±å‡†ç¡®ç‡ | â‰¥ 80% | å®ä½“å’Œå…³ç³»æå– |
| **ç¨³å®šæ€§** | æœåŠ¡å¯ç”¨æ€§ | â‰¥ 99.5% | æ ¸å¿ƒç®—æ³•æœåŠ¡ |

---

## ğŸ“… è¿­ä»£è®¡åˆ’æ€»è§ˆ

### Phase 1: çŸ¥è¯†å›¾è°±ä¸æ ¸å¿ƒå·¥ä½œæµ (2025 Q1, 12å‘¨)

**ç›®æ ‡**: å®ŒæˆP0ä¼˜å…ˆçº§åŠŸèƒ½ï¼Œå»ºç«‹æ ¸å¿ƒèƒ½åŠ›

| è¿­ä»£ | å‘¨æœŸ | äº¤ä»˜å†…å®¹ | è´£ä»»äºº |
|------|------|----------|--------|
| Iteration 1.1 | Week 1-4 | Neo4jå›¾è°±é›†æˆåˆ°retrieval-service | ç®—æ³•å›¢é˜Ÿ |
| Iteration 1.2 | Week 5-7 | LangGraphå·¥ä½œæµé›†æˆåˆ°agent-engine | ç®—æ³•å›¢é˜Ÿ |
| Iteration 1.3 | Week 8-10 | WebSocketå®æ—¶è¯­éŸ³æµ | åç«¯å›¢é˜Ÿ |
| Iteration 1.4 | Week 11-12 | é›†æˆæµ‹è¯•ä¸æ€§èƒ½ä¼˜åŒ– | å…¨å‘˜ |

### Phase 2: é«˜çº§æ£€ç´¢ä¸æ™ºèƒ½å¤„ç† (2025 Q2, 12å‘¨)

**ç›®æ ‡**: å®ŒæˆP1ä¼˜å…ˆçº§åŠŸèƒ½ï¼Œæå‡æ™ºèƒ½åŒ–æ°´å¹³

| è¿­ä»£ | å‘¨æœŸ | äº¤ä»˜å†…å®¹ | è´£ä»»äºº |
|------|------|----------|--------|
| Iteration 2.1 | Week 13-15 | ç¤¾åŒºæ£€æµ‹ç®—æ³• | ç®—æ³•å›¢é˜Ÿ |
| Iteration 2.2 | Week 16-19 | å¢é‡ç´¢å¼•ç³»ç»Ÿ | åç«¯å›¢é˜Ÿ |
| Iteration 2.3 | Week 20-22 | æƒ…æ„Ÿè¯†åˆ« | ç®—æ³•å›¢é˜Ÿ |
| Iteration 2.4 | Week 23-24 | å·¥å…·æƒé™ä½“ç³»å‡çº§ | åç«¯å›¢é˜Ÿ |

### Phase 3: é«˜çº§è¯­éŸ³ä¸ä¼˜åŒ– (2025 Q3, 12å‘¨)

**ç›®æ ‡**: å®ŒæˆP2ä¼˜å…ˆçº§åŠŸèƒ½ï¼Œå…¨é¢å¯¹é½

| è¿­ä»£ | å‘¨æœŸ | äº¤ä»˜å†…å®¹ | è´£ä»»äºº |
|------|------|----------|--------|
| Iteration 3.1 | Week 25-28 | è¯´è¯äººåˆ†ç¦» | ç®—æ³•å›¢é˜Ÿ |
| Iteration 3.2 | Week 29-31 | å…¨åŒå·¥æ‰“æ–­å¤„ç† | åç«¯å›¢é˜Ÿ |
| Iteration 3.3 | Week 32-34 | å®ä½“æ¶ˆæ­§ç®—æ³• | ç®—æ³•å›¢é˜Ÿ |
| Iteration 3.4 | Week 35-36 | å…¨é¢ä¼˜åŒ–ä¸æ€»ç»“ | å…¨å‘˜ |

---

## ğŸ”§ Phase 1 è¯¦ç»†å®æ–½æ–¹æ¡ˆ

---

## Iteration 1.1: Neo4jå›¾è°±é›†æˆ (Week 1-4)

### 1. ç›®æ ‡ä¸èŒƒå›´

#### äº¤ä»˜ç‰©
- âœ… retrieval-serviceé›†æˆNeo4jå®¢æˆ·ç«¯
- âœ… å®ç°Graphæ£€ç´¢è·¯å¾„
- âœ… ä¸‰è·¯å¹¶è¡Œæ£€ç´¢ï¼ˆVector + BM25 + Graphï¼‰
- âœ… RRFèåˆç®—æ³•
- âœ… APIæ¥å£ `/api/v1/retrieval/hybrid-graph`

#### æˆåŠŸæ ‡å‡†
- âœ… Graphæ£€ç´¢P95å»¶è¿Ÿ < 200ms
- âœ… ä¸‰è·¯å¹¶è¡Œæ€»å»¶è¿Ÿ < 500ms
- âœ… æ£€ç´¢å¬å›ç‡æå‡ â‰¥ 15%ï¼ˆå¯¹æ¯”äºŒè·¯å¹¶è¡Œï¼‰

### 2. æŠ€æœ¯æ¶æ„è®¾è®¡

#### 2.1 æ•´ä½“æ¶æ„

```mermaid
flowchart TB
    Client[Client API]

    subgraph RetrievalService["Retrieval Service"]
        API[Hybrid API]

        subgraph ParallelRetrieval["å¹¶è¡Œæ£€ç´¢å¼•æ“"]
            VectorR[Vector Retriever<br/>FAISS]
            BM25R[BM25 Retriever<br/>rank-bm25]
            GraphR[Graph Retriever<br/>Neo4j â­NEW]
        end

        Fusion[RRF Fusion Ranker]
        Rerank[Cross-Encoder Reranker]

        API --> ParallelRetrieval
        ParallelRetrieval --> Fusion
        Fusion --> Rerank
    end

    subgraph ExternalServices["External Services"]
        Neo4j[(Neo4j Graph DB)]
        FAISS[(FAISS Index)]
        Redis[(Redis Cache)]
    end

    Client --> API
    GraphR <--> Neo4j
    VectorR <--> FAISS
    Fusion <--> Redis
```

#### 2.2 æ•°æ®æ¨¡å‹è®¾è®¡

**Neo4jèŠ‚ç‚¹æ¨¡å‹**:
```cypher
// å®ä½“èŠ‚ç‚¹
CREATE (e:Entity {
    id: "entity_uuid",
    name: "Python",
    type: "ProgrammingLanguage",
    description: "é«˜çº§ç¼–ç¨‹è¯­è¨€",
    source_doc: "doc_123",
    chunk_id: "chunk_0",
    embedding: [0.1, 0.2, ...],  // 768ç»´å‘é‡
    created_at: 1729760000,
    updated_at: 1729760000
})

// æ–‡æ¡£èŠ‚ç‚¹
CREATE (d:Document {
    id: "doc_123",
    title: "Pythonæ•™ç¨‹",
    content_hash: "abc123",
    created_at: 1729760000
})

// å®ä½“-æ–‡æ¡£å…³ç³»
CREATE (e)-[:MENTIONED_IN {chunk_id: "chunk_0"}]->(d)
```

**Neo4jå…³ç³»æ¨¡å‹**:
```cypher
// å®ä½“å…³ç³»
CREATE (a:Entity {name: "Python"})-[r:USED_FOR {
    strength: 0.9,
    context: "Pythonç”¨äºæ•°æ®ç§‘å­¦",
    source_doc: "doc_123",
    created_at: 1729760000
}]->(b:Entity {name: "æ•°æ®ç§‘å­¦"})
```

#### 2.3 APIè®¾è®¡

**è¯·æ±‚ç»“æ„ä½“**:
```python
# app/models/retrieval.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict
from enum import Enum

class RetrievalMode(str, Enum):
    VECTOR_ONLY = "vector_only"
    BM25_ONLY = "bm25_only"
    GRAPH_ONLY = "graph_only"
    HYBRID = "hybrid"  # Vector + BM25
    HYBRID_GRAPH = "hybrid_graph"  # Vector + BM25 + Graph â­NEW

class HybridGraphRetrievalRequest(BaseModel):
    query: str = Field(..., description="æŸ¥è¯¢æ–‡æœ¬")
    mode: RetrievalMode = Field(
        RetrievalMode.HYBRID_GRAPH,
        description="æ£€ç´¢æ¨¡å¼"
    )
    top_k: int = Field(10, ge=1, le=100, description="è¿”å›ç»“æœæ•°")
    use_rerank: bool = Field(True, description="æ˜¯å¦ä½¿ç”¨Cross-Encoderé‡æ’")
    weights: Optional[Dict[str, float]] = Field(
        None,
        description="æƒé‡é…ç½®",
        example={"vector": 0.5, "bm25": 0.2, "graph": 0.3}
    )
    graph_depth: int = Field(2, ge=1, le=3, description="å›¾è°±æŸ¥è¯¢æ·±åº¦ï¼ˆè·³æ•°ï¼‰")

class RetrievalResult(BaseModel):
    document_id: str
    chunk_id: str
    text: str
    score: float
    source: str  # "vector" | "bm25" | "graph" | "fusion"
    metadata: Dict
    entities: Optional[List[str]] = None  # Graphæ£€ç´¢æ—¶åŒ…å«
    relations: Optional[List[Dict]] = None  # Graphæ£€ç´¢æ—¶åŒ…å«
```

**å“åº”ç»“æ„ä½“**:
```python
class HybridGraphRetrievalResponse(BaseModel):
    results: List[RetrievalResult]
    total: int
    stats: Dict[str, float]  # å„è·¯æ£€ç´¢è€—æ—¶
    mode: RetrievalMode
    elapsed_time: float

# å“åº”ç¤ºä¾‹
{
    "results": [
        {
            "document_id": "doc_123",
            "chunk_id": "chunk_0",
            "text": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦...",
            "score": 0.95,
            "source": "graph",
            "metadata": {"title": "Pythonæ•™ç¨‹", "author": "å¼ ä¸‰"},
            "entities": ["Python", "æ•°æ®ç§‘å­¦", "æœºå™¨å­¦ä¹ "],
            "relations": [
                {
                    "source": "Python",
                    "target": "æ•°æ®ç§‘å­¦",
                    "type": "USED_FOR",
                    "strength": 0.9
                }
            ]
        }
    ],
    "total": 10,
    "stats": {
        "vector_time": 0.102,
        "bm25_time": 0.053,
        "graph_time": 0.145,
        "fusion_time": 0.018,
        "rerank_time": 0.082
    },
    "mode": "hybrid_graph",
    "elapsed_time": 0.400
}
```

### 3. æ ¸å¿ƒä»£ç å®ç°

#### 3.1 Neo4jå®¢æˆ·ç«¯å°è£…

```python
# app/infrastructure/neo4j_client.py
from neo4j import AsyncGraphDatabase, AsyncDriver
from typing import List, Dict, Optional
import asyncio
import logging

logger = logging.getLogger(__name__)

class Neo4jClient:
    """Neo4jå¼‚æ­¥å®¢æˆ·ç«¯"""

    def __init__(
        self,
        uri: str,
        user: str,
        password: str,
        database: str = "neo4j"
    ):
        self.uri = uri
        self.user = user
        self.password = password
        self.database = database
        self._driver: Optional[AsyncDriver] = None

    async def connect(self):
        """å»ºç«‹è¿æ¥"""
        self._driver = AsyncGraphDatabase.driver(
            self.uri,
            auth=(self.user, self.password)
        )
        # éªŒè¯è¿æ¥
        await self._driver.verify_connectivity()
        logger.info(f"Connected to Neo4j at {self.uri}")

    async def close(self):
        """å…³é—­è¿æ¥"""
        if self._driver:
            await self._driver.close()
            logger.info("Neo4j connection closed")

    async def query(
        self,
        cypher: str,
        parameters: Optional[Dict] = None
    ) -> List[Dict]:
        """æ‰§è¡ŒCypheræŸ¥è¯¢"""
        async with self._driver.session(database=self.database) as session:
            result = await session.run(cypher, parameters or {})
            records = await result.data()
            return records

    async def create_entity(
        self,
        name: str,
        entity_type: str,
        description: str,
        source_doc: str,
        chunk_id: str,
        properties: Optional[Dict] = None
    ) -> str:
        """åˆ›å»ºå®ä½“èŠ‚ç‚¹"""
        cypher = """
        MERGE (e:Entity {name: $name})
        ON CREATE SET
            e.id = randomUUID(),
            e.type = $type,
            e.description = $description,
            e.created_at = timestamp()
        ON MATCH SET
            e.updated_at = timestamp()
        WITH e
        MERGE (e)-[:MENTIONED_IN {chunk_id: $chunk_id}]->(:Document {id: $source_doc})
        RETURN e.id as entity_id
        """
        params = {
            "name": name,
            "type": entity_type,
            "description": description,
            "source_doc": source_doc,
            "chunk_id": chunk_id
        }
        if properties:
            params.update(properties)

        result = await self.query(cypher, params)
        return result[0]["entity_id"] if result else None

    async def create_relationship(
        self,
        source_name: str,
        target_name: str,
        rel_type: str,
        strength: float,
        context: str,
        source_doc: str
    ) -> bool:
        """åˆ›å»ºå®ä½“å…³ç³»"""
        cypher = """
        MATCH (a:Entity {name: $source})
        MATCH (b:Entity {name: $target})
        MERGE (a)-[r:RELATES {type: $rel_type}]->(b)
        SET r.strength = $strength,
            r.context = $context,
            r.source_doc = $source_doc,
            r.updated_at = timestamp()
        RETURN id(r) as rel_id
        """
        params = {
            "source": source_name,
            "target": target_name,
            "rel_type": rel_type,
            "strength": strength,
            "context": context,
            "source_doc": source_doc
        }
        result = await self.query(cypher, params)
        return bool(result)

    async def get_entity_by_name(self, name: str) -> Optional[Dict]:
        """æ ¹æ®åç§°è·å–å®ä½“"""
        cypher = """
        MATCH (e:Entity {name: $name})
        RETURN e
        """
        result = await self.query(cypher, {"name": name})
        return result[0]["e"] if result else None

    async def get_related_entities(
        self,
        entity_name: str,
        depth: int = 2,
        limit: int = 50
    ) -> List[Dict]:
        """è·å–ç›¸å…³å®ä½“ï¼ˆå¤šè·³å…³ç³»ï¼‰"""
        cypher = f"""
        MATCH path = (e1:Entity {{name: $name}})-[*1..{depth}]-(e2:Entity)
        WITH e2, relationships(path) as rels, length(path) as dist
        RETURN DISTINCT
            e2.name as name,
            e2.type as type,
            e2.description as description,
            dist,
            [r in rels | {{type: type(r), strength: r.strength, context: r.context}}] as relations
        ORDER BY dist ASC, e2.name
        LIMIT $limit
        """
        result = await self.query(cypher, {"name": entity_name, "limit": limit})
        return result
```

#### 3.2 Graphæ£€ç´¢å™¨

```python
# app/services/graph_retrieval_service.py
from typing import List, Dict, Optional
from app.infrastructure.neo4j_client import Neo4jClient
from app.models.retrieval import RetrievalResult
import logging

logger = logging.getLogger(__name__)

class GraphRetrievalService:
    """åŸºäºNeo4jçš„å›¾è°±æ£€ç´¢æœåŠ¡"""

    def __init__(self, neo4j_client: Neo4jClient):
        self.neo4j = neo4j_client

    async def retrieve(
        self,
        query: str,
        top_k: int = 20,
        depth: int = 2
    ) -> List[RetrievalResult]:
        """
        å›¾è°±æ£€ç´¢

        ç­–ç•¥:
        1. ä»queryä¸­æå–å®ä½“ï¼ˆç®€åŒ–ï¼šåˆ†è¯ï¼‰
        2. åœ¨Neo4jä¸­æŸ¥æ‰¾è¿™äº›å®ä½“
        3. è·å–å¤šè·³ç›¸å…³å®ä½“å’Œå…³ç³»
        4. èšåˆæ¥æºæ–‡æ¡£
        5. æŒ‰ç›¸å…³æ€§æ’åº
        """
        # Step 1: æå–æŸ¥è¯¢ä¸­çš„å®ä½“ï¼ˆç®€åŒ–å®ç°ï¼Œåç»­å¯é›†æˆNERï¼‰
        query_entities = await self._extract_entities_from_query(query)

        if not query_entities:
            logger.warning(f"æœªä»queryæå–åˆ°å®ä½“: {query}")
            return []

        # Step 2: å¤šè·³å…³ç³»æŸ¥è¯¢
        cypher = f"""
        MATCH path = (e1:Entity)-[*1..{depth}]-(e2:Entity)
        WHERE e1.name IN $entity_names
        WITH
            path,
            relationships(path) as rels,
            length(path) as dist,
            [n in nodes(path) | n.name] as entity_path
        UNWIND rels as rel
        WITH DISTINCT
            rel.source_doc as document_id,
            rel.context as context,
            rel.chunk_id as chunk_id,
            entity_path,
            dist,
            COUNT(*) as relevance,
            COLLECT(DISTINCT {{
                source: startNode(rel).name,
                target: endNode(rel).name,
                type: type(rel),
                strength: rel.strength
            }}) as relations
        ORDER BY relevance DESC, dist ASC
        LIMIT $top_k
        """

        params = {
            "entity_names": query_entities,
            "top_k": top_k
        }

        results = await self.neo4j.query(cypher, params)

        # Step 3: è½¬æ¢ä¸ºRetrievalResult
        retrieval_results = []
        max_relevance = max([r["relevance"] for r in results], default=1)

        for r in results:
            retrieval_results.append(RetrievalResult(
                document_id=r["document_id"] or "unknown",
                chunk_id=r.get("chunk_id", f"graph_{r['document_id']}"),
                text=r["context"] or "",
                score=r["relevance"] / max_relevance,  # å½’ä¸€åŒ–åˆ°[0,1]
                source="graph",
                metadata={
                    "distance": r["dist"],
                    "entity_path": r["entity_path"]
                },
                entities=r["entity_path"],
                relations=r["relations"]
            ))

        logger.info(f"Graphæ£€ç´¢è¿”å› {len(retrieval_results)} æ¡ç»“æœ")
        return retrieval_results

    async def _extract_entities_from_query(self, query: str) -> List[str]:
        """
        ä»æŸ¥è¯¢ä¸­æå–å®ä½“ï¼ˆç®€åŒ–å®ç°ï¼‰

        åç»­å¯é›†æˆ:
        - NERæ¨¡å‹ï¼ˆSpaCy/HanLPï¼‰
        - LLMæå–
        - å…³é”®è¯æå–
        """
        # ç®€åŒ–å®ç°ï¼šåˆ†è¯ + Neo4jæ¨¡ç³ŠåŒ¹é…
        import jieba
        words = list(jieba.cut(query))

        # åœ¨Neo4jä¸­æŸ¥æ‰¾åŒ¹é…çš„å®ä½“
        cypher = """
        UNWIND $words as word
        MATCH (e:Entity)
        WHERE e.name CONTAINS word OR word CONTAINS e.name
        RETURN DISTINCT e.name as entity_name
        LIMIT 10
        """
        results = await self.neo4j.query(cypher, {"words": words})

        entity_names = [r["entity_name"] for r in results]
        logger.info(f"ä»queryæå–å®ä½“: {entity_names}")

        return entity_names
```

#### 3.3 ä¸‰è·¯å¹¶è¡Œæ£€ç´¢ + RRFèåˆ

```python
# app/services/hybrid_graph_service.py
from typing import List, Dict, Optional
import asyncio
import time
from app.services.vector_service import VectorRetrievalService
from app.services.bm25_service import BM25RetrievalService
from app.services.graph_retrieval_service import GraphRetrievalService
from app.services.rerank_service import RerankService
from app.models.retrieval import (
    RetrievalResult,
    HybridGraphRetrievalRequest,
    HybridGraphRetrievalResponse
)
import logging

logger = logging.getLogger(__name__)

class HybridGraphService:
    """æ··åˆå›¾è°±æ£€ç´¢æœåŠ¡ï¼ˆä¸‰è·¯å¹¶è¡Œï¼‰"""

    def __init__(
        self,
        vector_service: VectorRetrievalService,
        bm25_service: BM25RetrievalService,
        graph_service: GraphRetrievalService,
        rerank_service: RerankService
    ):
        self.vector_service = vector_service
        self.bm25_service = bm25_service
        self.graph_service = graph_service
        self.rerank_service = rerank_service

    async def retrieve(
        self,
        request: HybridGraphRetrievalRequest
    ) -> HybridGraphRetrievalResponse:
        """ä¸‰è·¯å¹¶è¡Œæ£€ç´¢ + RRFèåˆ + é‡æ’"""
        start_time = time.time()
        stats = {}

        # Step 1: ä¸‰è·¯å¹¶è¡Œæ£€ç´¢
        vector_start = time.time()
        bm25_start = time.time()
        graph_start = time.time()

        vector_results, bm25_results, graph_results = await asyncio.gather(
            self._vector_retrieve(request.query, request.top_k * 2),
            self._bm25_retrieve(request.query, request.top_k * 2),
            self._graph_retrieve(
                request.query,
                request.top_k * 2,
                request.graph_depth
            ),
            return_exceptions=True
        )

        # å¤„ç†å¼‚å¸¸
        if isinstance(vector_results, Exception):
            logger.error(f"Vectoræ£€ç´¢å¤±è´¥: {vector_results}")
            vector_results = []
        if isinstance(bm25_results, Exception):
            logger.error(f"BM25æ£€ç´¢å¤±è´¥: {bm25_results}")
            bm25_results = []
        if isinstance(graph_results, Exception):
            logger.error(f"Graphæ£€ç´¢å¤±è´¥: {graph_results}")
            graph_results = []

        stats["vector_time"] = time.time() - vector_start
        stats["bm25_time"] = time.time() - bm25_start
        stats["graph_time"] = time.time() - graph_start

        logger.info(
            f"ä¸‰è·¯æ£€ç´¢å®Œæˆ: "
            f"vector={len(vector_results)}, "
            f"bm25={len(bm25_results)}, "
            f"graph={len(graph_results)}"
        )

        # Step 2: RRFèåˆ
        fusion_start = time.time()
        weights = request.weights or {"vector": 0.5, "bm25": 0.2, "graph": 0.3}
        fused_results = self._rrf_fusion(
            {
                "vector": vector_results,
                "bm25": bm25_results,
                "graph": graph_results
            },
            weights=weights,
            k=60
        )
        stats["fusion_time"] = time.time() - fusion_start

        # Step 3: Cross-Encoderé‡æ’ï¼ˆå¯é€‰ï¼‰
        if request.use_rerank and len(fused_results) > 0:
            rerank_start = time.time()
            reranked_results = await self.rerank_service.rerank(
                query=request.query,
                results=fused_results,
                top_k=request.top_k
            )
            stats["rerank_time"] = time.time() - rerank_start
            final_results = reranked_results
        else:
            final_results = fused_results[:request.top_k]
            stats["rerank_time"] = 0.0

        elapsed_time = time.time() - start_time

        return HybridGraphRetrievalResponse(
            results=final_results,
            total=len(final_results),
            stats=stats,
            mode=request.mode,
            elapsed_time=elapsed_time
        )

    async def _vector_retrieve(
        self,
        query: str,
        top_k: int
    ) -> List[RetrievalResult]:
        """å‘é‡æ£€ç´¢"""
        return await self.vector_service.retrieve(query, top_k)

    async def _bm25_retrieve(
        self,
        query: str,
        top_k: int
    ) -> List[RetrievalResult]:
        """BM25æ£€ç´¢"""
        return await self.bm25_service.retrieve(query, top_k)

    async def _graph_retrieve(
        self,
        query: str,
        top_k: int,
        depth: int
    ) -> List[RetrievalResult]:
        """å›¾è°±æ£€ç´¢"""
        return await self.graph_service.retrieve(query, top_k, depth)

    def _rrf_fusion(
        self,
        retrieval_results: Dict[str, List[RetrievalResult]],
        weights: Dict[str, float],
        k: int = 60
    ) -> List[RetrievalResult]:
        """
        RRFèåˆç®—æ³•

        å…¬å¼: score(d) = Î£ weight_i / (k + rank_i(d))
        å…¶ä¸­ k=60 æ˜¯ç»éªŒå¸¸æ•°
        """
        doc_scores: Dict[str, Dict] = {}

        for source, results in retrieval_results.items():
            weight = weights.get(source, 1.0)

            for rank, result in enumerate(results):
                doc_key = f"{result.document_id}_{result.chunk_id}"

                # RRFåˆ†æ•°
                rrf_score = weight / (k + rank + 1)

                if doc_key not in doc_scores:
                    doc_scores[doc_key] = {
                        "result": result,
                        "score": 0.0,
                        "sources": []
                    }

                doc_scores[doc_key]["score"] += rrf_score
                doc_scores[doc_key]["sources"].append(source)

        # æ’åº
        sorted_docs = sorted(
            doc_scores.values(),
            key=lambda x: x["score"],
            reverse=True
        )

        # æ›´æ–°åˆ†æ•°å¹¶æ ‡è®°æ¥æº
        fused_results = []
        for doc in sorted_docs:
            result = doc["result"]
            result.score = doc["score"]
            result.source = "fusion" if len(doc["sources"]) > 1 else doc["sources"][0]
            result.metadata["fusion_sources"] = doc["sources"]
            fused_results.append(result)

        logger.info(f"RRFèåˆå: {len(fused_results)} æ¡ç»“æœ")
        return fused_results
```

#### 3.4 APIè·¯ç”±

```python
# app/routers/retrieval.py
from fastapi import APIRouter, Depends, HTTPException
from app.services.hybrid_graph_service import HybridGraphService
from app.models.retrieval import (
    HybridGraphRetrievalRequest,
    HybridGraphRetrievalResponse
)
from app.core.dependencies import get_hybrid_graph_service
import logging

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/v1/retrieval", tags=["retrieval"])

@router.post(
    "/hybrid-graph",
    response_model=HybridGraphRetrievalResponse,
    summary="æ··åˆå›¾è°±æ£€ç´¢ï¼ˆä¸‰è·¯å¹¶è¡Œï¼‰"
)
async def hybrid_graph_retrieval(
    request: HybridGraphRetrievalRequest,
    service: HybridGraphService = Depends(get_hybrid_graph_service)
):
    """
    æ··åˆå›¾è°±æ£€ç´¢API

    ç‰¹æ€§:
    - ä¸‰è·¯å¹¶è¡Œ: Vector (FAISS) + BM25 + Graph (Neo4j)
    - RRFèåˆ: å€’æ•°æ’åèåˆç®—æ³•
    - Cross-Encoderé‡æ’ï¼ˆå¯é€‰ï¼‰
    - å¯é…ç½®æƒé‡

    ç¤ºä¾‹:
    ```json
    {
        "query": "Pythonåœ¨æ•°æ®ç§‘å­¦ä¸­çš„åº”ç”¨",
        "mode": "hybrid_graph",
        "top_k": 10,
        "use_rerank": true,
        "weights": {"vector": 0.5, "bm25": 0.2, "graph": 0.3},
        "graph_depth": 2
    }
    ```
    """
    try:
        response = await service.retrieve(request)
        return response
    except Exception as e:
        logger.error(f"æ··åˆå›¾è°±æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
```

### 4. æµ‹è¯•ä¸éªŒè¯

#### 4.1 å•å…ƒæµ‹è¯•

```python
# tests/test_graph_retrieval.py
import pytest
from app.services.graph_retrieval_service import GraphRetrievalService
from app.infrastructure.neo4j_client import Neo4jClient

@pytest.fixture
async def neo4j_client():
    client = Neo4jClient(
        uri="bolt://localhost:7687",
        user="neo4j",
        password="password"
    )
    await client.connect()
    yield client
    await client.close()

@pytest.fixture
async def graph_service(neo4j_client):
    return GraphRetrievalService(neo4j_client)

@pytest.mark.asyncio
async def test_graph_retrieve_basic(graph_service):
    """æµ‹è¯•åŸºç¡€å›¾è°±æ£€ç´¢"""
    results = await graph_service.retrieve(
        query="Pythonç¼–ç¨‹è¯­è¨€",
        top_k=10,
        depth=2
    )

    assert len(results) > 0
    assert all(r.source == "graph" for r in results)
    assert all(r.entities is not None for r in results)

@pytest.mark.asyncio
async def test_graph_retrieve_multi_hop(graph_service):
    """æµ‹è¯•å¤šè·³å…³ç³»æ£€ç´¢"""
    results = await graph_service.retrieve(
        query="æœºå™¨å­¦ä¹ ",
        top_k=20,
        depth=3
    )

    # éªŒè¯æœ‰å¤šè·³å…³ç³»çš„ç»“æœ
    multi_hop = [r for r in results if r.metadata.get("distance", 1) > 1]
    assert len(multi_hop) > 0

@pytest.mark.asyncio
async def test_rrf_fusion(hybrid_graph_service):
    """æµ‹è¯•RRFèåˆ"""
    # å‡†å¤‡æ¨¡æ‹Ÿæ•°æ®
    vector_results = [...]
    bm25_results = [...]
    graph_results = [...]

    fused = hybrid_graph_service._rrf_fusion(
        {
            "vector": vector_results,
            "bm25": bm25_results,
            "graph": graph_results
        },
        weights={"vector": 0.5, "bm25": 0.2, "graph": 0.3}
    )

    assert len(fused) > 0
    # éªŒè¯åˆ†æ•°æ’åº
    assert all(
        fused[i].score >= fused[i+1].score
        for i in range(len(fused)-1)
    )
```

#### 4.2 é›†æˆæµ‹è¯•

```bash
# tests/integration/test_hybrid_graph_e2e.sh
#!/bin/bash

# å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
docker-compose up -d neo4j redis

# ç­‰å¾…æœåŠ¡å°±ç»ª
sleep 10

# å¯¼å…¥æµ‹è¯•æ•°æ®
python tests/fixtures/load_neo4j_data.py

# è¿è¡Œæ£€ç´¢æœåŠ¡
python -m uvicorn main:app --host 0.0.0.0 --port 8007 &
sleep 5

# æµ‹è¯•æ··åˆæ£€ç´¢API
curl -X POST "http://localhost:8007/api/v1/retrieval/hybrid-graph" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Pythonåœ¨æ•°æ®ç§‘å­¦ä¸­çš„åº”ç”¨",
    "mode": "hybrid_graph",
    "top_k": 10,
    "use_rerank": true,
    "weights": {"vector": 0.5, "bm25": 0.2, "graph": 0.3},
    "graph_depth": 2
  }' | jq '.results | length'

# æ¸…ç†
docker-compose down
```

#### 4.3 æ€§èƒ½æµ‹è¯•

```python
# tests/performance/test_retrieval_performance.py
import asyncio
import time
from statistics import mean, stdev

async def test_retrieval_latency():
    """æµ‹è¯•æ£€ç´¢å»¶è¿Ÿ"""
    latencies = []

    for i in range(100):
        start = time.time()
        response = await hybrid_graph_service.retrieve(
            HybridGraphRetrievalRequest(
                query=f"æµ‹è¯•æŸ¥è¯¢ {i}",
                top_k=10
            )
        )
        elapsed = time.time() - start
        latencies.append(elapsed)

    print(f"å¹³å‡å»¶è¿Ÿ: {mean(latencies)*1000:.2f}ms")
    print(f"P95å»¶è¿Ÿ: {sorted(latencies)[94]*1000:.2f}ms")
    print(f"P99å»¶è¿Ÿ: {sorted(latencies)[98]*1000:.2f}ms")

    # éªŒè¯P95 < 500ms
    assert sorted(latencies)[94] < 0.5

asyncio.run(test_retrieval_latency())
```

### 5. éƒ¨ç½²ä¸é…ç½®

#### 5.1 ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env
# Neo4jé…ç½®
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password
NEO4J_DATABASE=neo4j

# æ£€ç´¢é…ç½®
RETRIEVAL_TOP_K=20
RETRIEVAL_GRAPH_DEPTH=2
RRF_K=60

# æƒé‡é…ç½®
RETRIEVAL_VECTOR_WEIGHT=0.5
RETRIEVAL_BM25_WEIGHT=0.2
RETRIEVAL_GRAPH_WEIGHT=0.3

# æ€§èƒ½é…ç½®
MAX_CONCURRENT_RETRIEVALS=10
RETRIEVAL_TIMEOUT=5.0
```

#### 5.2 Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  retrieval-service:
    build: ./algo/retrieval-service
    ports:
      - "8007:8007"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - neo4j
      - redis
    networks:
      - voiceassistant

  neo4j:
    image: neo4j:5.15-community
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["apoc"]
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    networks:
      - voiceassistant

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - voiceassistant

volumes:
  neo4j_data:
  neo4j_logs:
  redis_data:

networks:
  voiceassistant:
    driver: bridge
```

### 6. ç›‘æ§ä¸è¿ç»´

#### 6.1 PrometheusæŒ‡æ ‡

```python
# app/core/metrics.py
from prometheus_client import Histogram, Counter, Gauge

# æ£€ç´¢å»¶è¿Ÿç›´æ–¹å›¾
retrieval_latency = Histogram(
    'retrieval_latency_seconds',
    'Retrieval latency in seconds',
    ['retrieval_type']  # vector, bm25, graph, fusion
)

# æ£€ç´¢è¯·æ±‚è®¡æ•°
retrieval_requests_total = Counter(
    'retrieval_requests_total',
    'Total retrieval requests',
    ['mode', 'status']
)

# Neo4jè¿æ¥æ± çŠ¶æ€
neo4j_connections_active = Gauge(
    'neo4j_connections_active',
    'Active Neo4j connections'
)
```

#### 6.2 æ—¥å¿—è§„èŒƒ

```python
# ä¸šåŠ¡æ—¥å¿—
logger.info(
    "æ··åˆå›¾è°±æ£€ç´¢",
    extra={
        "query": query,
        "top_k": top_k,
        "vector_results": len(vector_results),
        "bm25_results": len(bm25_results),
        "graph_results": len(graph_results),
        "total_time_ms": int(elapsed_time * 1000)
    }
)

# æ€§èƒ½æ—¥å¿—
logger.info(
    "æ£€ç´¢æ€§èƒ½ç»Ÿè®¡",
    extra={
        "vector_time_ms": int(stats["vector_time"] * 1000),
        "bm25_time_ms": int(stats["bm25_time"] * 1000),
        "graph_time_ms": int(stats["graph_time"] * 1000),
        "fusion_time_ms": int(stats["fusion_time"] * 1000),
        "rerank_time_ms": int(stats["rerank_time"] * 1000)
    }
)
```

### 7. ä¸Šçº¿æ£€æŸ¥æ¸…å•

- [ ] Neo4jå·²éƒ¨ç½²å¹¶åˆ›å»ºç´¢å¼•
  ```cypher
  CREATE INDEX entity_name_idx IF NOT EXISTS FOR (e:Entity) ON (e.name);
  CREATE INDEX entity_type_idx IF NOT EXISTS FOR (e:Entity) ON (e.type);
  CREATE INDEX document_id_idx IF NOT EXISTS FOR (d:Document) ON (d.id);
  ```

- [ ] æµ‹è¯•æ•°æ®å·²å¯¼å…¥Neo4j
- [ ] å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼ˆè¦†ç›–ç‡ > 80%ï¼‰
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] æ€§èƒ½æµ‹è¯•è¾¾æ ‡ï¼ˆP95 < 500msï¼‰
- [ ] ç›‘æ§æŒ‡æ ‡å·²é…ç½®
- [ ] æ—¥å¿—è¾“å‡ºæ­£å¸¸
- [ ] APIæ–‡æ¡£å·²æ›´æ–°
- [ ] ç°åº¦å‘å¸ƒè®¡åˆ’å·²åˆ¶å®š

---

## Iteration 1.2: LangGraphå·¥ä½œæµ (Week 5-7)

### 1. ç›®æ ‡ä¸èŒƒå›´

#### äº¤ä»˜ç‰©
- âœ… agent-engineé›†æˆLangGraphåº“
- âœ… å®ç°4èŠ‚ç‚¹çŠ¶æ€æœºï¼ˆPlanner/Executor/Critic/Synthesizerï¼‰
- âœ… æ¡ä»¶è¾¹é€»è¾‘
- âœ… ä»»åŠ¡è¿­ä»£æ§åˆ¶
- âœ… APIæ¥å£ `/api/v1/agent/execute-langgraph`

#### æˆåŠŸæ ‡å‡†
- âœ… å¤æ‚ä»»åŠ¡æˆåŠŸç‡ â‰¥ 85%
- âœ… å¹³å‡è¿­ä»£æ¬¡æ•° â‰¤ 5
- âœ… å•ä»»åŠ¡æ‰§è¡Œæ—¶é—´ < 30ç§’

### 2. æŠ€æœ¯æ¶æ„è®¾è®¡

#### 2.1 LangGraphçŠ¶æ€å›¾

```mermaid
stateDiagram-v2
    [*] --> Planner: åˆå§‹çŠ¶æ€

    Planner --> Executor: execute<br/>(æœ‰æœ‰æ•ˆè®¡åˆ’)
    Planner --> Planner: refine<br/>(éœ€è¦é‡æ–°è§„åˆ’)
    Planner --> [*]: end<br/>(æ— è®¡åˆ’æˆ–è¶…é™)

    Executor --> Executor: continue<br/>(ç»§ç»­ä¸‹ä¸€æ­¥)
    Executor --> Critic: reflect<br/>(éœ€è¦åæ€)
    Executor --> Synthesizer: synthesize<br/>(æ‰€æœ‰æ­¥éª¤å®Œæˆ)

    Critic --> Planner: è¿”å›è§„åˆ’<br/>(è°ƒæ•´è®¡åˆ’)

    Synthesizer --> [*]: å®Œæˆ
```

### 3. æ ¸å¿ƒä»£ç å®ç°

#### 3.1 AgentStateå®šä¹‰

```python
# app/core/langgraph_workflow.py
from typing import TypedDict, List, Dict, Any, Optional
from langgraph.graph import StateGraph, END
import logging

logger = logging.getLogger(__name__)

class AgentState(TypedDict):
    """AgentçŠ¶æ€å®šä¹‰"""
    # è¾“å…¥
    task: str                          # åŸå§‹ä»»åŠ¡æè¿°
    context: Dict[str, Any]           # ä¸Šä¸‹æ–‡ä¿¡æ¯
    available_tools: List[str]         # å¯ç”¨å·¥å…·åˆ—è¡¨

    # ä¸­é—´çŠ¶æ€
    plan: List[Dict[str, Any]]        # ä»»åŠ¡è®¡åˆ’
    current_step: int                  # å½“å‰æ­¥éª¤
    execution_results: List[Dict]      # æ‰§è¡Œç»“æœ

    # æ§åˆ¶æ ‡å¿—
    need_reflection: bool              # æ˜¯å¦éœ€è¦åæ€
    need_replan: bool                  # æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’
    iterations: int                    # å½“å‰è¿­ä»£æ¬¡æ•°
    max_iterations: int                # æœ€å¤§è¿­ä»£æ¬¡æ•°

    # è¾“å‡º
    final_result: str                  # æœ€ç»ˆç»“æœ
    error: str                         # é”™è¯¯ä¿¡æ¯
```

#### 3.2 èŠ‚ç‚¹å®ç°

```python
class LangGraphWorkflow:
    """LangGraphå·¥ä½œæµ"""

    def __init__(
        self,
        llm_service,
        tool_service,
        max_iterations: int = 10
    ):
        self.llm = llm_service
        self.tools = tool_service
        self.max_iterations = max_iterations

        # æ„å»ºçŠ¶æ€å›¾
        self.graph = self._build_graph()
        self.app = self.graph.compile()

    def _build_graph(self) -> StateGraph:
        """æ„å»ºLangGraphçŠ¶æ€å›¾"""
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("planner", self._planning_node)
        workflow.add_node("executor", self._execution_node)
        workflow.add_node("critic", self._reflection_node)
        workflow.add_node("synthesizer", self._synthesis_node)

        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("planner")

        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "planner",
            self._should_execute,
            {
                "execute": "executor",
                "refine": "planner",
                "end": END
            }
        )

        workflow.add_conditional_edges(
            "executor",
            self._should_reflect,
            {
                "continue": "executor",
                "reflect": "critic",
                "synthesize": "synthesizer"
            }
        )

        workflow.add_edge("critic", "planner")
        workflow.add_edge("synthesizer", END)

        return workflow

    async def _planning_node(self, state: AgentState) -> Dict:
        """è§„åˆ’èŠ‚ç‚¹ - ä»»åŠ¡åˆ†è§£"""
        logger.info(f"[Planner] è¿­ä»£ {state['iterations']}")

        task = state["task"]
        context = state["context"]
        available_tools = state.get("available_tools", [])

        # æ„å»ºè§„åˆ’æç¤º
        tools_desc = self.tools.get_tools_description(available_tools)

        planning_prompt = f"""
        ä»»åŠ¡: {task}
        ä¸Šä¸‹æ–‡: {context}
        å¯ç”¨å·¥å…·: {tools_desc}

        è¯·å°†ä»»åŠ¡åˆ†è§£ä¸ºå…·ä½“çš„æ‰§è¡Œæ­¥éª¤ã€‚æ¯ä¸ªæ­¥éª¤åŒ…å«:
        1. step_number: æ­¥éª¤ç¼–å·
        2. description: æ­¥éª¤æè¿°
        3. tool: éœ€è¦ä½¿ç”¨çš„å·¥å…· (å¦‚æœéœ€è¦)
        4. input: å·¥å…·è¾“å…¥å‚æ•°
        5. expected_output: é¢„æœŸè¾“å‡º

        è¿”å›JSONæ ¼å¼çš„è®¡åˆ’åˆ—è¡¨ã€‚
        """

        # è°ƒç”¨LLMç”Ÿæˆè®¡åˆ’
        response = await self.llm.chat(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è§„åˆ’ä¸“å®¶"},
                {"role": "user", "content": planning_prompt}
            ],
            temperature=0.7
        )

        # è§£æè®¡åˆ’
        plan = self._parse_plan(response)

        return {
            "plan": plan,
            "current_step": 0,
            "iterations": state["iterations"] + 1,
            "need_replan": False
        }

    async def _execution_node(self, state: AgentState) -> Dict:
        """æ‰§è¡ŒèŠ‚ç‚¹ - æ‰§è¡Œå½“å‰æ­¥éª¤"""
        logger.info(f"[Executor] æ‰§è¡Œæ­¥éª¤ {state['current_step']}")

        plan = state["plan"]
        current_step = state["current_step"]
        execution_results = state.get("execution_results", [])

        if current_step >= len(plan):
            return {
                "current_step": current_step,
                "need_reflection": False
            }

        step = plan[current_step]

        # æ‰§è¡Œæ­¥éª¤
        try:
            result = await self._execute_step(step)

            execution_results.append({
                "step": current_step,
                "description": step.get("description"),
                "result": result,
                "success": True,
                "error": None
            })

            return {
                "current_step": current_step + 1,
                "execution_results": execution_results,
                "need_reflection": True
            }

        except Exception as e:
            logger.error(f"æ­¥éª¤æ‰§è¡Œå¤±è´¥: {e}")
            execution_results.append({
                "step": current_step,
                "result": None,
                "success": False,
                "error": str(e)
            })

            return {
                "current_step": current_step,
                "execution_results": execution_results,
                "need_replan": True
            }

    async def _reflection_node(self, state: AgentState) -> Dict:
        """åæ€èŠ‚ç‚¹ - éªŒè¯æ‰§è¡Œç»“æœ"""
        logger.info("[Critic] åæ€æ‰§è¡Œç»“æœ")

        execution_results = state.get("execution_results", [])
        plan = state["plan"]

        reflection_prompt = f"""
        è®¡åˆ’: {plan}
        æ‰§è¡Œç»“æœ: {execution_results}

        è¯·è¯„ä¼°:
        1. æ‰§è¡Œç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ?
        2. æ˜¯å¦éœ€è¦è°ƒæ•´è®¡åˆ’?
        3. ä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ?

        è¿”å›JSON: {{"assessment": "è¯„ä¼°", "need_replan": true/false}}
        """

        response = await self.llm.chat(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç»“æœéªŒè¯ä¸“å®¶"},
                {"role": "user", "content": reflection_prompt}
            ]
        )

        reflection = self._parse_reflection(response)

        return {
            "need_replan": reflection.get("need_replan", False)
        }

    async def _synthesis_node(self, state: AgentState) -> Dict:
        """ç»¼åˆèŠ‚ç‚¹ - ç”Ÿæˆæœ€ç»ˆç»“æœ"""
        logger.info("[Synthesizer] ç»¼åˆæœ€ç»ˆç»“æœ")

        task = state["task"]
        execution_results = state.get("execution_results", [])

        synthesis_prompt = f"""
        åŸå§‹ä»»åŠ¡: {task}
        æ‰§è¡Œç»“æœ: {execution_results}

        è¯·ç»¼åˆæ‰€æœ‰æ‰§è¡Œç»“æœ,ç”Ÿæˆå®Œæ•´çš„æœ€ç»ˆç­”æ¡ˆã€‚
        """

        response = await self.llm.chat(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯ç»¼åˆä¸“å®¶"},
                {"role": "user", "content": synthesis_prompt}
            ]
        )

        return {
            "final_result": response
        }

    def _should_execute(self, state: AgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡Œ"""
        if state["iterations"] >= state["max_iterations"]:
            return "end"

        if state.get("need_replan", False):
            return "refine"

        if not state.get("plan") or len(state["plan"]) == 0:
            return "end"

        return "execute"

    def _should_reflect(self, state: AgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦åæ€"""
        current_step = state.get("current_step", 0)
        plan = state.get("plan", [])
        need_reflection = state.get("need_reflection", False)

        # æ‰€æœ‰æ­¥éª¤å®Œæˆ
        if current_step >= len(plan):
            return "synthesize"

        # éœ€è¦åæ€
        if need_reflection:
            return "reflect"

        # ç»§ç»­æ‰§è¡Œ
        return "continue"

    async def run(
        self,
        task: str,
        context: Optional[Dict[str, Any]] = None,
        available_tools: Optional[List[str]] = None,
        max_iterations: int = None
    ) -> Dict[str, Any]:
        """è¿è¡Œå·¥ä½œæµ"""
        initial_state = {
            "task": task,
            "context": context or {},
            "available_tools": available_tools or [],
            "plan": [],
            "current_step": 0,
            "execution_results": [],
            "need_reflection": False,
            "need_replan": False,
            "iterations": 0,
            "max_iterations": max_iterations or self.max_iterations,
            "final_result": "",
            "error": ""
        }

        result = await self.app.ainvoke(initial_state)

        return {
            "success": True,
            "final_result": result.get("final_result", ""),
            "execution_results": result.get("execution_results", []),
            "iterations": result.get("iterations", 0)
        }
```

#### 3.3 APIé›†æˆ

```python
# app/routers/agent.py
from fastapi import APIRouter, BackgroundTasks, Depends
from app.core.langgraph_workflow import LangGraphWorkflow
from app.models.agent import ExecuteRequest, ExecuteResponse
import uuid

router = APIRouter(prefix="/api/v1/agent", tags=["agent"])

@router.post("/execute-langgraph", response_model=ExecuteResponse)
async def execute_with_langgraph(
    request: ExecuteRequest,
    background_tasks: BackgroundTasks,
    workflow: LangGraphWorkflow = Depends(get_langgraph_workflow)
):
    """ä½¿ç”¨LangGraphå·¥ä½œæµæ‰§è¡Œä»»åŠ¡"""
    task_id = str(uuid.uuid4())

    # åå°æ‰§è¡Œ
    async def run_task():
        result = await workflow.run(
            task=request.task,
            context=request.context,
            available_tools=request.tools,
            max_iterations=request.max_iterations
        )
        # ä¿å­˜ç»“æœåˆ°Redis
        await save_task_result(task_id, result)

    background_tasks.add_task(run_task)

    return ExecuteResponse(
        task_id=task_id,
        status="pending",
        message="ä»»åŠ¡å·²æäº¤"
    )
```

### 4. æµ‹è¯•ä¸éªŒè¯

```python
# tests/test_langgraph_workflow.py
import pytest
from app.core.langgraph_workflow import LangGraphWorkflow

@pytest.mark.asyncio
async def test_simple_task():
    """æµ‹è¯•ç®€å•ä»»åŠ¡"""
    workflow = LangGraphWorkflow(llm_service, tool_service)

    result = await workflow.run(
        task="è®¡ç®— 25 * 4 + 10",
        available_tools=["calculator"]
    )

    assert result["success"] is True
    assert "110" in result["final_result"]
    assert result["iterations"] <= 3

@pytest.mark.asyncio
async def test_complex_task_with_replan():
    """æµ‹è¯•å¤æ‚ä»»åŠ¡ï¼ˆéœ€è¦é‡æ–°è§„åˆ’ï¼‰"""
    workflow = LangGraphWorkflow(llm_service, tool_service)

    result = await workflow.run(
        task="æœç´¢æœ€è¿‘çš„å¤©æ°”ï¼Œç„¶åå»ºè®®ç©¿è¡£",
        available_tools=["web_search"],
        max_iterations=10
    )

    assert result["success"] is True
    assert result["iterations"] > 1
    assert len(result["execution_results"]) > 0
```

---

## Iteration 1.3: WebSocketå®æ—¶è¯­éŸ³æµ (Week 8-10)

### 1. ç›®æ ‡ä¸èŒƒå›´

#### äº¤ä»˜ç‰©
- âœ… voice-engineå®ç°WebSocketç«¯ç‚¹
- âœ… å®æ—¶VADè§¦å‘ASR
- âœ… å¿ƒè·³æœºåˆ¶
- âœ… è¿æ¥ç®¡ç†ï¼ˆè¶…æ—¶ã€é‡è¿ï¼‰
- âœ… WebSocket API `/api/v1/voice/stream`

#### æˆåŠŸæ ‡å‡†
- âœ… VADè§¦å‘å»¶è¿Ÿ < 50ms
- âœ… ASRè¯†åˆ«å»¶è¿Ÿ < 500ms
- âœ… æ”¯æŒå¹¶å‘è¿æ¥ â‰¥ 100
- âœ… è¿æ¥ç¨³å®šæ€§ â‰¥ 99%

### 2. æŠ€æœ¯æ¶æ„è®¾è®¡

#### 2.1 WebSocketæµç¨‹å›¾

```mermaid
sequenceDiagram
    participant C as Client
    participant WS as WebSocket Handler
    participant VAD as Silero VAD
    participant ASR as Whisper ASR

    C->>WS: WebSocketè¿æ¥
    WS-->>C: è¿æ¥ç¡®è®¤

    loop å®æ—¶éŸ³é¢‘æµ
        C->>WS: éŸ³é¢‘å¸§ (binary)
        WS->>WS: è¿½åŠ åˆ°audio_buffer
        WS->>VAD: detect_speech(audio_array)
        VAD-->>WS: speech_prob=0.8
        WS-->>C: heartbeat

        C->>WS: éŸ³é¢‘å¸§
        WS->>VAD: detect_speech()
        VAD-->>WS: speech_prob=0.2 (é™éŸ³)

        Note over WS: æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
        WS->>ASR: transcribe(audio_buffer)
        ASR-->>WS: text="ä½ å¥½"
        WS-->>C: {type:"transcription", text:"ä½ å¥½"}
        WS->>WS: audio_buffer.clear()
    end

    C->>WS: æ–­å¼€è¿æ¥
    WS-->>C: è¿æ¥å…³é—­
```

### 3. æ ¸å¿ƒä»£ç å®ç°

#### 3.1 WebSocketç«¯ç‚¹

```python
# app/routers/voice_stream.py
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from app.services.realtime_voice_service import RealtimeVoiceService
import logging

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/v1/voice", tags=["voice"])

@router.websocket("/stream")
async def websocket_voice_stream(
    websocket: WebSocket,
    service: RealtimeVoiceService = Depends(get_realtime_voice_service)
):
    """
    WebSocketå®æ—¶è¯­éŸ³æµ

    æµç¨‹:
    1. å®¢æˆ·ç«¯å‘é€éŸ³é¢‘å¸§ï¼ˆbinaryï¼ŒPCM 16bit 16kHzï¼‰
    2. æœåŠ¡ç«¯VADæ£€æµ‹è¯­éŸ³æ´»åŠ¨
    3. æ£€æµ‹åˆ°é™éŸ³â†’è§¦å‘ASRè¯†åˆ«
    4. è¿”å›è¯†åˆ«ç»“æœï¼ˆJSONï¼‰
    5. å®šæœŸå‘é€å¿ƒè·³
    """
    await websocket.accept()

    session_id = str(uuid.uuid4())
    logger.info(f"[Session {session_id}] WebSocketè¿æ¥å»ºç«‹")

    try:
        await service.handle_stream(websocket, session_id)

    except WebSocketDisconnect:
        logger.info(f"[Session {session_id}] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")

    except Exception as e:
        logger.error(f"[Session {session_id}] å¼‚å¸¸: {e}", exc_info=True)
        await websocket.close(code=1011, reason=str(e))

    finally:
        await service.cleanup_session(session_id)
        logger.info(f"[Session {session_id}] ä¼šè¯æ¸…ç†å®Œæˆ")
```

#### 3.2 å®æ—¶è¯­éŸ³æœåŠ¡

```python
# app/services/realtime_voice_service.py
from fastapi import WebSocket
import numpy as np
import time
import asyncio
from app.services.asr_service import ASRService
from app.services.vad_service import VADService
import logging

logger = logging.getLogger(__name__)

class RealtimeVoiceService:
    """å®æ—¶è¯­éŸ³æµæœåŠ¡"""

    def __init__(
        self,
        asr_service: ASRService,
        vad_service: VADService,
        sample_rate: int = 16000,
        vad_threshold: float = 0.3,
        min_speech_duration: float = 0.5,
        heartbeat_interval: float = 1.0
    ):
        self.asr = asr_service
        self.vad = vad_service
        self.sample_rate = sample_rate
        self.vad_threshold = vad_threshold
        self.min_speech_duration = min_speech_duration
        self.heartbeat_interval = heartbeat_interval

        # ä¼šè¯ç®¡ç†
        self.sessions = {}

    async def handle_stream(
        self,
        websocket: WebSocket,
        session_id: str
    ):
        """å¤„ç†WebSocketéŸ³é¢‘æµ"""
        # åˆå§‹åŒ–ä¼šè¯
        session = {
            "audio_buffer": bytearray(),
            "buffer_duration": 0.0,
            "is_speaking": False,
            "last_speech_time": 0,
            "last_heartbeat_time": time.time(),
            "total_frames": 0
        }
        self.sessions[session_id] = session

        # å¯åŠ¨å¿ƒè·³ä»»åŠ¡
        heartbeat_task = asyncio.create_task(
            self._send_heartbeats(websocket, session_id)
        )

        try:
            while True:
                # æ¥æ”¶éŸ³é¢‘æ•°æ®ï¼ˆbinaryï¼‰
                data = await websocket.receive_bytes()

                session["audio_buffer"].extend(data)
                session["buffer_duration"] += len(data) / (self.sample_rate * 2)
                session["total_frames"] += 1

                # VADæ£€æµ‹
                audio_array = np.frombuffer(
                    bytes(session["audio_buffer"]),
                    dtype=np.int16
                ).astype(np.float32) / 32768.0

                speech_prob = await self.vad.detect_speech(
                    audio_array,
                    self.sample_rate
                )

                # çŠ¶æ€è½¬æ¢
                if speech_prob > self.vad_threshold:
                    session["is_speaking"] = True
                    session["last_speech_time"] = time.time()

                elif session["is_speaking"]:
                    silence_duration = time.time() - session["last_speech_time"]

                    # æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
                    if (silence_duration > self.min_speech_duration and
                        session["buffer_duration"] > 0.5):

                        # è§¦å‘ASR
                        start_time = time.time()
                        text = await self.asr.transcribe(
                            bytes(session["audio_buffer"])
                        )
                        asr_time = time.time() - start_time

                        # å‘é€è¯†åˆ«ç»“æœ
                        await websocket.send_json({
                            "type": "transcription",
                            "text": text,
                            "duration": session["buffer_duration"],
                            "asr_time": asr_time,
                            "timestamp": time.time()
                        })

                        logger.info(
                            f"[Session {session_id}] ASRè¯†åˆ«: {text} "
                            f"(duration={session['buffer_duration']:.2f}s, "
                            f"asr_time={asr_time*1000:.0f}ms)"
                        )

                        # æ¸…ç©ºç¼“å†²åŒº
                        session["audio_buffer"].clear()
                        session["buffer_duration"] = 0.0
                        session["is_speaking"] = False

        finally:
            heartbeat_task.cancel()

    async def _send_heartbeats(
        self,
        websocket: WebSocket,
        session_id: str
    ):
        """å‘é€å¿ƒè·³"""
        while True:
            try:
                await asyncio.sleep(self.heartbeat_interval)

                session = self.sessions.get(session_id)
                if not session:
                    break

                await websocket.send_json({
                    "type": "heartbeat",
                    "buffer_duration": session["buffer_duration"],
                    "total_frames": session["total_frames"],
                    "timestamp": time.time()
                })

            except asyncio.CancelledError:
                break

            except Exception as e:
                logger.error(f"å¿ƒè·³å‘é€å¤±è´¥: {e}")
                break

    async def cleanup_session(self, session_id: str):
        """æ¸…ç†ä¼šè¯"""
        if session_id in self.sessions:
            del self.sessions[session_id]
```

#### 3.3 å®¢æˆ·ç«¯ç¤ºä¾‹ï¼ˆJavaScriptï¼‰

```html
<!-- static/test_voice_stream.html -->
<!DOCTYPE html>
<html>
<head>
    <title>WebSocketå®æ—¶è¯­éŸ³æµ‹è¯•</title>
</head>
<body>
    <h1>WebSocketå®æ—¶è¯­éŸ³æµ‹è¯•</h1>
    <button id="start">å¼€å§‹å½•éŸ³</button>
    <button id="stop" disabled>åœæ­¢å½•éŸ³</button>
    <div id="results"></div>

    <script>
        const startBtn = document.getElementById('start');
        const stopBtn = document.getElementById('stop');
        const resultsDiv = document.getElementById('results');

        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;

        startBtn.onclick = async () => {
            // å»ºç«‹WebSocketè¿æ¥
            ws = new WebSocket('ws://localhost:8004/api/v1/voice/stream');

            ws.onopen = () => {
                console.log('WebSocketè¿æ¥å·²å»ºç«‹');
                resultsDiv.innerHTML += '<p>âœ… è¿æ¥æˆåŠŸ</p>';
            };

            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);

                if (data.type === 'transcription') {
                    resultsDiv.innerHTML += `<p><strong>è¯†åˆ«ç»“æœ:</strong> ${data.text}</p>`;
                    console.log('è¯†åˆ«ç»“æœ:', data);
                }
                else if (data.type === 'heartbeat') {
                    console.log('å¿ƒè·³:', data);
                }
            };

            ws.onerror = (error) => {
                console.error('WebSocketé”™è¯¯:', error);
                resultsDiv.innerHTML += '<p>âŒ è¿æ¥é”™è¯¯</p>';
            };

            ws.onclose = () => {
                console.log('WebSocketè¿æ¥å·²å…³é—­');
                resultsDiv.innerHTML += '<p>ğŸ”´ è¿æ¥å…³é—­</p>';
            };

            // å¼€å§‹å½•éŸ³
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true
                }
            });

            audioContext = new AudioContext({ sampleRate: 16000 });
            const source = audioContext.createMediaStreamSource(stream);
            const processor = audioContext.createScriptProcessor(4096, 1, 1);

            processor.onaudioprocess = (e) => {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    const inputData = e.inputBuffer.getChannelData(0);

                    // è½¬æ¢ä¸ºPCM 16bit
                    const pcm = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        pcm[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                    }

                    // å‘é€éŸ³é¢‘æ•°æ®
                    ws.send(pcm.buffer);
                }
            };

            source.connect(processor);
            processor.connect(audioContext.destination);

            startBtn.disabled = true;
            stopBtn.disabled = false;
        };

        stopBtn.onclick = () => {
            if (ws) {
                ws.close();
                ws = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            startBtn.disabled = false;
            stopBtn.disabled = true;
        };
    </script>
</body>
</html>
```

### 4. æµ‹è¯•ä¸éªŒè¯

```python
# tests/test_voice_stream.py
import pytest
import asyncio
from fastapi.testclient import TestClient
from websockets.client import connect

@pytest.mark.asyncio
async def test_websocket_connection():
    """æµ‹è¯•WebSocketè¿æ¥"""
    async with connect("ws://localhost:8004/api/v1/voice/stream") as ws:
        # å‘é€æµ‹è¯•éŸ³é¢‘æ•°æ®
        test_audio = np.random.randint(-32768, 32767, 16000, dtype=np.int16)
        await ws.send(test_audio.tobytes())

        # æ¥æ”¶å¿ƒè·³
        response = await asyncio.wait_for(ws.recv(), timeout=2.0)
        data = json.loads(response)

        assert data["type"] == "heartbeat"

@pytest.mark.asyncio
async def test_vad_trigger_asr():
    """æµ‹è¯•VADè§¦å‘ASR"""
    async with connect("ws://localhost:8004/api/v1/voice/stream") as ws:
        # å‘é€åŒ…å«è¯­éŸ³çš„éŸ³é¢‘ï¼ˆæ¨¡æ‹Ÿï¼‰
        speech_audio = load_test_audio("hello.wav")
        await ws.send(speech_audio.tobytes())

        # ç­‰å¾…è¯†åˆ«ç»“æœ
        response = await asyncio.wait_for(ws.recv(), timeout=5.0)
        data = json.loads(response)

        assert data["type"] == "transcription"
        assert len(data["text"]) > 0
```

---

## Phase 2 & Phase 3 è¿­ä»£è®¡åˆ’æ¦‚è¦

ç”±äºç¯‡å¹…é™åˆ¶ï¼ŒPhase 2å’ŒPhase 3çš„è¯¦ç»†å®æ–½æ–¹æ¡ˆå°†åœ¨åç»­ç‹¬ç«‹æ–‡æ¡£ä¸­æä¾›ã€‚ä»¥ä¸‹æ˜¯æ¦‚è¦ï¼š

### Phase 2: é«˜çº§æ£€ç´¢ä¸æ™ºèƒ½å¤„ç†

**Iteration 2.1: ç¤¾åŒºæ£€æµ‹ç®—æ³•** (Week 13-15)
- Leiden/Louvainç®—æ³•é›†æˆ
- Neo4jç¤¾åŒºæ‘˜è¦ç”Ÿæˆ
- API: `/api/v1/knowledge/community/detect`

**Iteration 2.2: å¢é‡ç´¢å¼•ç³»ç»Ÿ** (Week 16-19)
- æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†ï¼ˆRedisï¼‰
- å†…å®¹å“ˆå¸Œå¯¹æ¯”
- å·®å¼‚æ£€æµ‹ç®—æ³•
- åŸå­æ›´æ–°

**Iteration 2.3: æƒ…æ„Ÿè¯†åˆ«** (Week 20-22)
- MFCCç‰¹å¾æå–
- æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹
- API: `/api/v1/voice/emotion/recognize`

**Iteration 2.4: å·¥å…·æƒé™ä½“ç³»å‡çº§** (Week 23-24)
- 5çº§æƒé™ï¼ˆLOW_RISK â†’ CRITICALï¼‰
- å®¡è®¡æ—¥å¿—
- å·¥å…·é»‘åå•

### Phase 3: é«˜çº§è¯­éŸ³ä¸ä¼˜åŒ–

**Iteration 3.1: è¯´è¯äººåˆ†ç¦»** (Week 25-28)
- Pyannoteé›†æˆ
- å¤šäººå¯¹è¯å¤„ç†
- API: `/api/v1/voice/diarization`

**Iteration 3.2: å…¨åŒå·¥æ‰“æ–­å¤„ç†** (Week 29-31)
- æ‰“æ–­æ£€æµ‹
- TTSæ’­æ”¾æ§åˆ¶
- WebSocketåŒå‘é€šä¿¡

**Iteration 3.3: å®ä½“æ¶ˆæ­§ç®—æ³•** (Week 32-34)
- å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
- è‡ªåŠ¨åˆå¹¶é‡å¤å®ä½“
- API: `/api/v1/knowledge/entity/merge`

**Iteration 3.4: å…¨é¢ä¼˜åŒ–ä¸æ€»ç»“** (Week 35-36)
- æ€§èƒ½ä¼˜åŒ–
- æ–‡æ¡£å®Œå–„
- ä¸Šçº¿æ€»ç»“

---

## ğŸ“Š èµ„æºè§„åˆ’

### äººå‘˜é…ç½®

| è§’è‰² | äººæ•° | èŒè´£ | å…³é”®æŠ€èƒ½ |
|------|------|------|----------|
| **ç®—æ³•å·¥ç¨‹å¸ˆ** | 2 | Neo4j/LangGraph/æƒ…æ„Ÿè¯†åˆ« | Python, NLP, å›¾ç®—æ³• |
| **åç«¯å·¥ç¨‹å¸ˆ** | 2 | WebSocket/å¢é‡ç´¢å¼•/API | FastAPI, Redis, WebSocket |
| **æµ‹è¯•å·¥ç¨‹å¸ˆ** | 1 | æµ‹è¯•ä¸è´¨é‡ä¿è¯ | pytest, æ€§èƒ½æµ‹è¯• |
| **é¡¹ç›®ç»ç†** | 1 | è¿›åº¦ç®¡ç†ä¸åè°ƒ | æ•æ·ç®¡ç† |

### åŸºç¡€è®¾æ–½è§„åˆ’

| ç»„ä»¶ | è§„æ ¼ | æ•°é‡ | ç”¨é€” |
|------|------|------|------|
| Neo4j Enterprise | 8C16G, 500GB SSD | 1 | çŸ¥è¯†å›¾è°± |
| Redis Cluster | 4C8G | 3èŠ‚ç‚¹ | ç¼“å­˜/ä»»åŠ¡ |
| GPUæœåŠ¡å™¨ | NVIDIA T4 | 2 | æƒ…æ„Ÿè¯†åˆ« |
| å¼€å‘æœåŠ¡å™¨ | 8C16G | 4 | å¼€å‘æµ‹è¯• |

### é¢„ç®—ä¼°ç®—

| ç±»åˆ« | æœˆæˆæœ¬ | 6ä¸ªæœˆæ€»æˆæœ¬ | å¤‡æ³¨ |
|------|--------|-------------|------|
| äººåŠ›æˆæœ¬ | $30,000 | $180,000 | 6äººÃ—å¹³å‡$5K/æœˆ |
| åŸºç¡€è®¾æ–½ | $5,000 | $30,000 | Neo4j+Redis+GPU |
| è½¯ä»¶License | $1,000 | $6,000 | å¼€å‘å·¥å…· |
| æ‚é¡¹ | $2,000 | $12,000 | åŸ¹è®­ã€å·®æ—…ç­‰ |
| **æ€»è®¡** | **$38,000** | **$228,000** | - |

---

## ğŸ“ˆ é£é™©ç®¡ç†

### æŠ€æœ¯é£é™©

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|----------|
| Neo4jé›†æˆå¤æ‚åº¦è¶…é¢„æœŸ | é«˜ | é«˜ | æå‰POCï¼Œåˆ†é˜¶æ®µé›†æˆ |
| LangGraphå­¦ä¹ æ›²çº¿é™¡å³­ | ä¸­ | ä¸­ | åŸ¹è®­ï¼Œå°èŒƒå›´è¯•ç‚¹ |
| WebSocketå¹¶å‘ç“¶é¢ˆ | ä¸­ | é«˜ | è´Ÿè½½æµ‹è¯•ï¼Œé™æµé™çº§ |
| æƒ…æ„Ÿè¯†åˆ«å‡†ç¡®ç‡ä¸è¶³ | é«˜ | ä½ | é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¿«é€Ÿè¿­ä»£ |

### è¿›åº¦é£é™©

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|----------|
| å…³é”®äººå‘˜ç¦»èŒ | ä½ | é«˜ | çŸ¥è¯†æ–‡æ¡£åŒ–ï¼ŒåŒäººå¤‡ä»½ |
| éœ€æ±‚å˜æ›´é¢‘ç¹ | ä¸­ | ä¸­ | æ•æ·è¿­ä»£ï¼ŒMVPä¼˜å…ˆ |
| æµ‹è¯•å‘¨æœŸå»¶é•¿ | ä¸­ | ä¸­ | è‡ªåŠ¨åŒ–æµ‹è¯•ï¼ŒCI/CD |

---

## ğŸ“š é™„å½•

### A. å‚è€ƒæ–‡æ¡£

1. [VoiceHelperç®—æ³•æœåŠ¡å¯¹æ¯”æŠ¥å‘Š](./algo-services-comparison-report.md)
2. [LangGraphå®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
3. [Neo4j Python Driveræ–‡æ¡£](https://neo4j.com/docs/api/python-driver/)
4. [WebSocketåè®®è§„èŒƒ](https://datatracker.ietf.org/doc/html/rfc6455)

### B. æœ¯è¯­è¡¨

| æœ¯è¯­ | è¯´æ˜ |
|------|------|
| LangGraph | çŠ¶æ€æœºå·¥ä½œæµæ¡†æ¶ |
| RRF | Reciprocal Rank Fusionï¼Œå€’æ•°æ’åèåˆ |
| VAD | Voice Activity Detectionï¼Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹ |
| Leiden | ç¤¾åŒºæ£€æµ‹ç®—æ³• |
| Cross-Encoder | äº¤å‰ç¼–ç å™¨ï¼Œç”¨äºé‡æ’ |

### C. æ›´æ–°è®°å½•

| ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | å˜æ›´è¯´æ˜ |
|------|------|------|----------|
| v1.0 | 2025-10-27 | AI Assistant | åˆç‰ˆï¼ŒPhase 1è¯¦ç»†æ–¹æ¡ˆ |

---

**æ–‡æ¡£ç»“æŸ**

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**:
1. âœ… è¯„å®¡æœ¬è¿­ä»£è®¡åˆ’
2. âœ… å¯åŠ¨Iteration 1.1 POC
3. âœ… ç»„å»ºä¸“é¡¹å›¢é˜Ÿ
4. âœ… å»ºç«‹å‘¨æŠ¥æœºåˆ¶
