# Agent Engine å¯è§‚æµ‹æ€§é›†æˆæŒ‡å—

> **åˆ›å»ºæ—¶é—´**: 2025-10-29
> **ç‰ˆæœ¬**: v1.0
> **è¿­ä»£**: Phase 1 - å¯è§‚æµ‹æ€§ä¸è¯„æµ‹åŸºå»º

---

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•é›†æˆå’Œä½¿ç”¨ Agent Engine çš„å¯è§‚æµ‹æ€§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- âœ… æ‰§è¡Œè¿½è¸ª (ExecutionTracer)
- âœ… è‡ªåŠ¨åŒ–è¯„æµ‹ (AgentEvaluator)
- âœ… æˆæœ¬æ§åˆ¶ (BudgetController)
- âœ… Grafana ä»ªè¡¨ç›˜

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯ç”¨æ‰§è¡Œè¿½è¸ª

```python
from app.observability.tracer import ExecutionTracer, get_tracer
from app.core.agent_engine import AgentEngine

# åˆ›å»ºè¿½è¸ªå™¨
tracer = ExecutionTracer(enable_otel=True)

# è®¾ç½®ä¸ºå…¨å±€è¿½è¸ªå™¨
from app.observability.tracer import set_tracer
set_tracer(tracer)

# åœ¨ Agent Engine ä¸­ä½¿ç”¨
agent_engine = AgentEngine()
await agent_engine.initialize()

# æ‰§è¡Œä»»åŠ¡ï¼ˆè‡ªåŠ¨è¿½è¸ªï¼‰
task_id = "task_001"
tracer.start_task(task_id, "Calculate 2 + 2", mode="react")

result = await agent_engine.execute(
    task="Calculate 2 + 2",
    mode="react"
)

tracer.end_task(task_id, result["final_answer"], success=True)

# è·å–è¿½è¸ªæ‘˜è¦
summary = tracer.get_trace_summary(task_id)
print(f"Steps: {summary['step_count']}, Cost: ${summary['total_cost_usd']:.4f}")
```

### 2. è¿è¡Œè¯„æµ‹

```bash
# ä½¿ç”¨é¢„è®¾çš„åŸºå‡†æ•°æ®é›†
cd algo/agent-engine
python tests/eval/agent/run_evaluation.py \
  --dataset tests/eval/agent/datasets/benchmark.json \
  --modes react plan_execute \
  --output tests/eval/agent/reports/result.json \
  --enable-llm-judge
```

### 3. å¯ç”¨é¢„ç®—æ§åˆ¶

```python
from app.core.budget_controller import BudgetController

# åˆ›å»ºé¢„ç®—æ§åˆ¶å™¨
controller = BudgetController(
    redis_client=redis_client,
    default_tier=BudgetTier.PRO,
    alert_threshold=0.8
)

# æ‰§è¡Œå‰æ£€æŸ¥é¢„ç®—
tenant_id = "tenant_123"
if await controller.check_budget(tenant_id, estimated_cost=0.05):
    # æ‰§è¡Œä»»åŠ¡
    result = await agent_engine.execute(task="...")

    # è®°å½•æˆæœ¬
    await controller.record_cost(
        tenant_id=tenant_id,
        cost_usd=0.05,
        metadata={"mode": "react", "task_id": "task_001"}
    )
else:
    # åº”ç”¨é™çº§ç­–ç•¥
    strategy = await controller.get_fallback_strategy(tenant_id)
    print(f"Budget exceeded, fallback: {strategy.value}")
```

### 4. éƒ¨ç½² Grafana ä»ªè¡¨ç›˜

```bash
# å¯¼å…¥ä»ªè¡¨ç›˜
kubectl apply -f deployments/grafana/dashboards/agent-performance.json
kubectl apply -f deployments/grafana/dashboards/agent-cost.json
kubectl apply -f deployments/grafana/dashboards/agent-tracing.json

# è®¿é—® Grafana
open http://localhost:3000/dashboards
```

---

## ğŸ“Š æ‰§è¡Œè¿½è¸ªè¯¦è§£

### è¿½è¸ªäº‹ä»¶ç±»å‹

| äº‹ä»¶ç±»å‹ | è¯´æ˜ | ä½¿ç”¨åœºæ™¯ |
|---------|------|----------|
| `TASK_START` | ä»»åŠ¡å¼€å§‹ | è®°å½•ä»»åŠ¡å…ƒä¿¡æ¯ |
| `TASK_END` | ä»»åŠ¡ç»“æŸ | è®°å½•æœ€ç»ˆç»“æœå’Œç»Ÿè®¡ |
| `THOUGHT` | æ€è€ƒè¿‡ç¨‹ | ReAct æ¨¡å¼çš„æ¨ç†æ­¥éª¤ |
| `ACTION` | è¡ŒåŠ¨å†³ç­– | é€‰æ‹©å·¥å…·å’Œå‚æ•° |
| `OBSERVATION` | è§‚å¯Ÿç»“æœ | å·¥å…·æ‰§è¡Œç»“æœ |
| `TOOL_CALL` | å·¥å…·è°ƒç”¨ | è®°å½•å·¥å…·è°ƒç”¨æ€§èƒ½ |
| `LLM_CALL` | LLM è°ƒç”¨ | è®°å½• Token å’Œæˆæœ¬ |
| `MEMORY_RETRIEVAL` | è®°å¿†æ£€ç´¢ | è®°å¿†ç³»ç»Ÿæ€§èƒ½ |

### å®Œæ•´ç¤ºä¾‹ï¼šè¿½è¸ª ReAct æ‰§è¡Œ

```python
from app.observability.tracer import get_tracer

tracer = get_tracer()

# 1. å¼€å§‹ä»»åŠ¡
task_id = "task_123"
tracer.start_task(task_id, "What is 25 * 4 + 10?", mode="react")

# 2. è®°å½•ç¬¬ä¸€æ­¥æ€è€ƒ
tracer.record_thought(
    task_id,
    "I need to calculate 25 * 4 + 10. I should use the calculator tool.",
    step_number=1
)

# 3. è®°å½•è¡ŒåŠ¨
tracer.record_action(
    task_id,
    action="Use calculator to compute expression",
    tool="calculator",
    params={"expression": "25 * 4 + 10"},
    step_number=1
)

# 4. è®°å½•å·¥å…·è°ƒç”¨ï¼ˆåŒ…å«æ€§èƒ½ï¼‰
import time
start = time.time()
result = "110"  # å·¥å…·æ‰§è¡Œç»“æœ
duration_ms = (time.time() - start) * 1000

tracer.record_tool_call(
    task_id,
    tool_name="calculator",
    params={"expression": "25 * 4 + 10"},
    duration_ms=duration_ms,
    success=True,
    result=result
)

# 5. è®°å½•è§‚å¯Ÿ
tracer.record_observation(task_id, result, step_number=1)

# 6. è®°å½• LLM è°ƒç”¨
tracer.record_llm_call(
    task_id,
    model="gpt-4",
    prompt_tokens=50,
    completion_tokens=20,
    duration_ms=500,
    cost_usd=0.002
)

# 7. ç»“æŸä»»åŠ¡
tracer.end_task(task_id, final_result="The answer is 110", success=True)

# 8. å¯¼å‡ºè¿½è¸ªè®°å½•
trace_json = tracer.export_trace_json(task_id)
with open(f"traces/{task_id}.json", "w") as f:
    f.write(trace_json)
```

---

## ğŸ§ª è¯„æµ‹æ¡†æ¶ä½¿ç”¨

### è‡ªå®šä¹‰æµ‹è¯•ç”¨ä¾‹

åˆ›å»º `custom_tests.json`:

```json
[
  {
    "id": "custom_001",
    "category": "business_logic",
    "task": "æŸ¥è¯¢å®¢æˆ·è®¢å•çŠ¶æ€å¹¶å‘é€é€šçŸ¥",
    "expected_answer": "è®¢å•çŠ¶æ€å·²æŸ¥è¯¢å¹¶å‘é€é€šçŸ¥",
    "expected_tools": ["database_query", "notification_service"],
    "max_steps": 8,
    "metadata": {
      "complexity": "medium",
      "priority": "high"
    }
  }
]
```

### ç¼–ç¨‹å¼è¿è¡Œè¯„æµ‹

```python
from tests.eval.agent.evaluator import AgentEvaluator, TestCase
from app.core.agent_engine import AgentEngine

# åˆå§‹åŒ–
agent_engine = AgentEngine()
await agent_engine.initialize()

evaluator = AgentEvaluator(
    agent_engine=agent_engine,
    enable_llm_judge=True
)

# åŠ è½½æµ‹è¯•ç”¨ä¾‹
test_cases = evaluator.load_test_cases("custom_tests.json")

# è¿è¡Œè¯„æµ‹
results = await evaluator.evaluate(
    test_cases=test_cases,
    modes=["react", "plan_execute", "reflexion"]
)

# ç”ŸæˆæŠ¥å‘Š
report = evaluator.generate_report(results)

# æ‰“å°æ‘˜è¦
evaluator.print_summary(report)

# ä¿å­˜æŠ¥å‘Š
evaluator.save_report(report, "reports/custom_evaluation.json")
```

### CI é›†æˆ

`.github/workflows/agent-evaluation.yml`:

```yaml
name: Agent Evaluation

on:
  schedule:
    - cron: '0 2 * * *'  # æ¯å¤©å‡Œæ™¨2ç‚¹
  push:
    branches: [main, develop]

jobs:
  evaluate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          cd algo/agent-engine
          pip install -r requirements.txt

      - name: Run evaluation
        run: |
          cd algo/agent-engine
          python tests/eval/agent/run_evaluation.py \
            --dataset tests/eval/agent/datasets/benchmark.json \
            --modes react plan_execute \
            --output reports/nightly_eval.json

      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-report
          path: algo/agent-engine/reports/nightly_eval.json

      - name: Check regression
        run: |
          python scripts/check_evaluation_regression.py \
            --baseline reports/baseline.json \
            --current reports/nightly_eval.json \
            --threshold 0.05  # å…è®¸5%çš„æ€§èƒ½ä¸‹é™
```

---

## ğŸ’° æˆæœ¬æ§åˆ¶è¯¦è§£

### é¢„ç®—ç­‰çº§é…ç½®

```python
from app.core.budget_controller import BudgetTier

# ä¸ºç§Ÿæˆ·è®¾ç½®é¢„ç®—ç­‰çº§
await redis_client.set("budget:tier:tenant_123", BudgetTier.PRO.value)

# PRO ç­‰çº§: $10/day
# å®é™…é¢„ç®—å¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´
```

### è·å–ä½¿ç”¨æŠ¥å‘Š

```python
# è·å–è¿‡å»7å¤©çš„ä½¿ç”¨æŠ¥å‘Š
report = await controller.get_usage_report("tenant_123", days=7)

print(f"æ€»æ¶ˆè€—: ${report['total_usage']:.4f}")
print(f"æ—¥å‡æ¶ˆè€—: ${report['daily_average']:.4f}")
print(f"é¢„ç®—ä½¿ç”¨ç‡: {report['usage_ratio']:.2%}")

# æ¯æ—¥è¯¦æƒ…
for day in report['daily_usage']:
    print(f"{day['date']}: ${day['usage']:.4f}")
```

### æˆæœ¬ä¼˜åŒ–å»ºè®®

```python
suggestions = await controller.get_optimization_suggestions("tenant_123")

for suggestion in suggestions:
    print(f"ğŸ’¡ {suggestion}")

# è¾“å‡ºç¤ºä¾‹:
# ğŸ’¡ é¢„ç®—å³å°†ç”¨å°½ï¼Œå»ºè®®å‡çº§å¥—é¤æˆ–ä¼˜åŒ–ä½¿ç”¨
# ğŸ’¡ æ¯æ—¥å¹³å‡æ¶ˆè€—è¾ƒé«˜ï¼Œå»ºè®®ï¼š
# ğŸ’¡   - ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆå¦‚ GPT-3.5 ä»£æ›¿ GPT-4ï¼‰
# ğŸ’¡   - å¯ç”¨è¯­ä¹‰ç¼“å­˜ï¼Œå‡å°‘é‡å¤æŸ¥è¯¢
```

---

## ğŸ“ˆ Grafana ä»ªè¡¨ç›˜æŒ‡æ ‡

### Agent Performance Dashboard

**å…³é”®æŒ‡æ ‡**:
- ä»»åŠ¡æˆåŠŸç‡: `agent_tasks_total{status="success"}`
- P95 å»¶è¿Ÿ: `histogram_quantile(0.95, agent_task_duration_seconds_bucket)`
- å¹³å‡æ­¥éª¤æ•°: `avg(agent_step_count)`
- å·¥å…·è°ƒç”¨æˆåŠŸç‡: `agent_tool_calls_total{status="success"}`

**å‘Šè­¦è§„åˆ™**:
```yaml
# Prometheus Alert Rules
groups:
  - name: agent_engine
    rules:
      - alert: HighTaskFailureRate
        expr: sum(rate(agent_tasks_total{status="error"}[5m])) / sum(rate(agent_tasks_total[5m])) > 0.15
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ä»»åŠ¡å¤±è´¥ç‡è¿‡é«˜"
          description: "å¤±è´¥ç‡: {{ $value | humanizePercentage }}"

      - alert: HighLatency
        expr: histogram_quantile(0.95, sum(rate(agent_task_duration_seconds_bucket[5m])) by (le)) > 10
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "P95å»¶è¿Ÿè¶…è¿‡10ç§’"
```

### Agent Cost Dashboard

**å…³é”®æŒ‡æ ‡**:
- æ€»æˆæœ¬: `sum(increase(agent_cost_usd_total[24h]))`
- æ¯ä»»åŠ¡æˆæœ¬: `agent_cost_usd_total / agent_tasks_total`
- ç§Ÿæˆ·æ’è¡Œ: `topk(10, sum(increase(agent_cost_usd_total[24h])) by (tenant_id))`
- Token æ¶ˆè€—: `sum(increase(agent_tokens_total[24h]))`

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

**Q1: è¿½è¸ªæ•°æ®æœªä¸ŠæŠ¥åˆ° Jaegerï¼Ÿ**

æ£€æŸ¥ OpenTelemetry é…ç½®:
```bash
# æŸ¥çœ‹ç¯å¢ƒå˜é‡
echo $OTEL_EXPORTER_OTLP_ENDPOINT  # åº”è¯¥æŒ‡å‘ Jaeger

# æµ‹è¯•è¿æ¥
curl http://localhost:4318/v1/traces
```

**Q2: è¯„æµ‹å¤±è´¥ç‡é«˜ï¼Ÿ**

æ£€æŸ¥ Agent Engine çŠ¶æ€:
```python
# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = await agent_engine.get_stats()
print(f"æˆåŠŸç‡: {stats['success_rate']:.2%}")
print(f"å¤±è´¥åŸå› : {stats['error_distribution']}")
```

**Q3: é¢„ç®—æ§åˆ¶ä¸ç”Ÿæ•ˆï¼Ÿ**

æ£€æŸ¥ Redis è¿æ¥å’Œé…ç½®:
```python
# éªŒè¯é¢„ç®—è®°å½•
usage = await controller._get_daily_usage("tenant_123")
budget = await controller._get_budget("tenant_123")
print(f"å½“å‰æ¶ˆè€—: ${usage:.4f} / ${budget:.4f}")
```

---

## ğŸ“š æœ€ä½³å®è·µ

### 1. åˆ†é˜¶æ®µå¯ç”¨åŠŸèƒ½

```python
# Phase 1: åªå¯ç”¨è¿½è¸ªï¼ˆæ— æ€§èƒ½å½±å“ï¼‰
tracer = ExecutionTracer(enable_otel=False)

# Phase 2: å¯ç”¨ OpenTelemetryï¼ˆ< 5% æ€§èƒ½å¼€é”€ï¼‰
tracer = ExecutionTracer(enable_otel=True)

# Phase 3: å¯ç”¨å®Œæ•´è¯„æµ‹ï¼ˆä»…åœ¨å¼€å‘/æµ‹è¯•ç¯å¢ƒï¼‰
if os.getenv("ENV") != "production":
    evaluator = AgentEvaluator(agent_engine, enable_llm_judge=True)
```

### 2. å®šæœŸæ¸…ç†è¿½è¸ªæ•°æ®

```python
# ä»»åŠ¡å®Œæˆåæ¸…ç†
tracer.clear_trace(task_id)

# å®šæ—¶æ¸…ç†ï¼ˆåå°ä»»åŠ¡ï¼‰
async def cleanup_old_traces():
    cutoff_time = time.time() - 86400  # 24å°æ—¶å‰
    for task_id, events in tracer.traces.items():
        if events[0].timestamp < cutoff_time:
            tracer.clear_trace(task_id)
```

### 3. åˆç†è®¾ç½®é¢„ç®—å‘Šè­¦

```python
# å¤šçº§å‘Šè­¦
controller = BudgetController(alert_threshold=0.8)  # 80% å‘Šè­¦

# è‡ªå®šä¹‰å‘Šè­¦å›è°ƒ
async def on_budget_alert(tenant_id, usage_ratio):
    if usage_ratio > 0.9:
        # å‘é€ç´§æ€¥é€šçŸ¥
        await notification_service.send_urgent(tenant_id, "é¢„ç®—å³å°†è€—å°½")
    elif usage_ratio > 0.8:
        # å‘é€æé†’
        await notification_service.send_info(tenant_id, "é¢„ç®—ä½¿ç”¨å·²è¾¾80%")
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

å®Œæˆè¿­ä»£ 1 åï¼Œç»§ç»­ï¼š
- [ ] **è¿­ä»£ 2**: Self-RAG ä¸è®°å¿†å¢å¼º
- [ ] **è¿­ä»£ 3**: Multi-Agent åä½œå¢å¼º
- [ ] **è¿­ä»£ 4**: äººæœºåä½œä¸å·¥å…·ç”Ÿæ€

å‚è§: [ä¼˜åŒ–è·¯çº¿å›¾](../../../docs/roadmap/agent-engine-optimization-roadmap.md)

---

**æœ€åæ›´æ–°**: 2025-10-29
**ç»´æŠ¤è€…**: Agent-Engine Team
