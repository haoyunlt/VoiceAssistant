# Agent Engine - LLM å®¢æˆ·ç«¯ä½¿ç”¨æŒ‡å—

> **åŠŸèƒ½çŠ¶æ€**: âœ… å·²å®ç°
> **å®ç°æ—¥æœŸ**: 2025-10-27
> **Sprint**: Sprint 3
> **ç‰ˆæœ¬**: v1.0.0

---

## ğŸ“– æ¦‚è¿°

Agent Engine ç°å·²é›†æˆå¤šå‚å•† LLM å®¢æˆ·ç«¯ï¼Œæä¾›ï¼š

- **OpenAI** - GPT-4, GPT-3.5 Turbo
- **Claude** - Claude 3 (Opus, Sonnet, Haiku)
- **Ollama** - æœ¬åœ° LLM (Llama 2, Mistral, ç­‰)
- **è‡ªåŠ¨é™çº§** - OpenAI â†’ Claude â†’ Ollama

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd algo/agent-engine
pip install -r requirements.txt
```

### 2. é…ç½® API å¯†é’¥

```bash
# OpenAI
export OPENAI_API_KEY="sk-..."

# Claude
export ANTHROPIC_API_KEY="sk-ant-..."

# Ollama (æœ¬åœ°ï¼Œé»˜è®¤ http://localhost:11434)
export OLLAMA_BASE_URL="http://localhost:11434"

# é¦–é€‰æä¾›å•†
export PREFERRED_LLM_PROVIDER="openai"  # openai | claude | ollama
```

### 3. å¯åŠ¨æœåŠ¡

```bash
uvicorn main:app --host 0.0.0.0 --port 8003 --reload
```

---

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

### âœ… OpenAI GPT-4

- âœ… GPT-4 Turbo (128K context)
- âœ… GPT-3.5 Turbo (16K context)
- âœ… Function Calling
- âœ… æµå¼å“åº”

### âœ… Claude 3

- âœ… Claude 3 Opus (æœ€å¼ºå¤§)
- âœ… Claude 3 Sonnet (å¹³è¡¡)
- âœ… Claude 3 Haiku (å¿«é€Ÿ)
- âœ… 200K context window
- âœ… Tool Use

### âœ… Ollama (æœ¬åœ°)

- âœ… Llama 2, Mistral, CodeLlama
- âœ… å®Œå…¨ç¦»çº¿è¿è¡Œ
- âœ… å…è´¹
- âœ… ç§å¯†

### âœ… è‡ªåŠ¨é™çº§

**é™çº§é“¾**:

```
OpenAI â†’ Claude â†’ Ollama
```

---

## ğŸŒ API ç«¯ç‚¹

### æ–‡æœ¬ç”Ÿæˆ

**POST** `/api/v1/llm/complete`

**è¯·æ±‚**:

```json
{
  "messages": [
    { "role": "system", "content": "You are a helpful assistant." },
    { "role": "user", "content": "Hello!" }
  ],
  "temperature": 0.7,
  "max_tokens": 2000,
  "provider": "openai",
  "stream": false
}
```

**å“åº”**:

```json
{
  "content": "Hello! How can I help you today?",
  "model": "gpt-4-turbo-preview",
  "finish_reason": "stop",
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  },
  "provider": "openai"
}
```

### æµå¼ç”Ÿæˆ

è®¾ç½® `stream: true` å³å¯è·å¾— SSE æµã€‚

### æä¾›å•†çŠ¶æ€

**GET** `/api/v1/llm/providers/status`

### åˆ—å‡ºæ¨¡å‹

**GET** `/api/v1/llm/models`

---

## ğŸ“š Python API

```python
from app.llm.multi_llm_adapter import get_multi_llm_adapter
from app.llm.base import Message

# è·å–é€‚é…å™¨
adapter = get_multi_llm_adapter()

# ç”Ÿæˆæ–‡æœ¬
messages = [
    Message(role="system", content="You are helpful."),
    Message(role="user", content="Hello!")
]

response, provider = await adapter.complete(
    messages=messages,
    temperature=0.7,
    max_tokens=2000
)

print(f"Provider: {provider}")
print(f"Response: {response.content}")
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æä¾›å•†        | å»¶è¿Ÿ   | å‡†ç¡®ç‡   | æˆæœ¬ | å¤‡æ³¨         |
| ------------- | ------ | -------- | ---- | ------------ |
| OpenAI GPT-4  | ~1-3s  | **æœ€é«˜** | ä»˜è´¹ | æœ€å¼ºå¤§       |
| Claude 3 Opus | ~2-4s  | **æé«˜** | ä»˜è´¹ | 200K context |
| Ollama        | ~5-15s | ä¸­ç­‰     | å…è´¹ | æœ¬åœ°è¿è¡Œ     |

---

## ğŸ”§ é…ç½®

ç¯å¢ƒå˜é‡ï¼š

- `OPENAI_API_KEY` - OpenAI API å¯†é’¥
- `ANTHROPIC_API_KEY` - Claude API å¯†é’¥
- `OLLAMA_BASE_URL` - Ollama æœåŠ¡åœ°å€
- `PREFERRED_LLM_PROVIDER` - é¦–é€‰æä¾›å•†

---

## ğŸ“ æ”¯æŒ

**è´Ÿè´£äºº**: AI Engineer
**é—®é¢˜åé¦ˆ**: #sprint3-llm
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0

---

**æœ€åæ›´æ–°**: 2025-10-27
**çŠ¶æ€**: âœ… å·²å®Œæˆ
