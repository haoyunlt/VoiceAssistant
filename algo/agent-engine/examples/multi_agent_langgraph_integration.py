"""
Multi-Agent + LangGraph Integration Example
å±•ç¤ºå®Œæ•´çš„é›†æˆä½¿ç”¨æ–¹å¼
"""

import asyncio
import logging

from app.core.langgraph_engine import CheckpointManager, LangGraphWorkflowEngine
from app.core.multi_agent.coordinator import Agent, AgentRole
from app.core.multi_agent.enhanced_conflict_resolver import ConflictType

# å‡è®¾å¯¼å…¥ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦æ­£ç¡®çš„å¯¼å…¥è·¯å¾„ï¼‰
from app.core.multi_agent.enhanced_coordinator import EnhancedMultiAgentCoordinator
from app.core.multi_agent.task_scheduler import TaskPriority
from app.core.workflow_visualizer import visualize_execution, visualize_workflow

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def example_multi_agent_collaboration():
    """ç¤ºä¾‹ï¼šMulti-Agentåä½œ"""
    print("\n=== Multi-Agent åä½œç¤ºä¾‹ ===\n")

    # æ¨¡æ‹ŸLLMå’Œå·¥å…·
    class MockLLMClient:
        async def generate(self, prompt, **kwargs):
            return f"æ¨¡æ‹Ÿå›ç­”: {prompt[:50]}..."

    class MockToolRegistry:
        async def execute_tool(self, name, **kwargs):
            return f"å·¥å…· {name} æ‰§è¡ŒæˆåŠŸ"

    llm_client = MockLLMClient()
    tool_registry = MockToolRegistry()

    # 1. åˆ›å»ºå¢å¼ºåè°ƒå™¨
    coordinator = EnhancedMultiAgentCoordinator(llm_client, tool_registry)

    # 2. æ³¨å†ŒAgents
    print("ğŸ“ æ³¨å†ŒAgents...")

    researcher = Agent("researcher_01", AgentRole.RESEARCHER, llm_client)
    await coordinator.register_agent_with_capabilities(
        agent=researcher,
        capabilities={"research": 0.9, "analysis": 0.8, "data_collection": 0.85},
        success_rate=0.95,
        avg_response_time=2.5,
    )

    planner = Agent("planner_01", AgentRole.PLANNER, llm_client)
    await coordinator.register_agent_with_capabilities(
        agent=planner,
        capabilities={"planning": 0.85, "strategy": 0.9, "roadmap": 0.8},
        success_rate=0.90,
        avg_response_time=3.0,
    )

    executor = Agent("executor_01", AgentRole.EXECUTOR, llm_client)
    await coordinator.register_agent_with_capabilities(
        agent=executor,
        capabilities={"execution": 0.88, "implementation": 0.85},
        success_rate=0.92,
        avg_response_time=2.8,
    )

    print(f"âœ… å·²æ³¨å†Œ {len(coordinator.agents)} ä¸ªAgents\n")

    # 3. æ‰§è¡Œåä½œä»»åŠ¡
    print("ğŸš€ æ‰§è¡Œåä½œä»»åŠ¡...")

    result = await coordinator.collaborate_with_scheduling(
        task_description="åˆ†æQ4å¸‚åœºè¶‹åŠ¿å¹¶åˆ¶å®šå¢é•¿ç­–ç•¥",
        priority=TaskPriority.HIGH,
        required_capabilities=["research", "planning"],
        timeout=30,
    )

    print(f"\nä»»åŠ¡ç»“æœ:")
    print(f"  æˆåŠŸ: {result['success']}")
    print(f"  åˆ†é…Agent: {result.get('agent', 'N/A')}")
    print(f"  æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f}s")
    print(f"  è°ƒåº¦è´¨é‡: {result.get('schedule_quality', 0):.2f}")

    # 4. è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡:")
    comm_stats = coordinator.get_communication_stats()
    print(f"  æ¶ˆæ¯æ€»æ•°: {comm_stats['total_messages']}")
    print(f"  å¹³å‡å»¶è¿Ÿ: {comm_stats['avg_latency']:.3f}s")
    print(f"  å¤±è´¥ç‡: {comm_stats['failure_rate']:.1%}")

    # 5. å¥åº·æ£€æŸ¥
    print("\nğŸ¥ å¥åº·æ£€æŸ¥:")
    health = await coordinator.health_check()
    print(f"  ç³»ç»Ÿå¥åº·: {'âœ…' if health['healthy'] else 'âŒ'}")
    print(f"  é€šä¿¡å¼‚å¸¸: {len(health['anomalies'])} ä¸ª")
    if health["anomalies"]:
        for anomaly in health["anomalies"]:
            print(f"    - {anomaly['type']}: {anomaly['description']}")

    # 6. èƒ½åŠ›ç”»åƒ
    print("\nğŸ¯ Agentèƒ½åŠ›ç”»åƒ:")
    for agent_id in coordinator.agents.keys():
        profile = coordinator.get_agent_capabilities(agent_id)
        if profile:
            print(f"  {agent_id}:")
            print(f"    èƒ½åŠ›: {list(profile['capabilities'].keys())}")
            print(f"    æˆåŠŸç‡: {profile['success_rate']:.2%}")
            print(f"    å¹³å‡å“åº”: {profile['avg_response_time']:.2f}s")


async def example_langgraph_workflow():
    """ç¤ºä¾‹ï¼šLangGraphå·¥ä½œæµ"""
    print("\n=== LangGraph å·¥ä½œæµç¤ºä¾‹ ===\n")

    # 1. åˆå§‹åŒ–å¼•æ“
    checkpoint_manager = CheckpointManager()  # æœ¬åœ°å­˜å‚¨
    engine = LangGraphWorkflowEngine(checkpoint_manager)

    # 2. å®šä¹‰å·¥ä½œæµå‡½æ•°
    async def analyze_task(context):
        logger.info("åˆ†æä»»åŠ¡...")
        return {"analysis": "ä»»åŠ¡åˆ†æå®Œæˆ", "complexity": "high"}

    async def retrieve_documents(context):
        logger.info("æ£€ç´¢æ–‡æ¡£...")
        return {"documents": ["doc1.pdf", "doc2.pdf", "doc3.pdf"]}

    async def needs_review(context):
        # å†³ç­–ï¼šæ–‡æ¡£æ•°é‡è¶…è¿‡2ä¸ªéœ€è¦å®¡æŸ¥
        doc_count = len(context.get("documents", []))
        logger.info(f"å†³ç­–: æ–‡æ¡£æ•°={doc_count}, éœ€è¦å®¡æŸ¥={doc_count > 2}")
        return doc_count > 2

    async def review_result(context):
        logger.info("å®¡æŸ¥ç»“æœ...")
        return {"review": "å®¡æŸ¥é€šè¿‡", "quality_score": 0.92}

    async def finalize(context):
        logger.info("å®Œæˆå·¥ä½œæµ...")
        return {"status": "completed", "final_report": "å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ"}

    # 3. æ³¨å†Œå‡½æ•°
    engine.register_function("analyze_task", analyze_task)
    engine.register_function("retrieve_documents", retrieve_documents)
    engine.register_function("needs_review", needs_review)
    engine.register_function("review_result", review_result)
    engine.register_function("finalize", finalize)

    # 4. åˆ›å»ºå·¥ä½œæµé…ç½®
    workflow_config = {
        "nodes": [
            {"id": "start", "type": "action", "function": "analyze_task", "label": "åˆ†æä»»åŠ¡"},
            {
                "id": "retrieve",
                "type": "action",
                "function": "retrieve_documents",
                "label": "æ£€ç´¢æ–‡æ¡£",
            },
            {"id": "decide", "type": "decision", "condition": "needs_review", "label": "éœ€è¦å®¡æŸ¥?"},
            {"id": "review", "type": "action", "function": "review_result", "label": "å®¡æŸ¥ç»“æœ"},
            {"id": "end", "type": "action", "function": "finalize", "label": "å®Œæˆ"},
        ],
        "edges": [
            {"from": "start", "to": "retrieve"},
            {"from": "retrieve", "to": "decide"},
            {"from": "decide", "to": {"review": "needs_review", "end": "else"}},
            {"from": "review", "to": "end"},
        ],
        "entry": "start",
    }

    print("ğŸ“ åˆ›å»ºå·¥ä½œæµ...")
    workflow_id = engine.create_workflow(workflow_config)
    print(f"âœ… å·¥ä½œæµID: {workflow_id}\n")

    # 5. å¯è§†åŒ–å·¥ä½œæµ
    print("ğŸ¨ å·¥ä½œæµç»“æ„ (Mermaid):")
    mermaid = visualize_workflow(workflow_config)
    print(mermaid)
    print()

    # 6. æ‰§è¡Œå·¥ä½œæµ
    print("ğŸš€ æ‰§è¡Œå·¥ä½œæµ...\n")
    result = await engine.execute(
        workflow_id,
        initial_data={"task": "åˆ†æå®¢æˆ·æ•°æ®", "user_id": "user_123"},
        entry_node="start",
        save_checkpoints=True,
    )

    print(f"\næ‰§è¡Œç»“æœ:")
    print(f"  çŠ¶æ€: {result['status']}")
    print(f"  æ‰§è¡Œè·¯å¾„: {' â†’ '.join(result['node_history'])}")
    print(f"  æœ€ç»ˆæ•°æ®: {result['variables'].get('final_report', 'N/A')}")

    # 7. å¯è§†åŒ–æ‰§è¡Œè¿½è¸ª
    print("\nğŸ¨ æ‰§è¡Œè¿½è¸ª (Mermaid):")
    trace_mermaid = visualize_execution(workflow_config, node_history=result["node_history"])
    print(trace_mermaid)
    print()

    # 8. ç»Ÿè®¡ä¿¡æ¯
    stats = engine.get_stats()
    print(f"ğŸ“Š å¼•æ“ç»Ÿè®¡:")
    print(f"  æ€»æ‰§è¡Œæ¬¡æ•°: {stats['total_executions']}")
    print(f"  æˆåŠŸæ¬¡æ•°: {stats['successful_executions']}")
    print(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")


async def example_workflow_recovery():
    """ç¤ºä¾‹ï¼šå·¥ä½œæµæ¢å¤"""
    print("\n=== å·¥ä½œæµæ¢å¤ç¤ºä¾‹ ===\n")

    checkpoint_manager = CheckpointManager()
    engine = LangGraphWorkflowEngine(checkpoint_manager)

    # å®šä¹‰ä¼šå¤±è´¥çš„å‡½æ•°
    call_count = 0

    async def step1(context):
        logger.info("æ­¥éª¤1: åˆå§‹åŒ–")
        return {"step1": "completed"}

    async def step2(context):
        logger.info("æ­¥éª¤2: å¤„ç†")
        return {"step2": "completed"}

    async def step3_with_failure(context):
        nonlocal call_count
        call_count += 1
        logger.info(f"æ­¥éª¤3: å°è¯•æ‰§è¡Œ (ç¬¬{call_count}æ¬¡)")

        if call_count == 1:
            # ç¬¬ä¸€æ¬¡æ‰§è¡Œå¤±è´¥
            raise Exception("æ¨¡æ‹Ÿå¤±è´¥ï¼šç½‘ç»œè¶…æ—¶")
        else:
            # ç¬¬äºŒæ¬¡æ‰§è¡ŒæˆåŠŸ
            logger.info("æ­¥éª¤3: æ‰§è¡ŒæˆåŠŸ")
            return {"step3": "completed"}

    async def step4(context):
        logger.info("æ­¥éª¤4: å®Œæˆ")
        return {"final": "all_done"}

    # æ³¨å†Œå‡½æ•°
    engine.register_function("step1", step1)
    engine.register_function("step2", step2)
    engine.register_function("step3", step3_with_failure)
    engine.register_function("step4", step4)

    # åˆ›å»ºå·¥ä½œæµ
    workflow_config = {
        "nodes": [
            {"id": "s1", "type": "action", "function": "step1"},
            {"id": "s2", "type": "action", "function": "step2"},
            {"id": "s3", "type": "action", "function": "step3"},
            {"id": "s4", "type": "action", "function": "step4"},
        ],
        "edges": [
            {"from": "s1", "to": "s2"},
            {"from": "s2", "to": "s3"},
            {"from": "s3", "to": "s4"},
        ],
        "entry": "s1",
    }

    workflow_id = engine.create_workflow(workflow_config)

    # ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆä¼šå¤±è´¥ï¼‰
    print("ğŸš€ ç¬¬ä¸€æ¬¡æ‰§è¡Œ (ä¼šåœ¨æ­¥éª¤3å¤±è´¥)...")
    try:
        await engine.execute(workflow_id, initial_data={"task": "æµ‹è¯•æ¢å¤"})
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}\n")

    # æŸ¥çœ‹checkpoint
    status = engine.get_workflow_status(workflow_id)
    print(f"ğŸ“Œ CheckpointçŠ¶æ€:")
    print(f"  å½“å‰èŠ‚ç‚¹: {status['current_node']}")
    print(f"  å·²æ‰§è¡Œ: {status['node_history']}")
    print(f"  çŠ¶æ€: {status['status']}")
    print()

    # æ¢å¤æ‰§è¡Œ
    print("ğŸ”„ æ¢å¤æ‰§è¡Œ...")
    result = await engine.resume(workflow_id)

    print(f"\næ¢å¤ç»“æœ:")
    print(f"  çŠ¶æ€: {result['status']}")
    print(f"  å®Œæ•´è·¯å¾„: {' â†’ '.join(result['node_history'])}")
    print(f"  æœ€ç»ˆæ•°æ®: {result['variables']}")


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("  Multi-Agent + LangGraph é›†æˆç¤ºä¾‹")
    print("=" * 60)

    # 1. Multi-Agentåä½œ
    await example_multi_agent_collaboration()

    print("\n" + "-" * 60 + "\n")

    # 2. LangGraphå·¥ä½œæµ
    await example_langgraph_workflow()

    print("\n" + "-" * 60 + "\n")

    # 3. å·¥ä½œæµæ¢å¤
    await example_workflow_recovery()

    print("\n" + "=" * 60)
    print("  âœ… æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆ")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
