# Voice Engine - å®ç°æ€»ç»“

## ğŸ“‹ å®ç°æ¦‚è¿°

æœ¬æ–‡æ¡£æ€»ç»“äº† **Voice Engine**ï¼ˆè¯­éŸ³å¼•æ“ï¼‰çš„å®Œæ•´å®ç°ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº FastAPI çš„ Python å¾®æœåŠ¡ï¼Œæä¾› ASRï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰ã€TTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰ã€VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰åŠŸèƒ½ã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. ASRï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰

- **æŠ€æœ¯**: Faster-Whisper (OpenAI Whisper)
- **æ¨¡å‹**: tiny, base, small, medium, large
- **ç‰¹æ€§**:
  - æ‰¹é‡è¯†åˆ«
  - æµå¼è¯†åˆ«ï¼ˆæ¡†æ¶ï¼‰
  - å¤šè¯­è¨€æ”¯æŒï¼ˆ100+ è¯­è¨€ï¼‰
  - è‡ªåŠ¨è¯­è¨€æ£€æµ‹
  - VAD é¢„å¤„ç†
  - æ—¶é—´æˆ³åˆ†æ®µ

### 2. TTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰

- **æŠ€æœ¯**: Edge TTS (Microsoft Edge)
- **ç‰¹æ€§**:
  - æ‰¹é‡åˆæˆ
  - æµå¼åˆæˆ
  - å¤šéŸ³è‰²æ”¯æŒ
  - è¯­é€Ÿ/éŸ³è°ƒè°ƒæ•´
  - æ™ºèƒ½ç¼“å­˜
  - å¤šç§éŸ³é¢‘æ ¼å¼ï¼ˆmp3, wav, opusï¼‰

### 3. VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰

- **æŠ€æœ¯**: Silero VAD (PyTorch)
- **ç‰¹æ€§**:
  - å®æ—¶æ£€æµ‹
  - è¯­éŸ³ç‰‡æ®µåˆ†å‰²
  - é™éŸ³è¿‡æ»¤
  - å¯è°ƒèŠ‚é˜ˆå€¼
  - æœ€å°è¯­éŸ³æ®µæ§åˆ¶

## ğŸ“ ç›®å½•ç»“æ„

```
algo/voice-engine/
â”œâ”€â”€ main.py                          # FastAPI åº”ç”¨å…¥å£
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py                # é…ç½®ç®¡ç† (Pydantic Settings)
â”‚   â”‚   â””â”€â”€ logging_config.py        # æ—¥å¿—é…ç½®
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ voice.py                 # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ health.py                # å¥åº·æ£€æŸ¥
â”‚   â”‚   â”œâ”€â”€ asr.py                   # ASR API
â”‚   â”‚   â”œâ”€â”€ tts.py                   # TTS API
â”‚   â”‚   â””â”€â”€ vad.py                   # VAD API
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ asr_service.py           # ASR æœåŠ¡
â”‚       â”œâ”€â”€ tts_service.py           # TTS æœåŠ¡
â”‚       â””â”€â”€ vad_service.py           # VAD æœåŠ¡
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â””â”€â”€ IMPLEMENTATION_SUMMARY.md        # æœ¬æ–‡ä»¶
```

## ğŸ”§ æ ¸å¿ƒå®ç°

### 1. é…ç½®ç®¡ç† (`app/core/config.py`)

```python
class Settings(BaseSettings):
    # ASR é…ç½®
    ASR_PROVIDER: str = "whisper"
    WHISPER_MODEL: str = "base"
    WHISPER_DEVICE: str = "cpu"

    # TTS é…ç½®
    TTS_PROVIDER: str = "edge"
    TTS_VOICE: str = "zh-CN-XiaoxiaoNeural"

    # VAD é…ç½®
    VAD_ENABLED: bool = True
    VAD_THRESHOLD: float = 0.3
    VAD_MIN_SPEECH_DURATION_MS: int = 500
    VAD_MIN_SILENCE_DURATION_MS: int = 2000

    # éŸ³é¢‘æ ¼å¼
    AUDIO_SAMPLE_RATE: int = 16000
    AUDIO_CHANNELS: int = 1
```

### 2. ASR æœåŠ¡ (`app/services/asr_service.py`)

```python
class ASRService:
    def __init__(self):
        self.model = WhisperModel(
            settings.WHISPER_MODEL,
            device=settings.WHISPER_DEVICE,
            compute_type=settings.WHISPER_COMPUTE_TYPE,
        )

    async def recognize_from_bytes(self, audio_data: bytes, ...):
        # VAD é¢„å¤„ç†
        if enable_vad:
            vad_result = await self.vad_service.detect_from_bytes(audio_data)

        # Whisper è¯†åˆ«
        segments, info = self.model.transcribe(
            audio_file,
            language=language,
            vad_filter=True,
        )

        return ASRResponse(text=..., language=..., segments=...)
```

### 3. TTS æœåŠ¡ (`app/services/tts_service.py`)

```python
class TTSService:
    async def synthesize(self, request: TTSRequest):
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._generate_cache_key(request)
        if cached := self._get_from_cache(cache_key):
            return TTSResponse(audio_base64=cached, cached=True)

        # Edge TTS åˆæˆ
        communicate = edge_tts.Communicate(
            text=request.text,
            voice=request.voice,
            rate=request.rate,
            pitch=request.pitch,
        )

        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]

        # å­˜å…¥ç¼“å­˜
        self._put_to_cache(cache_key, audio_base64)

        return TTSResponse(audio_base64=audio_base64, cached=False)
```

### 4. VAD æœåŠ¡ (`app/services/vad_service.py`)

```python
class VADService:
    def __init__(self):
        # åŠ è½½ Silero VAD æ¨¡å‹
        self.model, self.utils = torch.hub.load(
            repo_or_dir="snakers4/silero-vad",
            model="silero_vad",
        )

    async def detect_from_bytes(self, audio_data: bytes, ...):
        # åŠ è½½éŸ³é¢‘
        audio_array, sample_rate = self._load_audio(audio_data)

        # Silero VAD æ£€æµ‹
        (get_speech_timestamps, _, _, _) = self.utils
        speech_timestamps = get_speech_timestamps(
            audio_array,
            self.model,
            threshold=threshold,
            min_speech_duration_ms=...,
            min_silence_duration_ms=...,
        )

        # è½¬æ¢ä¸ºå“åº”
        segments = [
            VoiceSegment(
                start_ms=ts["start"] / sample_rate * 1000,
                end_ms=ts["end"] / sample_rate * 1000,
                is_speech=True,
            )
            for ts in speech_timestamps
        ]

        return VADResponse(segments=segments, ...)
```

## ğŸ“¡ API æ¥å£

### 1. ASR API

#### æ‰¹é‡è¯†åˆ«

```
POST /api/v1/asr/recognize
```

#### æ–‡ä»¶ä¸Šä¼ è¯†åˆ«

```
POST /api/v1/asr/recognize/upload
```

#### æµå¼è¯†åˆ«ï¼ˆæ¡†æ¶ï¼‰

```
POST /api/v1/asr/stream
```

### 2. TTS API

#### æ‰¹é‡åˆæˆ

```
POST /api/v1/tts/synthesize
```

#### æµå¼åˆæˆ

```
POST /api/v1/tts/synthesize/stream
```

#### åˆ—å‡ºéŸ³è‰²

```
GET /api/v1/tts/voices
```

### 3. VAD API

#### æ£€æµ‹è¯­éŸ³æ´»åŠ¨

```
POST /api/v1/vad/detect
```

#### æ–‡ä»¶ä¸Šä¼ æ£€æµ‹

```
POST /api/v1/vad/detect/upload
```

## ğŸ¨ æ•°æ®æ¨¡å‹

### ASRRequest

```python
class ASRRequest(BaseModel):
    audio_url: Optional[str]
    audio_base64: Optional[str]
    language: Optional[str]
    enable_vad: bool = True
    task: str = "transcribe"  # or "translate"
```

### ASRResponse

```python
class ASRResponse(BaseModel):
    text: str
    language: str
    confidence: Optional[float]
    segments: Optional[List[dict]]
    duration_ms: float
    processing_time_ms: float
```

### TTSRequest

```python
class TTSRequest(BaseModel):
    text: str
    voice: Optional[str]
    rate: Optional[str] = "+0%"
    pitch: Optional[str] = "+0Hz"
    format: str = "mp3"
    cache_key: Optional[str]
```

### VADResponse

```python
class VADResponse(BaseModel):
    segments: List[VoiceSegment]
    total_speech_duration_ms: float
    total_duration_ms: float
    speech_ratio: float
    processing_time_ms: float
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### 1. æ¨¡å‹é¢„åŠ è½½

```python
# å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼Œé¿å…é¦–æ¬¡è¯·æ±‚å»¶è¿Ÿ
self.whisper_model = WhisperModel(...)
self.vad_model = torch.hub.load(...)
```

### 2. TTS ç¼“å­˜

```python
# ç›¸åŒæ–‡æœ¬å¤ç”¨åˆæˆç»“æœ
cache_key = hashlib.md5(f"{text}:{voice}:{rate}:{pitch}".encode()).hexdigest()
```

### 3. æµå¼å¤„ç†

```python
# TTS æµå¼è¿”å›ï¼Œé™ä½é¦–å­—èŠ‚å»¶è¿Ÿ
async for chunk in communicate.stream():
    if chunk["type"] == "audio":
        yield chunk["data"]
```

### 4. å¼‚æ­¥å¤„ç†

```python
# æ‰€æœ‰ I/O æ“ä½œå¼‚æ­¥åŒ–
async def recognize_from_bytes(self, audio_data: bytes):
    # å¼‚æ­¥è¯†åˆ«
```

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

### å»¶è¿ŸæŒ‡æ ‡

- `asr_recognize_duration_seconds`: ASR è¯†åˆ«å»¶è¿Ÿ
- `tts_synthesize_duration_seconds`: TTS åˆæˆå»¶è¿Ÿ
- `vad_detect_duration_seconds`: VAD æ£€æµ‹å»¶è¿Ÿ

### ä¸šåŠ¡æŒ‡æ ‡

- `asr_requests_total`: ASR è¯·æ±‚æ€»æ•°
- `tts_cache_hit_rate`: TTS ç¼“å­˜å‘½ä¸­ç‡
- `vad_speech_ratio_avg`: å¹³å‡è¯­éŸ³å æ¯”

## ğŸ”„ é›†æˆå…³ç³»

### ä¸Šæ¸¸æœåŠ¡

- **AI Orchestrator**: è°ƒç”¨è¯­éŸ³å¤„ç† API
- **Conversation Service**: å¯¹è¯åœºæ™¯è¯­éŸ³å¤„ç†

### ä¸‹æ¸¸æœåŠ¡

- **MinIO**: éŸ³é¢‘æ–‡ä»¶å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
- **Redis**: TTS ç¼“å­˜ï¼ˆå¯é€‰ï¼‰

## ğŸ§ª æµ‹è¯•è¦ç‚¹

### å•å…ƒæµ‹è¯•

- [ ] Whisper è¯†åˆ«å‡†ç¡®æ€§
- [ ] Edge TTS åˆæˆè´¨é‡
- [ ] VAD æ£€æµ‹å‡†ç¡®æ€§
- [ ] ç¼“å­˜é€»è¾‘

### é›†æˆæµ‹è¯•

- [ ] ASR å®Œæ•´æµç¨‹ï¼ˆä¸Šä¼  â†’ è¯†åˆ« â†’ è¿”å›ï¼‰
- [ ] TTS å®Œæ•´æµç¨‹ï¼ˆæ–‡æœ¬ â†’ åˆæˆ â†’ ç¼“å­˜ï¼‰
- [ ] VAD å®Œæ•´æµç¨‹ï¼ˆéŸ³é¢‘ â†’ æ£€æµ‹ â†’ åˆ†æ®µï¼‰

### æ€§èƒ½æµ‹è¯•

- [ ] ASR å»¶è¿Ÿ < 500msï¼ˆbase æ¨¡å‹ï¼Œ10s éŸ³é¢‘ï¼‰
- [ ] TTS å»¶è¿Ÿ < 1sï¼ˆ20 å­—æ–‡æœ¬ï¼‰
- [ ] VAD å»¶è¿Ÿ < 200msï¼ˆ10s éŸ³é¢‘ï¼‰
- [ ] TTS ç¼“å­˜å‘½ä¸­ç‡ > 30%

## ğŸ” å®‰å…¨è€ƒè™‘

- **æ–‡ä»¶å¤§å°é™åˆ¶**: æœ€å¤§ 5 åˆ†é’ŸéŸ³é¢‘
- **è¾“å…¥éªŒè¯**: Pydantic æ¨¡å‹éªŒè¯
- **URL ä¸‹è½½**: è¶…æ—¶å’Œå¤§å°é™åˆ¶
- **ç¼“å­˜éš”ç¦»**: ç§Ÿæˆ·çº§åˆ«ç¼“å­˜é”®

## ğŸ“ é…ç½®ç¤ºä¾‹

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
ASR_PROVIDER: whisper
WHISPER_MODEL: base
WHISPER_DEVICE: cuda # å¦‚æœæœ‰ GPU

TTS_PROVIDER: edge
TTS_VOICE: zh-CN-XiaoxiaoNeural

VAD_ENABLED: true
VAD_THRESHOLD: 0.3

AUDIO_SAMPLE_RATE: 16000
MAX_AUDIO_DURATION_SECONDS: 300

LOG_LEVEL: INFO
```

## ğŸ› å·²çŸ¥é—®é¢˜ä¸é™åˆ¶

1. **æµå¼ ASR**: å½“å‰ä»…å®ç°æ¡†æ¶ï¼Œéœ€è¦é›†æˆ WebSocket æˆ– SSE
2. **Azure Provider**: Azure Speech SDK é›†æˆå°šæœªå®ç°
3. **Redis ç¼“å­˜**: TTS ç¼“å­˜å½“å‰ä½¿ç”¨å†…å­˜ï¼Œåº”è¿ç§»åˆ° Redis
4. **GPU æ”¯æŒ**: Whisper æ”¯æŒ GPU åŠ é€Ÿï¼Œä½†éœ€è¦é…ç½® CUDA

## ğŸ”® åç»­ä¼˜åŒ–

1. **å®æ—¶æµå¼ ASR**: é›†æˆ WebSocketï¼Œæ”¯æŒå®æ—¶è¯­éŸ³è¯†åˆ«
2. **è¯´è¯äººåˆ†ç¦»**: è¯†åˆ«ä¸åŒè¯´è¯äººçš„è¯­éŸ³
3. **æƒ…æ„Ÿåˆ†æ**: åˆ†æè¯­éŸ³æƒ…æ„Ÿï¼ˆæ„¤æ€’ã€æ‚²ä¼¤ã€é«˜å…´ç­‰ï¼‰
4. **å™ªéŸ³æŠ‘åˆ¶**: é›†æˆéŸ³é¢‘é™å™ªç®—æ³•
5. **å¤šæ ¼å¼æ”¯æŒ**: æ”¯æŒæ›´å¤šéŸ³é¢‘ç¼–è§£ç æ ¼å¼
6. **åˆ†å¸ƒå¼éƒ¨ç½²**: æ¨¡å‹åˆ†ç¦»éƒ¨ç½²ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•

## âœ… éªŒæ”¶æ¸…å•

- [x] ASR è¯†åˆ«å®ç°ï¼ˆWhisperï¼‰
- [x] TTS åˆæˆå®ç°ï¼ˆEdge TTSï¼‰
- [x] VAD æ£€æµ‹å®ç°ï¼ˆSilero VADï¼‰
- [x] æ‰¹é‡ API å®ç°
- [x] æµå¼ API æ¡†æ¶å®ç°
- [x] TTS ç¼“å­˜å®ç°
- [x] å¤šéŸ³è‰²æ”¯æŒ
- [x] å¥åº·æ£€æŸ¥ API
- [x] é…ç½®ç®¡ç†ï¼ˆPydanticï¼‰
- [x] æ—¥å¿—é…ç½®
- [x] Dockerfile å’Œ Makefile
- [x] API æ–‡æ¡£ï¼ˆREADMEï¼‰
- [x] å®ç°æ€»ç»“ï¼ˆæœ¬æ–‡æ¡£ï¼‰

## ğŸ“š å‚è€ƒèµ„æ–™

- [Faster-Whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [Edge TTS GitHub](https://github.com/rany2/edge-tts)
- [Silero VAD GitHub](https://github.com/snakers4/silero-vad)
- [OpenAI Whisper Paper](https://arxiv.org/abs/2212.04356)
- [FastAPI å®˜æ–¹æ–‡æ¡£](https://fastapi.tiangolo.com/)

---

**å®ç°å®Œæˆæ—¥æœŸ**: 2025-10-26
**ç‰ˆæœ¬**: v1.0.0
**å®ç°è€…**: AI Assistant
