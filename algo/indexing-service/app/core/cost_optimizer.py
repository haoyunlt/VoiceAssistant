"""
æˆæœ¬ä¼˜åŒ–å™¨
åŒ…å«æ–‡æœ¬å»é‡ã€Token è®¡æ•°ã€æˆæœ¬è®¡ç®—å’Œä¼˜åŒ–å»ºè®®
"""

import hashlib
import logging
import re
from typing import Any

logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥ Prometheusï¼ˆå¯é€‰ä¾èµ–ï¼‰
try:
    from prometheus_client import Counter as PromCounter
    from prometheus_client import Histogram

    PROMETHEUS_AVAILABLE = True

    # Prometheus æŒ‡æ ‡
    TOKENS_PROCESSED = PromCounter(
        "embedding_tokens_processed_total",
        "Total number of tokens processed",
        ["model", "tenant_id"],
    )
    EMBEDDING_COST = PromCounter(
        "embedding_cost_dollars_total",
        "Total embedding cost in dollars",
        ["model", "tenant_id"],
    )
    DEDUPLICATION_SAVINGS = PromCounter(
        "deduplication_savings_total",
        "Total texts saved by deduplication",
        ["tenant_id"],
    )
    TOKENS_PER_REQUEST = Histogram(
        "tokens_per_request",
        "Distribution of tokens per request",
        ["model"],
        buckets=[10, 50, 100, 200, 500, 1000, 2000, 5000],
    )
except ImportError:
    PROMETHEUS_AVAILABLE = False
    logger.warning("prometheus_client not available, metrics disabled")


class TokenCounter:
    """Token è®¡æ•°å™¨"""

    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        """
        åˆå§‹åŒ– Token è®¡æ•°å™¨

        Args:
            model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºé€‰æ‹©è®¡æ•°æ–¹æ³•ï¼‰
        """
        self.model_name = model_name

        # å°è¯•å¯¼å…¥ tiktokenï¼ˆç²¾ç¡®è®¡æ•°ï¼‰
        try:
            import tiktoken

            self.tiktoken = tiktoken
            self.use_tiktoken = True
            self.encoding = tiktoken.encoding_for_model(model_name)
            logger.info(f"TokenCounter initialized with tiktoken for {model_name}")
        except ImportError:
            self.tiktoken = None
            self.use_tiktoken = False
            logger.warning("tiktoken not available, using approximation")

    def count_tokens(self, text: str) -> int:
        """
        è®¡ç®—æ–‡æœ¬çš„ Token æ•°é‡

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            Token æ•°é‡
        """
        if not text:
            return 0

        if self.use_tiktoken:
            # ç²¾ç¡®è®¡æ•°
            return len(self.encoding.encode(text))
        else:
            # è¿‘ä¼¼è®¡æ•°
            return self._approximate_token_count(text)

    def count_tokens_batch(self, texts: list[str]) -> list[int]:
        """
        æ‰¹é‡è®¡ç®— Token æ•°é‡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            Token æ•°é‡åˆ—è¡¨
        """
        return [self.count_tokens(text) for text in texts]

    def _approximate_token_count(self, text: str) -> int:
        """
        è¿‘ä¼¼ Token è®¡æ•°

        ç­–ç•¥:
        - ä¸­æ–‡å­—ç¬¦: æ¯ä¸ªå­—ç¬¦çº¦ 1.5 tokens
        - è‹±æ–‡å•è¯: æ¯ä¸ªå•è¯çº¦ 1.3 tokens
        - æ•°å­—å’Œæ ‡ç‚¹: æ¯ä¸ªçº¦ 1 token

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            è¿‘ä¼¼ Token æ•°é‡
        """
        # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦
        chinese_chars = sum(1 for char in text if "\u4e00" <= char <= "\u9fff")

        # ç»Ÿè®¡è‹±æ–‡å•è¯
        english_words = len([word for word in text.split() if any(c.isalpha() for c in word)])

        # ç»Ÿè®¡æ•°å­—
        numbers = len(re.findall(r"\d+", text))

        # ä¼°ç®— Token æ•°
        estimated_tokens = int(chinese_chars * 1.5 + english_words * 1.3 + numbers * 1.0)

        return max(estimated_tokens, 1)  # è‡³å°‘ 1 token

    def estimate_cost(
        self,
        token_count: int,
        model: str = "bge-m3",
        cost_per_1k_tokens: float | None = None,
    ) -> float:
        """
        ä¼°ç®—æˆæœ¬

        Args:
            token_count: Token æ•°é‡
            model: æ¨¡å‹åç§°
            cost_per_1k_tokens: æ¯ 1k tokens çš„æˆæœ¬

        Returns:
            æˆæœ¬ï¼ˆç¾å…ƒï¼‰
        """
        if cost_per_1k_tokens is None:
            cost_per_1k_tokens = self._get_model_cost(model)

        cost = (token_count / 1000) * cost_per_1k_tokens
        return cost

    def _get_model_cost(self, model: str) -> float:
        """
        è·å–æ¨¡å‹çš„å•ä»·

        Args:
            model: æ¨¡å‹åç§°

        Returns:
            æ¯ 1k tokens çš„æˆæœ¬ï¼ˆç¾å…ƒï¼‰
        """
        # å¸¸è§æ¨¡å‹çš„ä»·æ ¼ï¼ˆç¤ºä¾‹ï¼‰
        model_prices = {
            # OpenAI
            "text-embedding-ada-002": 0.0001,
            "text-embedding-3-small": 0.00002,
            "text-embedding-3-large": 0.00013,
            # Cohere
            "embed-english-v3.0": 0.0001,
            "embed-multilingual-v3.0": 0.0001,
            # æœ¬åœ°æ¨¡å‹ï¼ˆæ— æˆæœ¬ï¼Œä½†æœ‰ç®—åŠ›æˆæœ¬ï¼‰
            "bge-m3": 0.0,
            "bge-large-zh": 0.0,
            "bge-base-zh": 0.0,
            # å…¶ä»–
            "default": 0.0001,
        }

        return model_prices.get(model, model_prices["default"])


class TextDeduplicator:
    """æ–‡æœ¬å»é‡å™¨"""

    def __init__(self, use_hash: bool = True):
        """
        åˆå§‹åŒ–æ–‡æœ¬å»é‡å™¨

        Args:
            use_hash: æ˜¯å¦ä½¿ç”¨å“ˆå¸Œå»é‡ï¼ˆæ›´å¿«ä½†æœ‰æå°ç¢°æ’æ¦‚ç‡ï¼‰
        """
        self.use_hash = use_hash
        logger.info(f"TextDeduplicator initialized (use_hash={use_hash})")

    def deduplicate(self, texts: list[str]) -> tuple[list[str], list[int], dict[str, Any]]:
        """
        æ–‡æœ¬å»é‡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            (unique_texts, indices, stats)
            - unique_texts: å»é‡åçš„æ–‡æœ¬åˆ—è¡¨
            - indices: åŸå§‹ç´¢å¼•åˆ° unique ç´¢å¼•çš„æ˜ å°„
            - stats: å»é‡ç»Ÿè®¡ä¿¡æ¯
        """
        if not texts:
            return [], [], {"original_count": 0, "unique_count": 0, "duplicates": 0}

        unique_texts = []
        text_to_index = {}  # æ–‡æœ¬æˆ–å“ˆå¸Œ -> unique ç´¢å¼•
        indices = []  # åŸå§‹ç´¢å¼• -> unique ç´¢å¼•çš„æ˜ å°„

        for text in texts:
            # ç”Ÿæˆé”®ï¼ˆå“ˆå¸Œæˆ–åŸæ–‡ï¼‰
            key = self._hash_text(text) if self.use_hash else text

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if key in text_to_index:
                # é‡å¤æ–‡æœ¬
                unique_idx = text_to_index[key]
            else:
                # æ–°æ–‡æœ¬
                unique_idx = len(unique_texts)
                unique_texts.append(text)
                text_to_index[key] = unique_idx

            indices.append(unique_idx)

        stats = {
            "original_count": len(texts),
            "unique_count": len(unique_texts),
            "duplicates": len(texts) - len(unique_texts),
            "deduplication_rate": (len(texts) - len(unique_texts)) / len(texts) if texts else 0.0,
        }

        logger.debug(
            f"Deduplicated {len(texts)} texts -> {len(unique_texts)} unique "
            f"({stats['deduplication_rate']:.1%} duplicates)"
        )

        return unique_texts, indices, stats

    def deduplicate_with_reconstruction(self, texts: list[str]) -> tuple[list[str], list[int]]:
        """
        å»é‡å¹¶è¿”å›é‡å»ºæ˜ å°„

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            (unique_texts, reconstruction_indices)
            - unique_texts: å»é‡åçš„æ–‡æœ¬
            - reconstruction_indices: ç”¨äºé‡å»ºåŸå§‹é¡ºåºçš„ç´¢å¼•
        """
        unique_texts, indices, _ = self.deduplicate(texts)
        return unique_texts, indices

    def _hash_text(self, text: str) -> str:
        """
        è®¡ç®—æ–‡æœ¬å“ˆå¸Œ

        Args:
            text: æ–‡æœ¬

        Returns:
            å“ˆå¸Œå€¼
        """
        return hashlib.md5(text.encode()).hexdigest()


class CostCalculator:
    """æˆæœ¬è®¡ç®—å™¨"""

    def __init__(self, token_counter: TokenCounter):
        """
        åˆå§‹åŒ–æˆæœ¬è®¡ç®—å™¨

        Args:
            token_counter: Token è®¡æ•°å™¨
        """
        self.token_counter = token_counter
        self.total_tokens = 0
        self.total_cost = 0.0
        self.request_count = 0

        # æŒ‰æ¨¡å‹å’Œç§Ÿæˆ·ç»Ÿè®¡
        self.stats_by_model: dict[str, dict[str, Any]] = {}
        self.stats_by_tenant: dict[str, dict[str, Any]] = {}

        logger.info("CostCalculator initialized")

    def calculate_cost(
        self,
        texts: list[str],
        model: str,
        tenant_id: str = "default",
        cost_per_1k_tokens: float | None = None,
    ) -> dict[str, Any]:
        """
        è®¡ç®—æˆæœ¬

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            model: æ¨¡å‹åç§°
            tenant_id: ç§Ÿæˆ· ID
            cost_per_1k_tokens: æ¯ 1k tokens çš„æˆæœ¬

        Returns:
            æˆæœ¬ä¿¡æ¯
        """
        # ç»Ÿè®¡ Tokens
        token_counts = self.token_counter.count_tokens_batch(texts)
        total_tokens = sum(token_counts)

        # è®¡ç®—æˆæœ¬
        total_cost = self.token_counter.estimate_cost(total_tokens, model, cost_per_1k_tokens)

        # æ›´æ–°æ€»è®¡
        self.total_tokens += total_tokens
        self.total_cost += total_cost
        self.request_count += 1

        # æ›´æ–°æŒ‰æ¨¡å‹ç»Ÿè®¡
        if model not in self.stats_by_model:
            self.stats_by_model[model] = {
                "tokens": 0,
                "cost": 0.0,
                "requests": 0,
            }

        self.stats_by_model[model]["tokens"] += total_tokens
        self.stats_by_model[model]["cost"] += total_cost
        self.stats_by_model[model]["requests"] += 1

        # æ›´æ–°æŒ‰ç§Ÿæˆ·ç»Ÿè®¡
        if tenant_id not in self.stats_by_tenant:
            self.stats_by_tenant[tenant_id] = {
                "tokens": 0,
                "cost": 0.0,
                "requests": 0,
            }

        self.stats_by_tenant[tenant_id]["tokens"] += total_tokens
        self.stats_by_tenant[tenant_id]["cost"] += total_cost
        self.stats_by_tenant[tenant_id]["requests"] += 1

        # æ›´æ–° Prometheus æŒ‡æ ‡
        if PROMETHEUS_AVAILABLE:
            TOKENS_PROCESSED.labels(model=model, tenant_id=tenant_id).inc(total_tokens)
            EMBEDDING_COST.labels(model=model, tenant_id=tenant_id).inc(total_cost)
            TOKENS_PER_REQUEST.labels(model=model).observe(total_tokens)

        result = {
            "text_count": len(texts),
            "total_tokens": total_tokens,
            "avg_tokens_per_text": total_tokens / len(texts) if texts else 0,
            "total_cost": total_cost,
            "cost_per_text": total_cost / len(texts) if texts else 0,
            "model": model,
            "tenant_id": tenant_id,
        }

        logger.debug(
            f"Cost calculated: {len(texts)} texts, {total_tokens} tokens, ${total_cost:.6f}"
        )

        return result

    def get_total_stats(self) -> dict[str, Any]:
        """
        è·å–æ€»ä½“ç»Ÿè®¡

        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            "total_tokens": self.total_tokens,
            "total_cost": self.total_cost,
            "request_count": self.request_count,
            "avg_tokens_per_request": self.total_tokens / self.request_count
            if self.request_count > 0
            else 0,
            "avg_cost_per_request": self.total_cost / self.request_count
            if self.request_count > 0
            else 0,
        }

    def get_stats_by_model(self) -> dict[str, dict[str, Any]]:
        """è·å–æŒ‰æ¨¡å‹çš„ç»Ÿè®¡"""
        return self.stats_by_model

    def get_stats_by_tenant(self) -> dict[str, dict[str, Any]]:
        """è·å–æŒ‰ç§Ÿæˆ·çš„ç»Ÿè®¡"""
        return self.stats_by_tenant


class CostOptimizer:
    """æˆæœ¬ä¼˜åŒ–å™¨ï¼ˆæ•´åˆå»é‡ã€è®¡æ•°ã€è®¡ç®—ï¼‰"""

    def __init__(
        self,
        model_name: str = "bge-m3",
        enable_deduplication: bool = True,
    ):
        """
        åˆå§‹åŒ–æˆæœ¬ä¼˜åŒ–å™¨

        Args:
            model_name: æ¨¡å‹åç§°
            enable_deduplication: æ˜¯å¦å¯ç”¨å»é‡
        """
        self.model_name = model_name
        self.enable_deduplication = enable_deduplication

        # åˆå§‹åŒ–ç»„ä»¶
        self.token_counter = TokenCounter(model_name)
        self.deduplicator = TextDeduplicator(use_hash=True)
        self.cost_calculator = CostCalculator(self.token_counter)

        logger.info(f"CostOptimizer initialized: model={model_name}, dedup={enable_deduplication}")

    def optimize_and_calculate(
        self,
        texts: list[str],
        model: str | None = None,
        tenant_id: str = "default",
    ) -> tuple[list[str], list[int], dict[str, Any]]:
        """
        ä¼˜åŒ–æ–‡æœ¬å¹¶è®¡ç®—æˆæœ¬

        ç­–ç•¥:
        1. æ–‡æœ¬å»é‡
        2. ç»Ÿè®¡ Token
        3. è®¡ç®—æˆæœ¬
        4. è¿”å›ä¼˜åŒ–åçš„æ–‡æœ¬å’Œç»Ÿè®¡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä½¿ç”¨åˆå§‹åŒ–æ—¶çš„æ¨¡å‹ï¼‰
            tenant_id: ç§Ÿæˆ· ID

        Returns:
            (unique_texts, reconstruction_indices, stats)
        """
        if model is None:
            model = self.model_name

        # 1. å»é‡
        if self.enable_deduplication:
            unique_texts, indices, dedup_stats = self.deduplicator.deduplicate(texts)

            # è®°å½•å»é‡èŠ‚çœ
            if PROMETHEUS_AVAILABLE:
                DEDUPLICATION_SAVINGS.labels(tenant_id=tenant_id).inc(dedup_stats["duplicates"])
        else:
            unique_texts = texts
            indices = list(range(len(texts)))
            dedup_stats = {
                "original_count": len(texts),
                "unique_count": len(texts),
                "duplicates": 0,
                "deduplication_rate": 0.0,
            }

        # 2. è®¡ç®—æˆæœ¬ï¼ˆåŸºäºå»é‡åçš„æ–‡æœ¬ï¼‰
        cost_stats = self.cost_calculator.calculate_cost(unique_texts, model, tenant_id)

        # 3. è®¡ç®—èŠ‚çœ
        if self.enable_deduplication and dedup_stats["duplicates"] > 0:
            # è®¡ç®—å¦‚æœä¸å»é‡çš„æˆæœ¬
            full_cost_stats = self.cost_calculator.calculate_cost(texts, model, tenant_id)

            savings = {
                "tokens_saved": full_cost_stats["total_tokens"] - cost_stats["total_tokens"],
                "cost_saved": full_cost_stats["total_cost"] - cost_stats["total_cost"],
                "savings_rate": (full_cost_stats["total_cost"] - cost_stats["total_cost"])
                / full_cost_stats["total_cost"]
                if full_cost_stats["total_cost"] > 0
                else 0.0,
            }
        else:
            savings = {
                "tokens_saved": 0,
                "cost_saved": 0.0,
                "savings_rate": 0.0,
            }

        # 4. åˆå¹¶ç»Ÿè®¡
        stats = {
            "deduplication": dedup_stats,
            "cost": cost_stats,
            "savings": savings,
            "optimization_enabled": self.enable_deduplication,
        }

        logger.info(
            f"Optimized {len(texts)} texts -> {len(unique_texts)} unique, "
            f"saved ${savings['cost_saved']:.6f} ({savings['savings_rate']:.1%})"
        )

        return unique_texts, indices, stats

    def get_optimization_report(self) -> dict[str, Any]:
        """
        ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š

        Returns:
            ä¼˜åŒ–æŠ¥å‘Š
        """
        total_stats = self.cost_calculator.get_total_stats()
        model_stats = self.cost_calculator.get_stats_by_model()
        tenant_stats = self.cost_calculator.get_stats_by_tenant()

        report = {
            "total": total_stats,
            "by_model": model_stats,
            "by_tenant": tenant_stats,
            "recommendations": self._generate_recommendations(total_stats, model_stats),
        }

        return report

    def _generate_recommendations(
        self, total_stats: dict[str, Any], model_stats: dict[str, dict[str, Any]]
    ) -> list[str]:
        """
        ç”Ÿæˆä¼˜åŒ–å»ºè®®

        Args:
            total_stats: æ€»ä½“ç»Ÿè®¡
            model_stats: æŒ‰æ¨¡å‹ç»Ÿè®¡

        Returns:
            å»ºè®®åˆ—è¡¨
        """
        recommendations = []

        # 1. æ£€æŸ¥æˆæœ¬
        total_cost = total_stats["total_cost"]
        if total_cost > 100:
            recommendations.append(
                f"ğŸ’° High cost detected (${total_cost:.2f}). "
                "Consider enabling caching or using cheaper models."
            )

        # 2. æ£€æŸ¥æ˜¯å¦å¯ç”¨å»é‡
        if not self.enable_deduplication:
            recommendations.append("ğŸ”„ Deduplication is disabled. Enable it to reduce costs.")

        # 3. æ£€æŸ¥æ¨¡å‹é€‰æ‹©
        for model, stats in model_stats.items():
            cost = stats["cost"]
            tokens = stats["tokens"]

            # å¦‚æœä½¿ç”¨æ˜‚è´µçš„æ¨¡å‹ä½† Token æ•°å¾ˆå¤§
            if model.startswith("text-embedding-3-large") and tokens > 1000000:
                recommendations.append(
                    f"ğŸ’¡ Model '{model}' is expensive for high volume ({tokens:,} tokens). "
                    "Consider using 'text-embedding-3-small' or local models."
                )

            # å¦‚æœä½¿ç”¨ OpenAI ä½†é‡å¾ˆå¤§
            if "openai" in model.lower() and cost > 50:
                recommendations.append(
                    f"ğŸ’¡ High OpenAI costs (${cost:.2f}). "
                    "Consider using local models (BGE-M3) for cost savings."
                )

        # 4. æ£€æŸ¥å¹³å‡ Token æ•°
        avg_tokens = total_stats["avg_tokens_per_request"]
        if avg_tokens > 1000:
            recommendations.append(
                f"ğŸ“Š High average tokens per request ({avg_tokens:.0f}). "
                "Consider chunking texts into smaller pieces."
            )

        # 5. é€šç”¨å»ºè®®
        if not recommendations:
            recommendations.append("âœ… Cost optimization looks good! Continue monitoring.")

        return recommendations

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.cost_calculator = CostCalculator(self.token_counter)
        logger.info("Cost optimizer stats reset")


class CostBudgetManager:
    """æˆæœ¬é¢„ç®—ç®¡ç†å™¨"""

    def __init__(
        self,
        daily_budget: float = 100.0,
        monthly_budget: float = 3000.0,
        alert_threshold: float = 0.8,
    ):
        """
        åˆå§‹åŒ–é¢„ç®—ç®¡ç†å™¨

        Args:
            daily_budget: æ¯æ—¥é¢„ç®—ï¼ˆç¾å…ƒï¼‰
            monthly_budget: æ¯æœˆé¢„ç®—ï¼ˆç¾å…ƒï¼‰
            alert_threshold: å‘Šè­¦é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
        """
        self.daily_budget = daily_budget
        self.monthly_budget = monthly_budget
        self.alert_threshold = alert_threshold

        self.daily_spent = 0.0
        self.monthly_spent = 0.0

        logger.info(
            f"CostBudgetManager initialized: daily=${daily_budget}, "
            f"monthly=${monthly_budget}, alert={alert_threshold:.0%}"
        )

    def record_cost(self, cost: float) -> dict[str, Any]:
        """
        è®°å½•æˆæœ¬

        Args:
            cost: æˆæœ¬ï¼ˆç¾å…ƒï¼‰

        Returns:
            é¢„ç®—çŠ¶æ€
        """
        self.daily_spent += cost
        self.monthly_spent += cost

        daily_usage_rate = self.daily_spent / self.daily_budget
        monthly_usage_rate = self.monthly_spent / self.monthly_budget

        status = {
            "daily_spent": self.daily_spent,
            "daily_budget": self.daily_budget,
            "daily_remaining": self.daily_budget - self.daily_spent,
            "daily_usage_rate": daily_usage_rate,
            "monthly_spent": self.monthly_spent,
            "monthly_budget": self.monthly_budget,
            "monthly_remaining": self.monthly_budget - self.monthly_spent,
            "monthly_usage_rate": monthly_usage_rate,
            "alerts": [],
        }

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡å‘Šè­¦é˜ˆå€¼
        if daily_usage_rate >= self.alert_threshold:
            status["alerts"].append(
                f"âš ï¸  Daily budget {daily_usage_rate:.0%} used "
                f"(${self.daily_spent:.2f}/${self.daily_budget:.2f})"
            )

        if monthly_usage_rate >= self.alert_threshold:
            status["alerts"].append(
                f"âš ï¸  Monthly budget {monthly_usage_rate:.0%} used "
                f"(${self.monthly_spent:.2f}/${self.monthly_budget:.2f})"
            )

        # æ£€æŸ¥æ˜¯å¦è¶…é¢„ç®—
        if self.daily_spent > self.daily_budget:
            status["alerts"].append("ğŸš¨ Daily budget exceeded!")

        if self.monthly_spent > self.monthly_budget:
            status["alerts"].append("ğŸš¨ Monthly budget exceeded!")

        return status

    def check_budget(self, estimated_cost: float) -> tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰§è¡Œï¼ˆé¢„ç®—è¶³å¤Ÿï¼‰

        Args:
            estimated_cost: é¢„ä¼°æˆæœ¬

        Returns:
            (can_proceed, message)
        """
        if self.daily_spent + estimated_cost > self.daily_budget:
            return (
                False,
                f"Daily budget exceeded (${self.daily_spent:.2f}/${self.daily_budget:.2f})",
            )

        if self.monthly_spent + estimated_cost > self.monthly_budget:
            return (
                False,
                f"Monthly budget exceeded (${self.monthly_spent:.2f}/${self.monthly_budget:.2f})",
            )

        return True, "OK"

    def reset_daily(self):
        """é‡ç½®æ¯æ—¥ç»Ÿè®¡"""
        self.daily_spent = 0.0
        logger.info("Daily budget reset")

    def reset_monthly(self):
        """é‡ç½®æ¯æœˆç»Ÿè®¡"""
        self.monthly_spent = 0.0
        logger.info("Monthly budget reset")
