#!/usr/bin/env bash
#
# Retrieval Service ä¼˜åŒ–é¡¹ç›®åˆå§‹åŒ–è„šæœ¬
#
# ç”¨é€”:
# 1. åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
# 2. å‡†å¤‡é…ç½®æ–‡ä»¶æ¨¡æ¿
# 3. ä¸‹è½½æµ‹è¯•æ•°æ®é›†
# 4. è®¾ç½®å¼€å‘ç¯å¢ƒ
#

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
RETRIEVAL_SERVICE="$PROJECT_ROOT/algo/retrieval-service"

echo "ğŸš€ Retrieval Service ä¼˜åŒ–é¡¹ç›®åˆå§‹åŒ–"
echo "================================================"
echo ""

# é¢œè‰²è¾“å‡º
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥å‰ç½®æ¡ä»¶
check_prerequisites() {
    log_info "æ£€æŸ¥å‰ç½®æ¡ä»¶..."

    # æ£€æŸ¥Python
    if ! command -v python3 &> /dev/null; then
        log_error "Python3 æœªå®‰è£…"
        exit 1
    fi

    # æ£€æŸ¥ç›®å½•
    if [ ! -d "$RETRIEVAL_SERVICE" ]; then
        log_error "Retrieval service ç›®å½•ä¸å­˜åœ¨: $RETRIEVAL_SERVICE"
        exit 1
    fi

    log_info "å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡ âœ“"
}

# åˆ›å»ºç›®å½•ç»“æ„
create_directories() {
    log_info "åˆ›å»ºç›®å½•ç»“æ„..."

    # Phase 1-4 æ–°å¢æœåŠ¡ç›®å½•
    mkdir -p "$RETRIEVAL_SERVICE/app/services/query"
    mkdir -p "$RETRIEVAL_SERVICE/app/services/cache"
    mkdir -p "$RETRIEVAL_SERVICE/app/services/adaptive"
    mkdir -p "$RETRIEVAL_SERVICE/app/agents"
    mkdir -p "$RETRIEVAL_SERVICE/app/agents/tools"

    # è¯„æµ‹ç›®å½•
    mkdir -p "$RETRIEVAL_SERVICE/tests/eval/retrieval"
    mkdir -p "$RETRIEVAL_SERVICE/tests/eval/retrieval/datasets"
    mkdir -p "$RETRIEVAL_SERVICE/tests/eval/retrieval/reports"

    # æ€§èƒ½æµ‹è¯•
    mkdir -p "$RETRIEVAL_SERVICE/tests/load/k6"

    # é…ç½®ç›®å½•
    mkdir -p "$PROJECT_ROOT/configs/retrieval"

    # æ¨¡å‹ç›®å½•
    mkdir -p "$RETRIEVAL_SERVICE/models/intent_classifier"
    mkdir -p "$RETRIEVAL_SERVICE/models/reranker"

    log_info "ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ âœ“"
}

# åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿
create_config_templates() {
    log_info "åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿..."

    # Query optimization config
    cat > "$PROJECT_ROOT/configs/retrieval/query_optimization.yaml" <<'EOF'
# Query Optimization Configuration

expansion:
  enabled: false  # Phase 1 å¯ç”¨
  methods:
    - synonym
    - spelling
  max_expansions: 3
  synonym_dict_path: "data/synonyms.json"

multi_query:
  enabled: false  # Phase 1 å¯ç”¨
  num_queries: 3
  llm_model: "qwen-7b"
  llm_endpoint: "http://model-adapter:8000"
  temperature: 0.7
  timeout_ms: 3000

hyde:
  enabled: false  # Phase 1 å¯ç”¨
  num_hypotheses: 3
  fusion_method: "avg"  # avg, max, concat
  llm_model: "qwen-7b"
  temperature: 0.7

intent_classification:
  enabled: false  # Phase 1 å¯ç”¨
  model_path: "models/intent_classifier/bert-tiny"
  labels:
    - factual
    - procedural
    - navigational
    - comparative
EOF

    # Cache config
    cat > "$PROJECT_ROOT/configs/retrieval/cache.yaml" <<'EOF'
# Semantic Cache Configuration

strategy: "two_level"  # single, two_level

l1_cache:
  enabled: true
  ttl_seconds: 3600
  max_size_mb: 512
  eviction_policy: "lru"

l2_cache:
  enabled: false  # Phase 2 å¯ç”¨
  ttl_seconds: 21600
  similarity_threshold: 0.95
  max_items: 10000
  embedding_batch_size: 32

warming:
  enabled: false  # Phase 2 å¯ç”¨
  schedule: "0 */6 * * *"
  top_n_queries: 1000
  source: "analytics"  # analytics, manual
EOF

    # Reranking config
    cat > "$PROJECT_ROOT/configs/retrieval/reranking.yaml" <<'EOF'
# Reranking Configuration

strategy: "single"  # single, multi_stage

single_stage:
  model: "BAAI/bge-reranker-base"
  top_k: 10
  batch_size: 32

multi_stage:
  enabled: false  # Phase 2 å¯ç”¨

  stage1:
    model: "BAAI/bge-reranker-base"
    top_k: 20
    batch_size: 64

  stage2:
    model: "BAAI/bge-reranker-large"
    top_k: 10
    batch_size: 32
    use_llm: false
    llm_model: "gpt-4"
    llm_endpoint: "http://model-adapter:8000"
EOF

    # Adaptive retrieval config
    cat > "$PROJECT_ROOT/configs/retrieval/adaptive.yaml" <<'EOF'
# Adaptive Retrieval Configuration

enabled: false  # Phase 4 å¯ç”¨

complexity_evaluator:
  method: "rule_based"  # rule_based, ml
  model_path: "models/complexity_evaluator"

strategies:
  simple:
    trigger:
      word_count_max: 10
      entity_count_max: 0
    retrieval:
      method: "vector_only"
      top_k: 10
    timeout_ms: 200
    cost_weight: 1.0

  medium:
    trigger:
      word_count_max: 30
      entity_count_max: 2
    retrieval:
      method: "hybrid"
      fusion: "rrf"
      enable_rerank: false
    timeout_ms: 500
    cost_weight: 3.0

  complex:
    trigger:
      word_count_max: 999
    retrieval:
      method: "agent"
      enable_multi_query: true
      enable_rerank: true
      rerank_top_k: 10
    timeout_ms: 3000
    cost_weight: 10.0
EOF

    log_info "é…ç½®æ–‡ä»¶æ¨¡æ¿åˆ›å»ºå®Œæˆ âœ“"
}

# åˆ›å»ºè¯„æµ‹æ•°æ®é›†ä¸‹è½½è„šæœ¬
create_dataset_script() {
    log_info "åˆ›å»ºè¯„æµ‹æ•°æ®é›†ä¸‹è½½è„šæœ¬..."

    cat > "$RETRIEVAL_SERVICE/tests/eval/retrieval/download_datasets.sh" <<'EOF'
#!/usr/bin/env bash
# ä¸‹è½½è¯„æµ‹æ•°æ®é›†

set -euo pipefail

DATASETS_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)/datasets"

echo "ä¸‹è½½è¯„æµ‹æ•°æ®é›†åˆ°: $DATASETS_DIR"

# MS MARCO Dev Small (1000 queries)
if [ ! -f "$DATASETS_DIR/ms_marco_dev_small.jsonl" ]; then
    echo "ä¸‹è½½ MS MARCO Dev Small..."
    # TODO: æ›¿æ¢ä¸ºå®é™…ä¸‹è½½é“¾æ¥
    # wget https://example.com/ms_marco_dev_small.jsonl.gz -O "$DATASETS_DIR/ms_marco_dev_small.jsonl.gz"
    # gunzip "$DATASETS_DIR/ms_marco_dev_small.jsonl.gz"
    echo "âš ï¸  éœ€è¦æ‰‹åŠ¨ä¸‹è½½ MS MARCO æ•°æ®é›†"
else
    echo "âœ“ MS MARCO æ•°æ®é›†å·²å­˜åœ¨"
fi

# Natural Questions (å¯é€‰)
if [ ! -f "$DATASETS_DIR/natural_questions.jsonl" ]; then
    echo "ä¸‹è½½ Natural Questions..."
    # TODO: ä¸‹è½½é“¾æ¥
    echo "âš ï¸  éœ€è¦æ‰‹åŠ¨ä¸‹è½½ Natural Questions æ•°æ®é›†"
else
    echo "âœ“ Natural Questions æ•°æ®é›†å·²å­˜åœ¨"
fi

echo "æ•°æ®é›†å‡†å¤‡å®Œæˆ"
EOF

    chmod +x "$RETRIEVAL_SERVICE/tests/eval/retrieval/download_datasets.sh"

    log_info "è¯„æµ‹æ•°æ®é›†ä¸‹è½½è„šæœ¬åˆ›å»ºå®Œæˆ âœ“"
}

# åˆ›å»ºè¯„æµ‹é…ç½®
create_eval_config() {
    log_info "åˆ›å»ºè¯„æµ‹é…ç½®..."

    cat > "$RETRIEVAL_SERVICE/tests/eval/retrieval/config.yaml" <<'EOF'
# Retrieval Evaluation Configuration

datasets:
  - name: "ms_marco_dev_small"
    path: "datasets/ms_marco_dev_small.jsonl"
    format: "jsonl"
    fields:
      query: "query"
      doc_id: "doc_id"
      relevance: "label"
    enabled: true

metrics:
  - "mrr@10"
  - "ndcg@10"
  - "recall@5"
  - "recall@10"
  - "precision@5"

strategies:
  - name: "vector_only"
    config:
      method: "vector"
      top_k: 10

  - name: "hybrid_rrf"
    config:
      method: "hybrid"
      fusion: "rrf"
      top_k: 10
      enable_rerank: false

  - name: "hybrid_rerank"
    config:
      method: "hybrid"
      fusion: "rrf"
      top_k: 10
      enable_rerank: true

baseline:
  name: "vector_only"
  metrics:
    mrr@10: 0.65
    ndcg@10: 0.70
    recall@10: 0.75

output:
  report_dir: "reports"
  format: "html"  # html, json, markdown
  detailed: true
EOF

    log_info "è¯„æµ‹é…ç½®åˆ›å»ºå®Œæˆ âœ“"
}

# åˆ›å»ºå ä½æ–‡ä»¶
create_placeholder_files() {
    log_info "åˆ›å»ºå ä½æ–‡ä»¶..."

    # Query services
    touch "$RETRIEVAL_SERVICE/app/services/query/__init__.py"
    touch "$RETRIEVAL_SERVICE/app/services/query/expansion_service.py"
    touch "$RETRIEVAL_SERVICE/app/services/query/multi_query_service.py"
    touch "$RETRIEVAL_SERVICE/app/services/query/hyde_service.py"
    touch "$RETRIEVAL_SERVICE/app/services/query/intent_classifier.py"

    # Cache services
    touch "$RETRIEVAL_SERVICE/app/services/cache/__init__.py"
    touch "$RETRIEVAL_SERVICE/app/services/cache/semantic_cache.py"
    touch "$RETRIEVAL_SERVICE/app/services/cache/warming_service.py"

    # Adaptive services
    touch "$RETRIEVAL_SERVICE/app/services/adaptive/__init__.py"
    touch "$RETRIEVAL_SERVICE/app/services/adaptive/retrieval_service.py"
    touch "$RETRIEVAL_SERVICE/app/services/adaptive/complexity_evaluator.py"

    # Evaluation
    touch "$RETRIEVAL_SERVICE/tests/eval/retrieval/__init__.py"
    touch "$RETRIEVAL_SERVICE/tests/eval/retrieval/metrics.py"
    touch "$RETRIEVAL_SERVICE/tests/eval/retrieval/run_evaluation.py"

    log_info "å ä½æ–‡ä»¶åˆ›å»ºå®Œæˆ âœ“"
}

# åˆ›å»ºREADME
create_readme() {
    log_info "åˆ›å»ºREADME..."

    cat > "$RETRIEVAL_SERVICE/tests/eval/retrieval/README.md" <<'EOF'
# Retrieval Service è¯„æµ‹

## å¿«é€Ÿå¼€å§‹

### 1. ä¸‹è½½æ•°æ®é›†

```bash
./download_datasets.sh
```

### 2. è¿è¡ŒBaselineè¯„æµ‹

```bash
python run_evaluation.py --baseline --config config.yaml
```

### 3. è¯„æµ‹æ–°ç­–ç•¥

```bash
python run_evaluation.py --strategy hybrid_rerank --compare-with baseline
```

### 4. æŸ¥çœ‹æŠ¥å‘Š

```bash
open reports/eval_latest.html
```

## è¯„æµ‹æŒ‡æ ‡

- **MRR@10**: Mean Reciprocal Rank at 10
- **NDCG@10**: Normalized Discounted Cumulative Gain at 10
- **Recall@K**: å¬å›ç‡
- **Precision@K**: ç²¾ç¡®ç‡

## æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†

ç¼–è¾‘ `config.yaml`:

```yaml
datasets:
  - name: "my_dataset"
    path: "datasets/my_dataset.jsonl"
    format: "jsonl"
    fields:
      query: "query"
      doc_id: "doc_id"
      relevance: "label"
```

æ•°æ®æ ¼å¼:
```json
{"query": "å¦‚ä½•ä½¿ç”¨Python", "doc_id": "doc_123", "label": 1}
```
EOF

    log_info "READMEåˆ›å»ºå®Œæˆ âœ“"
}

# åˆ›å»ºGitåˆ†æ”¯
create_git_branch() {
    log_info "åˆ›å»ºGitåˆ†æ”¯..."

    cd "$PROJECT_ROOT"

    if git rev-parse --verify feat/retrieval-optimization-setup &>/dev/null; then
        log_warn "åˆ†æ”¯ feat/retrieval-optimization-setup å·²å­˜åœ¨"
    else
        git checkout -b feat/retrieval-optimization-setup
        log_info "åˆ›å»ºåˆ†æ”¯: feat/retrieval-optimization-setup âœ“"
    fi
}

# è¾“å‡ºåç»­æ­¥éª¤
print_next_steps() {
    echo ""
    echo "================================================"
    echo "âœ… åˆå§‹åŒ–å®Œæˆï¼"
    echo "================================================"
    echo ""
    echo "ğŸ“‹ åç»­æ­¥éª¤:"
    echo ""
    echo "1. æŸ¥çœ‹è·¯çº¿å›¾:"
    echo "   cat docs/roadmap/README.md"
    echo ""
    echo "2. ä¸‹è½½è¯„æµ‹æ•°æ®é›†:"
    echo "   cd algo/retrieval-service/tests/eval/retrieval"
    echo "   ./download_datasets.sh"
    echo ""
    echo "3. è¿è¡ŒBaselineè¯„æµ‹:"
    echo "   cd algo/retrieval-service"
    echo "   python tests/eval/retrieval/run_evaluation.py --baseline"
    echo ""
    echo "4. å¼€å§‹å®ç°Task 1.1 (Query Expansion):"
    echo "   - ç¼–è¾‘: app/services/query/expansion_service.py"
    echo "   - å‚è€ƒ: docs/arch/retrieval-service-tech-guide.md"
    echo ""
    echo "5. åˆ›å»ºGitHub Issues:"
    echo "   python scripts/create_roadmap_issues.py"
    echo ""
    echo "ğŸ“š æ–‡æ¡£ä½ç½®:"
    echo "   - ä¼˜åŒ–æ–¹æ¡ˆ: docs/roadmap/retrieval-service-optimization.md"
    echo "   - ä»»åŠ¡æ¸…å•: docs/roadmap/retrieval-optimization-tasks.md"
    echo "   - æŠ€æœ¯æŒ‡å—: docs/arch/retrieval-service-tech-guide.md"
    echo ""
    echo "ğŸš€ ç¥å¼€å‘é¡ºåˆ©ï¼"
    echo ""
}

# ä¸»å‡½æ•°
main() {
    check_prerequisites
    create_directories
    create_config_templates
    create_dataset_script
    create_eval_config
    create_placeholder_files
    create_readme
    # create_git_branch  # å¯é€‰
    print_next_steps
}

# æ‰§è¡Œ
main "$@"
